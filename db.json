{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0},{"_id":"source/favicon.ico","path":"favicon.ico","modified":1,"renderable":0},{"_id":"source/robots.txt","path":"robots.txt","modified":1,"renderable":0},{"_id":"source/root.txt","path":"root.txt","modified":1,"renderable":0},{"_id":"themes/Material-T/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/Material-T/source/img/apple-touch-icon.png","path":"img/apple-touch-icon.png","modified":1,"renderable":1},{"_id":"themes/Material-T/source/img/avatar.png","path":"img/avatar.png","modified":1,"renderable":1},{"_id":"themes/Material-T/source/img/favicon.png","path":"img/favicon.png","modified":1,"renderable":1},{"_id":"themes/Material-T/source/js/main.js","path":"js/main.js","modified":1,"renderable":1},{"_id":"themes/Material-T/source/js/post.js","path":"js/post.js","modified":1,"renderable":1},{"_id":"themes/Material-T/source/img/about.jpg","path":"img/about.jpg","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/anchor/anchor.min.js","path":"lib/anchor/anchor.min.js","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/github-markdown/github-markdown.min.css","path":"lib/github-markdown/github-markdown.min.css","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/nprogress/nprogress.css","path":"lib/nprogress/nprogress.css","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/nprogress/nprogress.min.js","path":"lib/nprogress/nprogress.min.js","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/prettify/github-v2.min.css","path":"lib/prettify/github-v2.min.css","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/prettify/tomorrow-night-eighties.min.css","path":"lib/prettify/tomorrow-night-eighties.min.css","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/prettify/prettify.min.js","path":"lib/prettify/prettify.min.js","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/prettify/tomorrow-night.min.css","path":"lib/prettify/tomorrow-night.min.css","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/prettify/tomorrow.min.css","path":"lib/prettify/tomorrow.min.css","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/tocbot/tocbot.min.js","path":"lib/tocbot/tocbot.min.js","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/typed/typed.min.js","path":"lib/typed/typed.min.js","modified":1,"renderable":1},{"_id":"themes/Material-T/source/img/archive.jpg","path":"img/archive.jpg","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/font-awesome/css/all.min.css","path":"lib/font-awesome/css/all.min.css","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-regular-400.eot","path":"lib/font-awesome/webfonts/fa-regular-400.eot","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-regular-400.ttf","path":"lib/font-awesome/webfonts/fa-regular-400.ttf","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-regular-400.woff2","path":"lib/font-awesome/webfonts/fa-regular-400.woff2","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-regular-400.woff","path":"lib/font-awesome/webfonts/fa-regular-400.woff","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/mdbootstrap/js/bootstrap.min.js","path":"lib/mdbootstrap/js/bootstrap.min.js","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/mdbootstrap/js/popper.min.js","path":"lib/mdbootstrap/js/popper.min.js","modified":1,"renderable":1},{"_id":"themes/Material-T/source/img/post.jpg","path":"img/post.jpg","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-brands-400.woff2","path":"lib/font-awesome/webfonts/fa-brands-400.woff2","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-brands-400.woff","path":"lib/font-awesome/webfonts/fa-brands-400.woff","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-solid-900.woff2","path":"lib/font-awesome/webfonts/fa-solid-900.woff2","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-solid-900.woff","path":"lib/font-awesome/webfonts/fa-solid-900.woff","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/mdbootstrap/js/jquery-3.4.1.min.js","path":"lib/mdbootstrap/js/jquery-3.4.1.min.js","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-brands-400.eot","path":"lib/font-awesome/webfonts/fa-brands-400.eot","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-brands-400.ttf","path":"lib/font-awesome/webfonts/fa-brands-400.ttf","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-regular-400.svg","path":"lib/font-awesome/webfonts/fa-regular-400.svg","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Bold.eot","path":"lib/mdbootstrap/font/roboto/Roboto-Bold.eot","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Light.eot","path":"lib/mdbootstrap/font/roboto/Roboto-Light.eot","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Bold.woff2","path":"lib/mdbootstrap/font/roboto/Roboto-Bold.woff2","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Medium.eot","path":"lib/mdbootstrap/font/roboto/Roboto-Medium.eot","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Light.woff2","path":"lib/mdbootstrap/font/roboto/Roboto-Light.woff2","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Light.woff","path":"lib/mdbootstrap/font/roboto/Roboto-Light.woff","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Medium.woff2","path":"lib/mdbootstrap/font/roboto/Roboto-Medium.woff2","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Regular.eot","path":"lib/mdbootstrap/font/roboto/Roboto-Regular.eot","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Medium.woff","path":"lib/mdbootstrap/font/roboto/Roboto-Medium.woff","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Thin.eot","path":"lib/mdbootstrap/font/roboto/Roboto-Thin.eot","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Regular.woff2","path":"lib/mdbootstrap/font/roboto/Roboto-Regular.woff2","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Regular.woff","path":"lib/mdbootstrap/font/roboto/Roboto-Regular.woff","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Thin.woff","path":"lib/mdbootstrap/font/roboto/Roboto-Thin.woff","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Thin.woff2","path":"lib/mdbootstrap/font/roboto/Roboto-Thin.woff2","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/mdbootstrap/css/bootstrap.min.css","path":"lib/mdbootstrap/css/bootstrap.min.css","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-solid-900.eot","path":"lib/font-awesome/webfonts/fa-solid-900.eot","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-solid-900.ttf","path":"lib/font-awesome/webfonts/fa-solid-900.ttf","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Bold.woff","path":"lib/mdbootstrap/font/roboto/Roboto-Bold.woff","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Light.ttf","path":"lib/mdbootstrap/font/roboto/Roboto-Light.ttf","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Medium.ttf","path":"lib/mdbootstrap/font/roboto/Roboto-Medium.ttf","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Regular.ttf","path":"lib/mdbootstrap/font/roboto/Roboto-Regular.ttf","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Thin.ttf","path":"lib/mdbootstrap/font/roboto/Roboto-Thin.ttf","modified":1,"renderable":1},{"_id":"themes/Material-T/source/img/index.jpg","path":"img/index.jpg","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Bold.ttf","path":"lib/mdbootstrap/font/roboto/Roboto-Bold.ttf","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/mdbootstrap/css/mdb.min.css","path":"lib/mdbootstrap/css/mdb.min.css","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/mdbootstrap/js/mdb.min.js","path":"lib/mdbootstrap/js/mdb.min.js","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-brands-400.svg","path":"lib/font-awesome/webfonts/fa-brands-400.svg","modified":1,"renderable":1},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-solid-900.svg","path":"lib/font-awesome/webfonts/fa-solid-900.svg","modified":1,"renderable":1}],"Cache":[{"_id":"source/404.html","hash":"115ffee530ae7d4ee406e76776e20e9bfaeb4f9d","modified":1566352144126},{"_id":"source/CNAME","hash":"58a245e5291e156ffab1f3b84219930adbdf45d2","modified":1566352144126},{"_id":"source/favicon.ico","hash":"2635768a4986cd46c7b92ebf94bbc7bfa7e5225f","modified":1566352144132},{"_id":"source/robots.txt","hash":"b48691b5fc4ac919ad8fe2e0f3356cf1d1c007a3","modified":1566352144132},{"_id":"source/root.txt","hash":"680b6068f217c824d8a34e51f8d15395562bb9a4","modified":1566352144132},{"_id":"themes/Material-T/.gitignore","hash":"bd095eee271360a38772ee1a42d4f000fb722e5f","modified":1566352199254},{"_id":"themes/Material-T/Changelog.md","hash":"ebdec33eb73ac2b731c9f5b9ce68ec8d1491b807","modified":1566352199255},{"_id":"themes/Material-T/LICENSE","hash":"75aba841e65714e4bd8da3a87f18d40a78b7eb79","modified":1566352199255},{"_id":"themes/Material-T/README.md","hash":"3a0514c8b7a48448e30bf413833bc782e819b157","modified":1566352199256},{"_id":"themes/Material-T/_config.yml","hash":"5e8973c807bf43662126316ee2c8b05a55515fc8","modified":1566352199256},{"_id":"themes/Material-T/layout/page.ejs","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1566352199266},{"_id":"themes/Material-T/pages/about.md","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1566352199269},{"_id":"source/_posts/Cowboy的路由机制.md","hash":"ffffc1ed15222492acd846f06c59be7a63f9c85c","modified":1566352144127},{"_id":"source/_posts/Erlang-Efficiency-guide-非标准笔记.md","hash":"d1c13a6565bfc2e5a4e15aa9893606c4863ff823","modified":1566352144127},{"_id":"source/_posts/Erlang发送邮件相关问题.md","hash":"e315998b0f671fc9e1e7053abd32ad9fbd3090de","modified":1566352144127},{"_id":"source/_posts/Erlang通过NIF集成c代码示例.md","hash":"6d526b75fdd71aae51c57c78ea295383f35ddba1","modified":1566352144127},{"_id":"source/_posts/MQTT-V1-3-协议详解.md","hash":"69a6525104af3868a95417fae19de8f929453693","modified":1566352144128},{"_id":"source/_posts/Nginx配置.md","hash":"57c89255e0c3a75e2b6e673c15935cf4b3f21e18","modified":1566352144128},{"_id":"source/_posts/coding-with-swift-on-linux.md","hash":"cf70e50bfe90aa11f04f9bf434ef36557629a3fd","modified":1566352144128},{"_id":"source/_posts/different-between-p-and-w-in-io-format.md","hash":"112b59eb129a2883be2f06138486aea46644d867","modified":1566352144129},{"_id":"source/_posts/Riak安装与MapReduce测试.md","hash":"5347e88b997c7db04e4ae0b23713d67a12003e2f","modified":1566352144128},{"_id":"source/_posts/ejabberd-receiver分析.md","hash":"6366dad5974e562f9a5c01e80c4f3dfbfd08c04d","modified":1566352144129},{"_id":"source/_posts/erlang—program-optimization.md","hash":"e6d29a3ed1b4a4dfa2e1ebb9628e38388331500d","modified":1566352144129},{"_id":"source/_posts/githubConnectionWay.md","hash":"3f7d303c5ec4b9419b582498135ac211dfedad9c","modified":1566352144129},{"_id":"source/_posts/goa请求处理解析.md","hash":"f8745475b8999768fa44f9fbd1c5956a155d438b","modified":1566352144130},{"_id":"source/_posts/hexo的archive分页问题.md","hash":"6a4f240d33ad580001eeb4a0442a977ef39cecd2","modified":1566352144130},{"_id":"source/_posts/restfulWebServices2.md","hash":"6446d7583e82ed401c72762bf0babbb5567dc47d","modified":1566352144130},{"_id":"source/_posts/restfulWebService1.md","hash":"7fa2f72ae6cf2e2d2158a8e1686df94675c33b71","modified":1566352144130},{"_id":"source/_posts/restfulWebServices3.md","hash":"e5876caad3a529afa080ed852806b8b754da8f17","modified":1566352144130},{"_id":"source/_posts/tsung压测restful服务器.md","hash":"7b8c666d518cabcf14db6af0db3b6916130e548d","modified":1566352144131},{"_id":"source/_posts/webrtc一些笔记.md","hash":"0e1f903963115fcddf7adb52ce38b78d7580cc7f","modified":1566352144131},{"_id":"source/_posts/阿里短信发送api.md","hash":"a8f8262e0c5bfaad6b81a150ef5bdd2dce5f02b5","modified":1566352144132},{"_id":"source/tags/index.md","hash":"e2bf6350397182767e9bc51838233ce78acd208b","modified":1566352144133},{"_id":"themes/Material-T/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1566352199242},{"_id":"themes/Material-T/.git/config","hash":"6be7d994109bcfae88767ff358a0e061358c236a","modified":1566352199246},{"_id":"themes/Material-T/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1566352177286},{"_id":"themes/Material-T/.git/index","hash":"a654e5de5a92875f39ac244cd6244df73e26c9ef","modified":1566352274089},{"_id":"themes/Material-T/.git/packed-refs","hash":"576440c22d915a09779cbd3af70f773f4089c7bb","modified":1566352199237},{"_id":"themes/Material-T/layout/404.ejs","hash":"0d98ca6531164a61a599dc1321975aba2b1273f6","modified":1566352199257},{"_id":"themes/Material-T/layout/about.ejs","hash":"6bbc22534ddab6c6b0fa7a70575175579076062d","modified":1566352199263},{"_id":"themes/Material-T/layout/archive.ejs","hash":"61aff033ea8a49f778c89563e859455dc1d06ebd","modified":1566352199263},{"_id":"themes/Material-T/layout/categories.ejs","hash":"f5ea23c8d0a493b29607247314a2979bec72a68e","modified":1566352199264},{"_id":"themes/Material-T/layout/category.ejs","hash":"be154b6ee029ab1e10c75c8ab675bdae3562a6b3","modified":1566352199264},{"_id":"themes/Material-T/layout/index.ejs","hash":"642d6b76f7707362c64ed763a4f792a9f3294094","modified":1566352199264},{"_id":"themes/Material-T/layout/layout.ejs","hash":"784bf6aadf3ce5916dc7ee40a8d64fca9205a878","modified":1566352199265},{"_id":"themes/Material-T/layout/post.ejs","hash":"8a82f6d72ccd0424b828d42e8fe17dc3075299a9","modified":1566352199267},{"_id":"themes/Material-T/layout/tag.ejs","hash":"88f38b99188d4f32707e4a6bfac91ac29df9c205","modified":1566352199267},{"_id":"themes/Material-T/layout/tags.ejs","hash":"1fea68fdf6fb7ff0a50e1bb98e23d86953677552","modified":1566352199268},{"_id":"themes/Material-T/scripts/pages.js","hash":"a0672b3ec28030d006a8a02268b2604d5e37188f","modified":1566352199270},{"_id":"themes/Material-T/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1566352177287},{"_id":"themes/Material-T/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1566352177286},{"_id":"themes/Material-T/.git/hooks/fsmonitor-watchman.sample","hash":"f7c0aa40cb0d620ff0bca3efe3521ec79e5d7156","modified":1566352177287},{"_id":"themes/Material-T/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1566352177287},{"_id":"themes/Material-T/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1566352177288},{"_id":"themes/Material-T/.git/hooks/pre-commit.sample","hash":"33729ad4ce51acda35094e581e4088f3167a0af8","modified":1566352177286},{"_id":"themes/Material-T/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1566352177288},{"_id":"themes/Material-T/.git/hooks/pre-rebase.sample","hash":"288efdc0027db4cfd8b7c47c4aeddba09b6ded12","modified":1566352177286},{"_id":"themes/Material-T/.git/hooks/pre-receive.sample","hash":"705a17d259e7896f0082fe2e9f2c0c3b127be5ac","modified":1566352177287},{"_id":"themes/Material-T/.git/hooks/prepare-commit-msg.sample","hash":"2584806ba147152ae005cb675aa4f01d5d068456","modified":1566352177287},{"_id":"themes/Material-T/.git/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1566352177288},{"_id":"themes/Material-T/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1566352177285},{"_id":"themes/Material-T/.git/logs/HEAD","hash":"b64f088f3ee44907d3ba01901fab2ae09faa0826","modified":1566352199244},{"_id":"themes/Material-T/layout/_partial/analytics.ejs","hash":"126896d1721ff6183538aa9284f30cc9349b870e","modified":1566352199258},{"_id":"themes/Material-T/layout/_partial/head.ejs","hash":"6ef4e4ff9bc6a796a48a39355429ea2edb7f5e34","modified":1566352199260},{"_id":"themes/Material-T/layout/_partial/footer.ejs","hash":"6243b7e93a53760b8b2487026eead38b0270b18d","modified":1566352199260},{"_id":"themes/Material-T/layout/_partial/nav.ejs","hash":"dcf368b3280b5066ce0a983ab078f8c8b566b992","modified":1566352199261},{"_id":"themes/Material-T/layout/_partial/paginator.ejs","hash":"cc6534bcb40202925127add67c4e21a7acf1a08d","modified":1566352199261},{"_id":"themes/Material-T/layout/_partial/toc.ejs","hash":"6b3aa82ba9584d9c6819f8f764a092b7f5772389","modified":1566352199262},{"_id":"themes/Material-T/source/css/main.styl","hash":"77d36afdcf8f765fc8655c29eb3b9c2177ffdecf","modified":1566352199285},{"_id":"themes/Material-T/source/img/apple-touch-icon.png","hash":"7e79eceaaab4def3d4b905d1c69dc04d52f18f06","modified":1566352199289},{"_id":"themes/Material-T/source/img/avatar.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":1566352199293},{"_id":"themes/Material-T/source/img/favicon.png","hash":"7e79eceaaab4def3d4b905d1c69dc04d52f18f06","modified":1566352199294},{"_id":"themes/Material-T/source/js/main.js","hash":"0eb803058d0813b069886ada131d2b7e33b39ead","modified":1566352199300},{"_id":"themes/Material-T/source/js/post.js","hash":"b989e6dc7cf84a6e5f952ad724f7c8316116805e","modified":1566352199301},{"_id":"themes/Material-T/source/css/_functions/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1566352199272},{"_id":"themes/Material-T/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1566352199274},{"_id":"themes/Material-T/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1566352199285},{"_id":"themes/Material-T/.git/objects/pack/pack-5d70b67879d27aea3c4868f4a954499ddffa7895.idx","hash":"5f0cff18050513c2bd248a3d6c9582b7e89026f0","modified":1566352199206},{"_id":"themes/Material-T/.git/refs/heads/master","hash":"14833ea611fe93325f8a69f3cd8539d4172b5b5d","modified":1566352199244},{"_id":"themes/Material-T/layout/_partial/comments/disqus.ejs","hash":"1e9aa20022dcae19d0a860c67eceb8f2d62d2605","modified":1566352199259},{"_id":"themes/Material-T/layout/_partial/comments/valine.ejs","hash":"e6f1ac8423e1bf2064c4bed93ed806fef919f3fb","modified":1566352199259},{"_id":"themes/Material-T/source/css/_custom/custom.styl","hash":"3626d8439c27c9bfde008de8a7ba5124bbc7c397","modified":1566352199271},{"_id":"themes/Material-T/source/css/_functions/base.styl","hash":"263f260a09184cbaf17e475fa12abdacbe418f88","modified":1566352199272},{"_id":"themes/Material-T/source/css/_mixins/base.styl","hash":"68caf7cc73fa6211f9802b69293a2a38d7322de7","modified":1566352199273},{"_id":"themes/Material-T/source/css/_pages/pages.styl","hash":"03703ece80dac645607d4731dff3fdd923777d2a","modified":1566352199283},{"_id":"themes/Material-T/source/css/_variables/base.styl","hash":"26ad22c626a9d4210ed71bf60f98a831e6c08638","modified":1566352199284},{"_id":"themes/Material-T/source/img/about.jpg","hash":"2804180ef2c9ceb95745cdd375af25041096a06a","modified":1566352199288},{"_id":"themes/Material-T/source/lib/anchor/anchor.min.js","hash":"0996588202bd062dad6f592615cb4791e1f8be91","modified":1566352199302},{"_id":"themes/Material-T/source/lib/github-markdown/github-markdown.min.css","hash":"7596e53d0288c681f37c3d0ef356eb073d1776af","modified":1566352199345},{"_id":"themes/Material-T/source/lib/nprogress/nprogress.css","hash":"f051ddd1d9849850aab87e28b5183ab7c2b4ecf3","modified":1566352199378},{"_id":"themes/Material-T/source/lib/nprogress/nprogress.min.js","hash":"fd01afe96f6b5f91d7b7da8e07c4fd2f23364b7a","modified":1566352199378},{"_id":"themes/Material-T/source/lib/prettify/github-v2.min.css","hash":"da1b8e6d4df1f044d12f461880e677d65dbbf2d3","modified":1566352199378},{"_id":"themes/Material-T/source/lib/prettify/tomorrow-night-eighties.min.css","hash":"a5f2102fc148359a92435b170f3bfb25e1221837","modified":1566352199379},{"_id":"themes/Material-T/source/lib/prettify/prettify.min.js","hash":"4f49dd6b74ba2c6484d8cee33241976c3392a479","modified":1566352199379},{"_id":"themes/Material-T/source/lib/prettify/tomorrow-night.min.css","hash":"535256d676d247d3282e9a8ae2777c6f7df4fdc6","modified":1566352199380},{"_id":"themes/Material-T/source/lib/prettify/tomorrow.min.css","hash":"ea61879c64ca73a5ea233b1315faf7f2fdfebca9","modified":1566352199380},{"_id":"themes/Material-T/source/lib/tocbot/tocbot.min.js","hash":"bae97e8a24a05a99335f8e725641c8ca9c50502a","modified":1566352199380},{"_id":"themes/Material-T/source/lib/typed/typed.min.js","hash":"e98db7171ade8e557286ac40538670966b8be127","modified":1566352199381},{"_id":"themes/Material-T/source/css/_pages/_archive/archive.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1566352199276},{"_id":"themes/Material-T/source/css/_pages/_category/category.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1566352199279},{"_id":"themes/Material-T/source/css/_pages/_tag/tag.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1566352199282},{"_id":"themes/Material-T/.git/logs/refs/heads/master","hash":"b64f088f3ee44907d3ba01901fab2ae09faa0826","modified":1566352199245},{"_id":"themes/Material-T/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1566352199241},{"_id":"themes/Material-T/source/css/_pages/_about/about.styl","hash":"bbb3107c44240e99528d5f5742dc3233275ab8d1","modified":1566352199275},{"_id":"themes/Material-T/source/css/_pages/_category/categories.styl","hash":"d9626b5495843bcd6d250527014bf20ec13554ac","modified":1566352199278},{"_id":"themes/Material-T/source/css/_pages/_base/base.styl","hash":"06dabf589c5c253379dff9e7bbdb47cdac0db38b","modified":1566352199277},{"_id":"themes/Material-T/source/css/_pages/_index/index.styl","hash":"1f62b555dde51b1fedf6b2f2a2771f4bc7df269b","modified":1566352199279},{"_id":"themes/Material-T/source/css/_pages/_post/post.styl","hash":"6af6c5a3bd2e7bf75ad0d5e5c1de681a9f2a6082","modified":1566352199281},{"_id":"themes/Material-T/source/css/_pages/_tag/tags.styl","hash":"66fe62bd50d6d0683805d7277f5093dfab17f0c0","modified":1566352199283},{"_id":"themes/Material-T/source/img/archive.jpg","hash":"201b829d6ff58f6f282c447e49489b616c139839","modified":1566352199293},{"_id":"themes/Material-T/source/lib/font-awesome/css/all.min.css","hash":"6f4095f66e56d39ef0adefbe85a1dcfc13bd133b","modified":1566352199304},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-regular-400.eot","hash":"2e97930b520222ec3c2e4188ce07cc1904beba48","modified":1566352199322},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-regular-400.ttf","hash":"5eb58f4263f87c543388bf66dec7d1f0b7c5b32c","modified":1566352199325},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-regular-400.woff2","hash":"8b356dc021032d9380af47f7608a6b62a9b6f363","modified":1566352199327},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-regular-400.woff","hash":"38e6bd17442bb34e0e13a2c9bcbc5299f68be173","modified":1566352199326},{"_id":"themes/Material-T/source/lib/mdbootstrap/js/bootstrap.min.js","hash":"6778fed3cf095a318141a31f455c8f4663885bde","modified":1566352199371},{"_id":"themes/Material-T/source/lib/mdbootstrap/js/popper.min.js","hash":"5958a52438c8d753d692b11b5419bd1490c2655b","modified":1566352199377},{"_id":"themes/Material-T/source/img/post.jpg","hash":"548eea5a45017ffc1127e5a1b59ee6a94813939d","modified":1566352199299},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-brands-400.woff2","hash":"9465c5894ca2f93655fa5767b820b762aff6b518","modified":1566352199321},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-brands-400.woff","hash":"2417fe03c7330a5160f070d6ab747a2bc4bbd41b","modified":1566352199320},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-solid-900.woff2","hash":"d378644ff0f7549fa6f217a08dfd2566a770638e","modified":1566352199344},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-solid-900.woff","hash":"5d5d1448b199c38f1b39a49b1e9b3f1381a26cad","modified":1566352199343},{"_id":"themes/Material-T/source/lib/mdbootstrap/js/jquery-3.4.1.min.js","hash":"88523924351bac0b5d560fe0c5781e2556e7693d","modified":1566352199372},{"_id":"themes/Material-T/.git/logs/refs/remotes/origin/HEAD","hash":"b64f088f3ee44907d3ba01901fab2ae09faa0826","modified":1566352199240},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-brands-400.eot","hash":"453e71a65f2958480b74fdb75a53d41068699dbf","modified":1566352199307},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-brands-400.ttf","hash":"3fbe9822118e91350912f51f3080ce4aa9b3ec38","modified":1566352199318},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-regular-400.svg","hash":"f9583bce6740a4125e14d0628ffbd946b7ddfdda","modified":1566352199324},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Bold.eot","hash":"a76cd602f5188b9fbd4ba7443dcb9c064e3dbf10","modified":1566352199351},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Light.eot","hash":"42fe156996197e5eb0c0264c5d1bb3b4681f4595","modified":1566352199355},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Bold.woff2","hash":"933b866d09c2b087707a98dab64b3888865eeb96","modified":1566352199354},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Medium.eot","hash":"1517f4b6e1c5d0e5198f937557253aac8fab0416","modified":1566352199358},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Light.woff2","hash":"bbdc28b887400fcb340b504ec2904993af42a5d7","modified":1566352199358},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Light.woff","hash":"6300f659be9e834ab263efe2fb3c581d48b1e7b2","modified":1566352199357},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Medium.woff2","hash":"6cc1b73571af9e827c4e7e91418f476703cd4c4b","modified":1566352199361},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Regular.eot","hash":"77ae3e980ec03863ebe2587a8ef9ddfd06941db0","modified":1566352199361},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Medium.woff","hash":"d45f84922131364989ad6578c7a06b6b4fc22c34","modified":1566352199360},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Thin.eot","hash":"0790a51a848dbe7292c98f9d0459218bf1a8ffdd","modified":1566352199364},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Regular.woff2","hash":"ed1558b0541f5e01ce48c7db1588371b990eec19","modified":1566352199364},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Regular.woff","hash":"74734dde8d94e7268170f9b994dedfbdcb5b3a15","modified":1566352199363},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Thin.woff","hash":"fbc3e71d456c96667d8082ab910e3946ef89240b","modified":1566352199368},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Thin.woff2","hash":"2449e3dac5ddb7c3da8bb07450493b62d052758c","modified":1566352199369},{"_id":"themes/Material-T/source/lib/mdbootstrap/css/bootstrap.min.css","hash":"6e10354828454898fda80f55f3decb347fd9ed21","modified":1566352199347},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-solid-900.eot","hash":"2b0ebea58a0bc895400dffe8c5e434c8b12338e3","modified":1566352199329},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-solid-900.ttf","hash":"7b280debee5800806092e35a6bc2c6fd9c51cf63","modified":1566352199342},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Bold.woff","hash":"ee99cd87a59a9a5d4092c83232bb3eec67547425","modified":1566352199354},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Light.ttf","hash":"e321c183e2b75ee19813892b7bac8d7c411cb88a","modified":1566352199356},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Medium.ttf","hash":"6060ca726b9760b76f7c347dce9d2fa1fe42ec92","modified":1566352199359},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Regular.ttf","hash":"824b5480c977a8166e177e5357d13164ccc45f47","modified":1566352199362},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Thin.ttf","hash":"173ed64528b4d010a76d8d38deb1d7e7eed58eda","modified":1566352199368},{"_id":"themes/Material-T/source/img/index.jpg","hash":"001440798844e7d6152a5e76b360f8e99782ca75","modified":1566352199296},{"_id":"themes/Material-T/source/lib/mdbootstrap/font/roboto/Roboto-Bold.ttf","hash":"47327df0f35e7cd7c8645874897a7449697544ae","modified":1566352199353},{"_id":"themes/Material-T/source/lib/mdbootstrap/css/mdb.min.css","hash":"62818e7755b098a1c3b503425356570a2c7474d9","modified":1566352199349},{"_id":"themes/Material-T/source/lib/mdbootstrap/js/mdb.min.js","hash":"fef8d611bbc14ad31ca9ec9e2990bfde4d873bb1","modified":1566352199376},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-brands-400.svg","hash":"fcac55c6f9e9993cea6e2ecc729fffc36c7009b2","modified":1566352199315},{"_id":"themes/Material-T/source/lib/font-awesome/webfonts/fa-solid-900.svg","hash":"3d24b0004b9dac32a46622cefa72cb3173b13115","modified":1566352199338},{"_id":"themes/Material-T/.git/objects/pack/pack-5d70b67879d27aea3c4868f4a954499ddffa7895.pack","hash":"af7f8654df01c60baf1c7247dbe7d7476aabd67b","modified":1566352199205}],"Category":[],"Data":[],"Page":[{"_content":"<!DOCTYPE HTML>\n<html>\n<head>\n  <meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8;\"/>\n  <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\" />\n  <meta name=\"robots\" content=\"all\" />\n  <meta name=\"robots\" content=\"index,follow\"/>\n</head>\n<body>\n\n<script type=\"text/javascript\" src=\"http://www.qq.com/404/search_children.js\" charset=\"utf-8\" homePageUrl=\"http://blog.csbzy.com\" homePageName=\"回到我的主页\"></script>\n\n</body>\n</html>\n","source":"404.html","raw":"<!DOCTYPE HTML>\n<html>\n<head>\n  <meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8;\"/>\n  <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\" />\n  <meta name=\"robots\" content=\"all\" />\n  <meta name=\"robots\" content=\"index,follow\"/>\n</head>\n<body>\n\n<script type=\"text/javascript\" src=\"http://www.qq.com/404/search_children.js\" charset=\"utf-8\" homePageUrl=\"http://blog.csbzy.com\" homePageName=\"回到我的主页\"></script>\n\n</body>\n</html>\n","date":"2019-08-21T01:49:04.126Z","updated":"2019-08-21T01:49:04.126Z","path":"404.html","title":"","comments":1,"layout":"page","_id":"cjzkm7pp10000jl9u7ih2p8ob","content":"<!DOCTYPE HTML>\n<html>\n<head>\n  <meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8;\">\n  <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\">\n  <meta name=\"robots\" content=\"all\">\n  <meta name=\"robots\" content=\"index,follow\">\n</head>\n<body>\n\n<script type=\"text/javascript\" src=\"http://www.qq.com/404/search_children.js\" charset=\"utf-8\" homepageurl=\"http://blog.csbzy.com\" homepagename=\"回到我的主页\"></script>\n\n</body>\n</html>\n","site":{"data":{}},"excerpt":"","more":"<!DOCTYPE HTML>\n<html>\n<head>\n  <meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8;\">\n  <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\">\n  <meta name=\"robots\" content=\"all\">\n  <meta name=\"robots\" content=\"index,follow\">\n</head>\n<body>\n\n<script type=\"text/javascript\" src=\"http://www.qq.com/404/search_children.js\" charset=\"utf-8\" homepageurl=\"http://blog.csbzy.com\" homepagename=\"回到我的主页\"></script>\n\n</body>\n</html>\n"},{"title":"tags","date":"2015-10-22T10:26:39.000Z","type":"tags","comment":false,"_content":"","source":"tags/index.md","raw":"title: tags\ndate: 2015-10-22 18:26:39\ntype: \"tags\"\ncomment: false\n---\n","updated":"2019-08-21T01:49:04.133Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cjzkm7prb0020jl9uheu0t9r2","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Cowboy的路由机制","date":"2015-10-22T10:24:56.000Z","_content":"\n路由机制\n=====\n配置链接URL到Erlang模块（处理对应请求的模块）的映射就是路由。\n\n当 Cowboy接收到一个请求时，它会尝试在给定的分发规则中匹配 域名 到对应的资源路径。如果匹配成功，那么对应的Erlang 模块就会被执行。\n\nCowboy首先会匹配域名，接着尝试找到匹配的资源路径。\n\nCowboy会将路由规则编译后，再使用。\n\n\n结构\n=====\n通用的路由结构是这样定义的：\n`Routes= [Host1, Host2, ... HostN].`\n\n每一个域名的匹配规则 包含了 对连接路径的选项约束和路径部件的列表。\n\n`Host1= {HostMatch, PathsList}.`\n`Host2= {HostMatch, Constraints, PathsList}.`\n\n路径部件的定义如下：\n`PathsList= [Path1, Path2, ... PathN].`\n\n最后，每一路径包含了该路径自身的匹配规则以及对应的处理模块\n`Path1= {PathMatch, Handler, Opts}.`\n`Path2= {PathMatch, Constraints, Handler, Opts}.`\n\n匹配规则语法\n=====\n匹配语法规则用于标识 域名到路径间的处理handlers。\n域名的语法规则：\n`HostMatch1= \"cowboy.example.org\".`\n`HostMatch2= \"cowboy.example.org.\".`\n`HostMatch3= \".cowboy.example.org\".`\n\n路径的语法规则：\n`PathMatch= \"/hats/:name/prices\".`\n`HostMatch= \":subdomain.example.org\".`\n\n此外，还可以将域名的某一字段保存到Req对象中，再后续可以使用，这就是值绑定。\n`PathMatch= \"/hats/:name/prices\".`\n`HostMatch= \":subdomain.example.org\".`\n比如，http://test.example.org/hats/wild_cowboy_legendary/prices 将会\n把test绑定到subdomain，而wild_cowboy_legendary就会绑定到name，它们可以被cow_req:binding/{2,3}中检索，绑定的名字必须是一个atom\n'_'：表示匹配任何内容\n\n约束\n=====\n匹配域名和路径完成后，就会检测是否满足可选的约束，约束如下：\n```erlang\n{Name, int}\n{Name, function, fun ((Value) -> true | {true, NewValue} | false)}\n```\nint 约束将会检查 绑定的二进制串是一个int，或可被转化成一个int\nfunction约束，将会调用给定的约束函数并且返回结果，给定函数必须自己保证不会崩溃的。\n\n\n为了保存Cowboy可以更高效地查找正确的handler模块，Cowboy会编译定义好的路由分发规则。\n编译的方法是：cowboy_router:compile/1.\n```erlang\n\tDispatch= cowboy_router:compile([\n    %% {HostMatch, list({PathMatch, Handler, Opts})}\n    {'_', [{'_', my_handler, []}]}\n\t]),\n\t%% Name, NbAcceptors, TransOpts, ProtoOpts\n\tcowboy:start_http(my_http_listener, 100,\n   \t[{port, 8080}],\n   \t[{env, [{dispatch, Dispatch}]}]\n\t).\n```\n如果定义好的路由分发规则有错误，cowboy_router:compile/1 \n将会返回{error, badarg}\n\n在线更新路由规则\n=====\n通过 cowboy:set_env/3更新路由的分发规则，连接监听模块接受新的连接时就会使用新的路由分发规则。\n```erlang\n    cowboy:set_env(my_http_listener, dispatch,\n    cowboy_router:compile(Dispatch)).\n```\n\n\n\n\n","source":"_posts/Cowboy的路由机制.md","raw":"title: Cowboy的路由机制\ndate: 2015-10-22 18:24:56\ntags: [Cowboy]\n---\n\n路由机制\n=====\n配置链接URL到Erlang模块（处理对应请求的模块）的映射就是路由。\n\n当 Cowboy接收到一个请求时，它会尝试在给定的分发规则中匹配 域名 到对应的资源路径。如果匹配成功，那么对应的Erlang 模块就会被执行。\n\nCowboy首先会匹配域名，接着尝试找到匹配的资源路径。\n\nCowboy会将路由规则编译后，再使用。\n\n\n结构\n=====\n通用的路由结构是这样定义的：\n`Routes= [Host1, Host2, ... HostN].`\n\n每一个域名的匹配规则 包含了 对连接路径的选项约束和路径部件的列表。\n\n`Host1= {HostMatch, PathsList}.`\n`Host2= {HostMatch, Constraints, PathsList}.`\n\n路径部件的定义如下：\n`PathsList= [Path1, Path2, ... PathN].`\n\n最后，每一路径包含了该路径自身的匹配规则以及对应的处理模块\n`Path1= {PathMatch, Handler, Opts}.`\n`Path2= {PathMatch, Constraints, Handler, Opts}.`\n\n匹配规则语法\n=====\n匹配语法规则用于标识 域名到路径间的处理handlers。\n域名的语法规则：\n`HostMatch1= \"cowboy.example.org\".`\n`HostMatch2= \"cowboy.example.org.\".`\n`HostMatch3= \".cowboy.example.org\".`\n\n路径的语法规则：\n`PathMatch= \"/hats/:name/prices\".`\n`HostMatch= \":subdomain.example.org\".`\n\n此外，还可以将域名的某一字段保存到Req对象中，再后续可以使用，这就是值绑定。\n`PathMatch= \"/hats/:name/prices\".`\n`HostMatch= \":subdomain.example.org\".`\n比如，http://test.example.org/hats/wild_cowboy_legendary/prices 将会\n把test绑定到subdomain，而wild_cowboy_legendary就会绑定到name，它们可以被cow_req:binding/{2,3}中检索，绑定的名字必须是一个atom\n'_'：表示匹配任何内容\n\n约束\n=====\n匹配域名和路径完成后，就会检测是否满足可选的约束，约束如下：\n```erlang\n{Name, int}\n{Name, function, fun ((Value) -> true | {true, NewValue} | false)}\n```\nint 约束将会检查 绑定的二进制串是一个int，或可被转化成一个int\nfunction约束，将会调用给定的约束函数并且返回结果，给定函数必须自己保证不会崩溃的。\n\n\n为了保存Cowboy可以更高效地查找正确的handler模块，Cowboy会编译定义好的路由分发规则。\n编译的方法是：cowboy_router:compile/1.\n```erlang\n\tDispatch= cowboy_router:compile([\n    %% {HostMatch, list({PathMatch, Handler, Opts})}\n    {'_', [{'_', my_handler, []}]}\n\t]),\n\t%% Name, NbAcceptors, TransOpts, ProtoOpts\n\tcowboy:start_http(my_http_listener, 100,\n   \t[{port, 8080}],\n   \t[{env, [{dispatch, Dispatch}]}]\n\t).\n```\n如果定义好的路由分发规则有错误，cowboy_router:compile/1 \n将会返回{error, badarg}\n\n在线更新路由规则\n=====\n通过 cowboy:set_env/3更新路由的分发规则，连接监听模块接受新的连接时就会使用新的路由分发规则。\n```erlang\n    cowboy:set_env(my_http_listener, dispatch,\n    cowboy_router:compile(Dispatch)).\n```\n\n\n\n\n","slug":"Cowboy的路由机制","published":1,"updated":"2019-08-21T01:49:04.127Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzkm7ppv0001jl9u6ujvzyrk","content":"<h1 id=\"路由机制\"><a href=\"#路由机制\" class=\"headerlink\" title=\"路由机制\"></a>路由机制</h1><p>配置链接URL到Erlang模块（处理对应请求的模块）的映射就是路由。</p>\n<p>当 Cowboy接收到一个请求时，它会尝试在给定的分发规则中匹配 域名 到对应的资源路径。如果匹配成功，那么对应的Erlang 模块就会被执行。</p>\n<p>Cowboy首先会匹配域名，接着尝试找到匹配的资源路径。</p>\n<p>Cowboy会将路由规则编译后，再使用。</p>\n<h1 id=\"结构\"><a href=\"#结构\" class=\"headerlink\" title=\"结构\"></a>结构</h1><p>通用的路由结构是这样定义的：<br><code>Routes= [Host1, Host2, ... HostN].</code></p>\n<p>每一个域名的匹配规则 包含了 对连接路径的选项约束和路径部件的列表。</p>\n<p><code>Host1= {HostMatch, PathsList}.</code><br><code>Host2= {HostMatch, Constraints, PathsList}.</code></p>\n<p>路径部件的定义如下：<br><code>PathsList= [Path1, Path2, ... PathN].</code></p>\n<p>最后，每一路径包含了该路径自身的匹配规则以及对应的处理模块<br><code>Path1= {PathMatch, Handler, Opts}.</code><br><code>Path2= {PathMatch, Constraints, Handler, Opts}.</code></p>\n<h1 id=\"匹配规则语法\"><a href=\"#匹配规则语法\" class=\"headerlink\" title=\"匹配规则语法\"></a>匹配规则语法</h1><p>匹配语法规则用于标识 域名到路径间的处理handlers。<br>域名的语法规则：<br><code>HostMatch1= &quot;cowboy.example.org&quot;.</code><br><code>HostMatch2= &quot;cowboy.example.org.&quot;.</code><br><code>HostMatch3= &quot;.cowboy.example.org&quot;.</code></p>\n<p>路径的语法规则：<br><code>PathMatch= &quot;/hats/:name/prices&quot;.</code><br><code>HostMatch= &quot;:subdomain.example.org&quot;.</code></p>\n<p>此外，还可以将域名的某一字段保存到Req对象中，再后续可以使用，这就是值绑定。<br><code>PathMatch= &quot;/hats/:name/prices&quot;.</code><br><code>HostMatch= &quot;:subdomain.example.org&quot;.</code><br>比如，<a href=\"http://test.example.org/hats/wild_cowboy_legendary/prices\" target=\"_blank\" rel=\"noopener\">http://test.example.org/hats/wild_cowboy_legendary/prices</a> 将会<br>把test绑定到subdomain，而wild_cowboy_legendary就会绑定到name，它们可以被cow_req:binding/{2,3}中检索，绑定的名字必须是一个atom<br>‘_’：表示匹配任何内容</p>\n<h1 id=\"约束\"><a href=\"#约束\" class=\"headerlink\" title=\"约束\"></a>约束</h1><p>匹配域名和路径完成后，就会检测是否满足可选的约束，约束如下：</p>\n<pre><code class=\"erlang\">{Name, int}\n{Name, function, fun ((Value) -&gt; true | {true, NewValue} | false)}\n</code></pre>\n<p>int 约束将会检查 绑定的二进制串是一个int，或可被转化成一个int<br>function约束，将会调用给定的约束函数并且返回结果，给定函数必须自己保证不会崩溃的。</p>\n<p>为了保存Cowboy可以更高效地查找正确的handler模块，Cowboy会编译定义好的路由分发规则。<br>编译的方法是：cowboy_router:compile/1.</p>\n<pre><code class=\"erlang\">    Dispatch= cowboy_router:compile([\n    %% {HostMatch, list({PathMatch, Handler, Opts})}\n    {&#39;_&#39;, [{&#39;_&#39;, my_handler, []}]}\n    ]),\n    %% Name, NbAcceptors, TransOpts, ProtoOpts\n    cowboy:start_http(my_http_listener, 100,\n       [{port, 8080}],\n       [{env, [{dispatch, Dispatch}]}]\n    ).\n</code></pre>\n<p>如果定义好的路由分发规则有错误，cowboy_router:compile/1<br>将会返回{error, badarg}</p>\n<h1 id=\"在线更新路由规则\"><a href=\"#在线更新路由规则\" class=\"headerlink\" title=\"在线更新路由规则\"></a>在线更新路由规则</h1><p>通过 cowboy:set_env/3更新路由的分发规则，连接监听模块接受新的连接时就会使用新的路由分发规则。</p>\n<pre><code class=\"erlang\">    cowboy:set_env(my_http_listener, dispatch,\n    cowboy_router:compile(Dispatch)).\n</code></pre>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"路由机制\"><a href=\"#路由机制\" class=\"headerlink\" title=\"路由机制\"></a>路由机制</h1><p>配置链接URL到Erlang模块（处理对应请求的模块）的映射就是路由。</p>\n<p>当 Cowboy接收到一个请求时，它会尝试在给定的分发规则中匹配 域名 到对应的资源路径。如果匹配成功，那么对应的Erlang 模块就会被执行。</p>\n<p>Cowboy首先会匹配域名，接着尝试找到匹配的资源路径。</p>\n<p>Cowboy会将路由规则编译后，再使用。</p>\n<h1 id=\"结构\"><a href=\"#结构\" class=\"headerlink\" title=\"结构\"></a>结构</h1><p>通用的路由结构是这样定义的：<br><code>Routes= [Host1, Host2, ... HostN].</code></p>\n<p>每一个域名的匹配规则 包含了 对连接路径的选项约束和路径部件的列表。</p>\n<p><code>Host1= {HostMatch, PathsList}.</code><br><code>Host2= {HostMatch, Constraints, PathsList}.</code></p>\n<p>路径部件的定义如下：<br><code>PathsList= [Path1, Path2, ... PathN].</code></p>\n<p>最后，每一路径包含了该路径自身的匹配规则以及对应的处理模块<br><code>Path1= {PathMatch, Handler, Opts}.</code><br><code>Path2= {PathMatch, Constraints, Handler, Opts}.</code></p>\n<h1 id=\"匹配规则语法\"><a href=\"#匹配规则语法\" class=\"headerlink\" title=\"匹配规则语法\"></a>匹配规则语法</h1><p>匹配语法规则用于标识 域名到路径间的处理handlers。<br>域名的语法规则：<br><code>HostMatch1= &quot;cowboy.example.org&quot;.</code><br><code>HostMatch2= &quot;cowboy.example.org.&quot;.</code><br><code>HostMatch3= &quot;.cowboy.example.org&quot;.</code></p>\n<p>路径的语法规则：<br><code>PathMatch= &quot;/hats/:name/prices&quot;.</code><br><code>HostMatch= &quot;:subdomain.example.org&quot;.</code></p>\n<p>此外，还可以将域名的某一字段保存到Req对象中，再后续可以使用，这就是值绑定。<br><code>PathMatch= &quot;/hats/:name/prices&quot;.</code><br><code>HostMatch= &quot;:subdomain.example.org&quot;.</code><br>比如，<a href=\"http://test.example.org/hats/wild_cowboy_legendary/prices\" target=\"_blank\" rel=\"noopener\">http://test.example.org/hats/wild_cowboy_legendary/prices</a> 将会<br>把test绑定到subdomain，而wild_cowboy_legendary就会绑定到name，它们可以被cow_req:binding/{2,3}中检索，绑定的名字必须是一个atom<br>‘_’：表示匹配任何内容</p>\n<h1 id=\"约束\"><a href=\"#约束\" class=\"headerlink\" title=\"约束\"></a>约束</h1><p>匹配域名和路径完成后，就会检测是否满足可选的约束，约束如下：</p>\n<pre><code class=\"erlang\">{Name, int}\n{Name, function, fun ((Value) -&gt; true | {true, NewValue} | false)}\n</code></pre>\n<p>int 约束将会检查 绑定的二进制串是一个int，或可被转化成一个int<br>function约束，将会调用给定的约束函数并且返回结果，给定函数必须自己保证不会崩溃的。</p>\n<p>为了保存Cowboy可以更高效地查找正确的handler模块，Cowboy会编译定义好的路由分发规则。<br>编译的方法是：cowboy_router:compile/1.</p>\n<pre><code class=\"erlang\">    Dispatch= cowboy_router:compile([\n    %% {HostMatch, list({PathMatch, Handler, Opts})}\n    {&#39;_&#39;, [{&#39;_&#39;, my_handler, []}]}\n    ]),\n    %% Name, NbAcceptors, TransOpts, ProtoOpts\n    cowboy:start_http(my_http_listener, 100,\n       [{port, 8080}],\n       [{env, [{dispatch, Dispatch}]}]\n    ).\n</code></pre>\n<p>如果定义好的路由分发规则有错误，cowboy_router:compile/1<br>将会返回{error, badarg}</p>\n<h1 id=\"在线更新路由规则\"><a href=\"#在线更新路由规则\" class=\"headerlink\" title=\"在线更新路由规则\"></a>在线更新路由规则</h1><p>通过 cowboy:set_env/3更新路由的分发规则，连接监听模块接受新的连接时就会使用新的路由分发规则。</p>\n<pre><code class=\"erlang\">    cowboy:set_env(my_http_listener, dispatch,\n    cowboy_router:compile(Dispatch)).\n</code></pre>\n"},{"title":"Erlang_Efficiency_guide_非标准笔记","date":"2015-10-24T06:27:28.000Z","_content":"Efficiency guide 译文\n===\n\ntimer模块\n====\n通过`erlang:send_after/3` 或`erlang:start_timer/3` 来启动一个定时器会比使用timer模块更加有效率。timer模块使用一个独立的进程来管理定时器，因此该进程很容易过载，如果很多进程频繁创建或取消定时器。\n\n`list_to_atom/1`\n====\nAtoms 是不参与垃圾回收的。一旦一个原子被创建，它将不会被回收，Erlang虚拟机会因为atoms数量太多（默认1048576）而导致崩溃。\n因此，转换输入的字符参数变成atom会导致系统变得不安全。如果只允许已经定义的原子可以允许被转换，可以使用 `list_to_existing_atom/1`去避免服务器崩溃。（这就使得我们需要提前创建所有允许被创建的atiom\n\n`length/1`\n====\n执行`length/1`所消耗的时间是与输入列表的长度成比例增长的。而 `erlang:tuple_size/1`、`byte_size/1`、和`bit_size/1`的执行时间是常量时间。因此避免对长度过长的list进行`leng/1`运算。一些对`length/1`的使用可以被替换成模式匹配，比如：\n    foo(L) when length(L) >=3 -> .....\n可以替换为\n    foo([_,_,_|_]=L)->....\n另外对不使用的变量命名为`_`也可以提升程序效率。\n\n`setelement/3`\n====\n`setelement/3`复制它修改的元祖，因此，在循环中调用`setelement/3`将会每次都创建新的副本。如果无法优化循环调用`setelement/3`的代码，那么对一个大tuple修改多个元素的最优办法就是将tuple转换为list修改list后再转换会tuple。\n\n`size/1`\n====\n`size/1`可以返回tuple或binary的大小。使用 BIFs `tuple_size/1`和 `byte_size/1`可以让编译器和运行时系统去优化性能。\n\n`split_binary/2`\n====\n通过模式匹配来切分binary会比调用`split_binary/2`来的快。另外，混合比特语法匹配和split_binary/2 会阻止一些对对比特语法匹配的优化。\n这样：\n    \"  Bin1:Num/binary,Bin2/binary  \" =Bin`\n而不要：\n    {Bin1,Bin2}=split_binary(Bin,Num)\n\n'--'操作符\n====\n列表的长度越长，`--`的效率就越低。\n不要：\n    HugeList1 -- HugeList2\n而是这样(对列表元素没有顺序要求的列表使用）：\n    HugeSet1 = ordsets:from_list(HugeList1),\n    HugeSet2 = ordsets:from_list(HugeList2),\n    ordsets:subtract(HugeSet1,HugeSet2)\n对于对列表元素有顺序要求的列表：\n`    Set=gb_sets:from_list(HugeList2),\n    [E|| E 《-HugeList1, not gb_sets:is_element(E，Set)]`\n\nbinaries 是如何被实例化的\n====\n在内部来说，binaries和bitstring是一样的东西。\n在虚拟机内部有四种类型的binary对象。有两种包含了binary数据，另外两种仅仅只是引用了binary的一部分。而binary容器是 引用binaries（引用计数binaries的缩写）和堆binaries（heap binaries）。\n- Refc binaries 包含两部分：\n  1.一个保存在进程堆的（process heap）对象，即ProcBin,所有的ProcBin都是进程链接的一部分，因此gc 会追踪它们，并且在ProcBin消失后减少引用次数。\n  2.保存在所有进程堆之外的binary对象，binary对象可以被任意个ProcBins（任意个进程中）引用，它包含了引用计数器用来计算当前引用的数量，当引用数量为0时就会被回收。\n- Heap binaries 是小binaries，最大为64字节。所以直接保存在程序的堆中。它将会在进程gc或当作消息发送时被复制，gc不需要任何的处理就可以回收。\n有两种类型的引用对象可以引用 一个refc binary 或 heap binary，它们就是 sub binaries 和 匹配文本。\nsub binaries 由 `split_binary/2` 创建或者匹配到一个binary时。sun binaries 只是引用了其他binaries的一部分（refc binaries 或heap binary），因此匹配binaries是非常廉价的，因为他不会发生任何的拷贝。\n上下文匹配和sub binary类似，不同的是对binary 匹配做了优化；举个例子，它包含了一个直接指向binary数据的指针。\n\n构造二进制\n====\n运行时系统特别对附加binary作了优化，举个例子：\n    Bin0= \"  0 \",  %%为变量Bin0绑定一个heap binary，\n    Bin1=\"  Bin0/binary,1,2,3  \"  %%创建一个refc binary 其内容是Bin0的副本，refc binary的ProcBin部分拥有数据的大小（数据存储到二进制中的大小），binary object 却会有额外的空间被开辟，binary object的大小可能是 Bin0的两倍或者是256（或者更大）。\n    Bin2 =\" Bin1/binary,4,5,6\"\n\n\n\n","source":"_posts/Erlang-Efficiency-guide-非标准笔记.md","raw":"title: Erlang_Efficiency_guide_非标准笔记\ndate: 2015-10-24 14:27:28\ntags: [Erlang]\n---\nEfficiency guide 译文\n===\n\ntimer模块\n====\n通过`erlang:send_after/3` 或`erlang:start_timer/3` 来启动一个定时器会比使用timer模块更加有效率。timer模块使用一个独立的进程来管理定时器，因此该进程很容易过载，如果很多进程频繁创建或取消定时器。\n\n`list_to_atom/1`\n====\nAtoms 是不参与垃圾回收的。一旦一个原子被创建，它将不会被回收，Erlang虚拟机会因为atoms数量太多（默认1048576）而导致崩溃。\n因此，转换输入的字符参数变成atom会导致系统变得不安全。如果只允许已经定义的原子可以允许被转换，可以使用 `list_to_existing_atom/1`去避免服务器崩溃。（这就使得我们需要提前创建所有允许被创建的atiom\n\n`length/1`\n====\n执行`length/1`所消耗的时间是与输入列表的长度成比例增长的。而 `erlang:tuple_size/1`、`byte_size/1`、和`bit_size/1`的执行时间是常量时间。因此避免对长度过长的list进行`leng/1`运算。一些对`length/1`的使用可以被替换成模式匹配，比如：\n    foo(L) when length(L) >=3 -> .....\n可以替换为\n    foo([_,_,_|_]=L)->....\n另外对不使用的变量命名为`_`也可以提升程序效率。\n\n`setelement/3`\n====\n`setelement/3`复制它修改的元祖，因此，在循环中调用`setelement/3`将会每次都创建新的副本。如果无法优化循环调用`setelement/3`的代码，那么对一个大tuple修改多个元素的最优办法就是将tuple转换为list修改list后再转换会tuple。\n\n`size/1`\n====\n`size/1`可以返回tuple或binary的大小。使用 BIFs `tuple_size/1`和 `byte_size/1`可以让编译器和运行时系统去优化性能。\n\n`split_binary/2`\n====\n通过模式匹配来切分binary会比调用`split_binary/2`来的快。另外，混合比特语法匹配和split_binary/2 会阻止一些对对比特语法匹配的优化。\n这样：\n    \"  Bin1:Num/binary,Bin2/binary  \" =Bin`\n而不要：\n    {Bin1,Bin2}=split_binary(Bin,Num)\n\n'--'操作符\n====\n列表的长度越长，`--`的效率就越低。\n不要：\n    HugeList1 -- HugeList2\n而是这样(对列表元素没有顺序要求的列表使用）：\n    HugeSet1 = ordsets:from_list(HugeList1),\n    HugeSet2 = ordsets:from_list(HugeList2),\n    ordsets:subtract(HugeSet1,HugeSet2)\n对于对列表元素有顺序要求的列表：\n`    Set=gb_sets:from_list(HugeList2),\n    [E|| E 《-HugeList1, not gb_sets:is_element(E，Set)]`\n\nbinaries 是如何被实例化的\n====\n在内部来说，binaries和bitstring是一样的东西。\n在虚拟机内部有四种类型的binary对象。有两种包含了binary数据，另外两种仅仅只是引用了binary的一部分。而binary容器是 引用binaries（引用计数binaries的缩写）和堆binaries（heap binaries）。\n- Refc binaries 包含两部分：\n  1.一个保存在进程堆的（process heap）对象，即ProcBin,所有的ProcBin都是进程链接的一部分，因此gc 会追踪它们，并且在ProcBin消失后减少引用次数。\n  2.保存在所有进程堆之外的binary对象，binary对象可以被任意个ProcBins（任意个进程中）引用，它包含了引用计数器用来计算当前引用的数量，当引用数量为0时就会被回收。\n- Heap binaries 是小binaries，最大为64字节。所以直接保存在程序的堆中。它将会在进程gc或当作消息发送时被复制，gc不需要任何的处理就可以回收。\n有两种类型的引用对象可以引用 一个refc binary 或 heap binary，它们就是 sub binaries 和 匹配文本。\nsub binaries 由 `split_binary/2` 创建或者匹配到一个binary时。sun binaries 只是引用了其他binaries的一部分（refc binaries 或heap binary），因此匹配binaries是非常廉价的，因为他不会发生任何的拷贝。\n上下文匹配和sub binary类似，不同的是对binary 匹配做了优化；举个例子，它包含了一个直接指向binary数据的指针。\n\n构造二进制\n====\n运行时系统特别对附加binary作了优化，举个例子：\n    Bin0= \"  0 \",  %%为变量Bin0绑定一个heap binary，\n    Bin1=\"  Bin0/binary,1,2,3  \"  %%创建一个refc binary 其内容是Bin0的副本，refc binary的ProcBin部分拥有数据的大小（数据存储到二进制中的大小），binary object 却会有额外的空间被开辟，binary object的大小可能是 Bin0的两倍或者是256（或者更大）。\n    Bin2 =\" Bin1/binary,4,5,6\"\n\n\n\n","slug":"Erlang-Efficiency-guide-非标准笔记","published":1,"updated":"2019-08-21T01:49:04.127Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzkm7ppz0002jl9uidm2xk2w","content":"<h1 id=\"Efficiency-guide-译文\"><a href=\"#Efficiency-guide-译文\" class=\"headerlink\" title=\"Efficiency guide 译文\"></a>Efficiency guide 译文</h1><h1 id=\"timer模块\"><a href=\"#timer模块\" class=\"headerlink\" title=\"timer模块\"></a>timer模块</h1><p>通过<code>erlang:send_after/3</code> 或<code>erlang:start_timer/3</code> 来启动一个定时器会比使用timer模块更加有效率。timer模块使用一个独立的进程来管理定时器，因此该进程很容易过载，如果很多进程频繁创建或取消定时器。</p>\n<h1 id=\"list-to-atom-1\"><a href=\"#list-to-atom-1\" class=\"headerlink\" title=\"list_to_atom/1\"></a><code>list_to_atom/1</code></h1><p>Atoms 是不参与垃圾回收的。一旦一个原子被创建，它将不会被回收，Erlang虚拟机会因为atoms数量太多（默认1048576）而导致崩溃。<br>因此，转换输入的字符参数变成atom会导致系统变得不安全。如果只允许已经定义的原子可以允许被转换，可以使用 <code>list_to_existing_atom/1</code>去避免服务器崩溃。（这就使得我们需要提前创建所有允许被创建的atiom</p>\n<h1 id=\"length-1\"><a href=\"#length-1\" class=\"headerlink\" title=\"length/1\"></a><code>length/1</code></h1><p>执行<code>length/1</code>所消耗的时间是与输入列表的长度成比例增长的。而 <code>erlang:tuple_size/1</code>、<code>byte_size/1</code>、和<code>bit_size/1</code>的执行时间是常量时间。因此避免对长度过长的list进行<code>leng/1</code>运算。一些对<code>length/1</code>的使用可以被替换成模式匹配，比如：<br>    foo(L) when length(L) &gt;=3 -&gt; …..<br>可以替换为<br>    foo([_,_,_|<em>]=L)-&gt;….<br>另外对不使用的变量命名为`</em>`也可以提升程序效率。</p>\n<h1 id=\"setelement-3\"><a href=\"#setelement-3\" class=\"headerlink\" title=\"setelement/3\"></a><code>setelement/3</code></h1><p><code>setelement/3</code>复制它修改的元祖，因此，在循环中调用<code>setelement/3</code>将会每次都创建新的副本。如果无法优化循环调用<code>setelement/3</code>的代码，那么对一个大tuple修改多个元素的最优办法就是将tuple转换为list修改list后再转换会tuple。</p>\n<h1 id=\"size-1\"><a href=\"#size-1\" class=\"headerlink\" title=\"size/1\"></a><code>size/1</code></h1><p><code>size/1</code>可以返回tuple或binary的大小。使用 BIFs <code>tuple_size/1</code>和 <code>byte_size/1</code>可以让编译器和运行时系统去优化性能。</p>\n<h1 id=\"split-binary-2\"><a href=\"#split-binary-2\" class=\"headerlink\" title=\"split_binary/2\"></a><code>split_binary/2</code></h1><p>通过模式匹配来切分binary会比调用<code>split_binary/2</code>来的快。另外，混合比特语法匹配和split_binary/2 会阻止一些对对比特语法匹配的优化。<br>这样：<br>    “  Bin1:Num/binary,Bin2/binary  “ =Bin`<br>而不要：<br>    {Bin1,Bin2}=split_binary(Bin,Num)</p>\n<h1 id=\"‘–’操作符\"><a href=\"#‘–’操作符\" class=\"headerlink\" title=\"‘–’操作符\"></a>‘–’操作符</h1><p>列表的长度越长，<code>--</code>的效率就越低。<br>不要：<br>    HugeList1 – HugeList2<br>而是这样(对列表元素没有顺序要求的列表使用）：<br>    HugeSet1 = ordsets:from_list(HugeList1),<br>    HugeSet2 = ordsets:from_list(HugeList2),<br>    ordsets:subtract(HugeSet1,HugeSet2)<br>对于对列表元素有顺序要求的列表：<br><code>Set=gb_sets:from_list(HugeList2),\n    [E|| E 《-HugeList1, not gb_sets:is_element(E，Set)]</code></p>\n<h1 id=\"binaries-是如何被实例化的\"><a href=\"#binaries-是如何被实例化的\" class=\"headerlink\" title=\"binaries 是如何被实例化的\"></a>binaries 是如何被实例化的</h1><p>在内部来说，binaries和bitstring是一样的东西。<br>在虚拟机内部有四种类型的binary对象。有两种包含了binary数据，另外两种仅仅只是引用了binary的一部分。而binary容器是 引用binaries（引用计数binaries的缩写）和堆binaries（heap binaries）。</p>\n<ul>\n<li>Refc binaries 包含两部分：<br>1.一个保存在进程堆的（process heap）对象，即ProcBin,所有的ProcBin都是进程链接的一部分，因此gc 会追踪它们，并且在ProcBin消失后减少引用次数。<br>2.保存在所有进程堆之外的binary对象，binary对象可以被任意个ProcBins（任意个进程中）引用，它包含了引用计数器用来计算当前引用的数量，当引用数量为0时就会被回收。</li>\n<li>Heap binaries 是小binaries，最大为64字节。所以直接保存在程序的堆中。它将会在进程gc或当作消息发送时被复制，gc不需要任何的处理就可以回收。<br>有两种类型的引用对象可以引用 一个refc binary 或 heap binary，它们就是 sub binaries 和 匹配文本。<br>sub binaries 由 <code>split_binary/2</code> 创建或者匹配到一个binary时。sun binaries 只是引用了其他binaries的一部分（refc binaries 或heap binary），因此匹配binaries是非常廉价的，因为他不会发生任何的拷贝。<br>上下文匹配和sub binary类似，不同的是对binary 匹配做了优化；举个例子，它包含了一个直接指向binary数据的指针。</li>\n</ul>\n<h1 id=\"构造二进制\"><a href=\"#构造二进制\" class=\"headerlink\" title=\"构造二进制\"></a>构造二进制</h1><p>运行时系统特别对附加binary作了优化，举个例子：<br>    Bin0= “  0 “,  %%为变量Bin0绑定一个heap binary，<br>    Bin1=”  Bin0/binary,1,2,3  “  %%创建一个refc binary 其内容是Bin0的副本，refc binary的ProcBin部分拥有数据的大小（数据存储到二进制中的大小），binary object 却会有额外的空间被开辟，binary object的大小可能是 Bin0的两倍或者是256（或者更大）。<br>    Bin2 =” Bin1/binary,4,5,6”</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Efficiency-guide-译文\"><a href=\"#Efficiency-guide-译文\" class=\"headerlink\" title=\"Efficiency guide 译文\"></a>Efficiency guide 译文</h1><h1 id=\"timer模块\"><a href=\"#timer模块\" class=\"headerlink\" title=\"timer模块\"></a>timer模块</h1><p>通过<code>erlang:send_after/3</code> 或<code>erlang:start_timer/3</code> 来启动一个定时器会比使用timer模块更加有效率。timer模块使用一个独立的进程来管理定时器，因此该进程很容易过载，如果很多进程频繁创建或取消定时器。</p>\n<h1 id=\"list-to-atom-1\"><a href=\"#list-to-atom-1\" class=\"headerlink\" title=\"list_to_atom/1\"></a><code>list_to_atom/1</code></h1><p>Atoms 是不参与垃圾回收的。一旦一个原子被创建，它将不会被回收，Erlang虚拟机会因为atoms数量太多（默认1048576）而导致崩溃。<br>因此，转换输入的字符参数变成atom会导致系统变得不安全。如果只允许已经定义的原子可以允许被转换，可以使用 <code>list_to_existing_atom/1</code>去避免服务器崩溃。（这就使得我们需要提前创建所有允许被创建的atiom</p>\n<h1 id=\"length-1\"><a href=\"#length-1\" class=\"headerlink\" title=\"length/1\"></a><code>length/1</code></h1><p>执行<code>length/1</code>所消耗的时间是与输入列表的长度成比例增长的。而 <code>erlang:tuple_size/1</code>、<code>byte_size/1</code>、和<code>bit_size/1</code>的执行时间是常量时间。因此避免对长度过长的list进行<code>leng/1</code>运算。一些对<code>length/1</code>的使用可以被替换成模式匹配，比如：<br>    foo(L) when length(L) &gt;=3 -&gt; …..<br>可以替换为<br>    foo([_,_,_|<em>]=L)-&gt;….<br>另外对不使用的变量命名为`</em>`也可以提升程序效率。</p>\n<h1 id=\"setelement-3\"><a href=\"#setelement-3\" class=\"headerlink\" title=\"setelement/3\"></a><code>setelement/3</code></h1><p><code>setelement/3</code>复制它修改的元祖，因此，在循环中调用<code>setelement/3</code>将会每次都创建新的副本。如果无法优化循环调用<code>setelement/3</code>的代码，那么对一个大tuple修改多个元素的最优办法就是将tuple转换为list修改list后再转换会tuple。</p>\n<h1 id=\"size-1\"><a href=\"#size-1\" class=\"headerlink\" title=\"size/1\"></a><code>size/1</code></h1><p><code>size/1</code>可以返回tuple或binary的大小。使用 BIFs <code>tuple_size/1</code>和 <code>byte_size/1</code>可以让编译器和运行时系统去优化性能。</p>\n<h1 id=\"split-binary-2\"><a href=\"#split-binary-2\" class=\"headerlink\" title=\"split_binary/2\"></a><code>split_binary/2</code></h1><p>通过模式匹配来切分binary会比调用<code>split_binary/2</code>来的快。另外，混合比特语法匹配和split_binary/2 会阻止一些对对比特语法匹配的优化。<br>这样：<br>    “  Bin1:Num/binary,Bin2/binary  “ =Bin`<br>而不要：<br>    {Bin1,Bin2}=split_binary(Bin,Num)</p>\n<h1 id=\"‘–’操作符\"><a href=\"#‘–’操作符\" class=\"headerlink\" title=\"‘–’操作符\"></a>‘–’操作符</h1><p>列表的长度越长，<code>--</code>的效率就越低。<br>不要：<br>    HugeList1 – HugeList2<br>而是这样(对列表元素没有顺序要求的列表使用）：<br>    HugeSet1 = ordsets:from_list(HugeList1),<br>    HugeSet2 = ordsets:from_list(HugeList2),<br>    ordsets:subtract(HugeSet1,HugeSet2)<br>对于对列表元素有顺序要求的列表：<br><code>Set=gb_sets:from_list(HugeList2),\n    [E|| E 《-HugeList1, not gb_sets:is_element(E，Set)]</code></p>\n<h1 id=\"binaries-是如何被实例化的\"><a href=\"#binaries-是如何被实例化的\" class=\"headerlink\" title=\"binaries 是如何被实例化的\"></a>binaries 是如何被实例化的</h1><p>在内部来说，binaries和bitstring是一样的东西。<br>在虚拟机内部有四种类型的binary对象。有两种包含了binary数据，另外两种仅仅只是引用了binary的一部分。而binary容器是 引用binaries（引用计数binaries的缩写）和堆binaries（heap binaries）。</p>\n<ul>\n<li>Refc binaries 包含两部分：<br>1.一个保存在进程堆的（process heap）对象，即ProcBin,所有的ProcBin都是进程链接的一部分，因此gc 会追踪它们，并且在ProcBin消失后减少引用次数。<br>2.保存在所有进程堆之外的binary对象，binary对象可以被任意个ProcBins（任意个进程中）引用，它包含了引用计数器用来计算当前引用的数量，当引用数量为0时就会被回收。</li>\n<li>Heap binaries 是小binaries，最大为64字节。所以直接保存在程序的堆中。它将会在进程gc或当作消息发送时被复制，gc不需要任何的处理就可以回收。<br>有两种类型的引用对象可以引用 一个refc binary 或 heap binary，它们就是 sub binaries 和 匹配文本。<br>sub binaries 由 <code>split_binary/2</code> 创建或者匹配到一个binary时。sun binaries 只是引用了其他binaries的一部分（refc binaries 或heap binary），因此匹配binaries是非常廉价的，因为他不会发生任何的拷贝。<br>上下文匹配和sub binary类似，不同的是对binary 匹配做了优化；举个例子，它包含了一个直接指向binary数据的指针。</li>\n</ul>\n<h1 id=\"构造二进制\"><a href=\"#构造二进制\" class=\"headerlink\" title=\"构造二进制\"></a>构造二进制</h1><p>运行时系统特别对附加binary作了优化，举个例子：<br>    Bin0= “  0 “,  %%为变量Bin0绑定一个heap binary，<br>    Bin1=”  Bin0/binary,1,2,3  “  %%创建一个refc binary 其内容是Bin0的副本，refc binary的ProcBin部分拥有数据的大小（数据存储到二进制中的大小），binary object 却会有额外的空间被开辟，binary object的大小可能是 Bin0的两倍或者是256（或者更大）。<br>    Bin2 =” Bin1/binary,4,5,6”</p>\n"},{"title":"Erlang发送邮件相关问题","date":"2015-10-22T10:22:11.000Z","_content":"Erlang 发送邮件相关问题\n====\n\n1. 协议相关\n=====\n一封邮件的发送的协议格式如下：\n```php\n\t\"HELO XXX\\r\\n\"\n\t\"AUTH LOGIN \\r\\r\"\n\t\"$Account\\r\\n\" ($Account为账号需要经过base64 encoding）\n\t\"$Password\\r\\n\" ($Password 为密码需要经过base64 encoding)\n\t\"DATA\\r\\n\"\n\t\"From: < $Account> \\r\\n\" ($Account 为发送者的email\n\t\"To : < $ToEmails >\\r\\n\" ($ToEmails 为发送者的列表）\n\t\"Subject: =?UTF-8?B? $Tittle ?=\\r\\n\"($Tittle 是邮件标题经过base64 编码后的字符串，这样做的目的是为了避免中文乱码）\n\t\"MIME-version: 1.0\\r\\n\"\n\t\"Content-Type:text/html;charset=UTF-8\\r\\n\\r\\n\"\n\t\"$DATA\\r\\n\\r\\n\" (正文内容）\n\t\"\\r\\n.\\r\\n\"(结束）\n\t\"QUIT\\r\\n\"(退出）\n```\n\n2.乱码问题\n=====\nErlang 处理中文，唯一办法就是转换成utf-8 ,所以在smtp协议里面就需要指明对应的编码，所以标题需要改为`\"Subject: =?UTF-8?B? $Tittle ?=\\r\\n\"($Tittle 是邮件标题经过base64编码后的字符串，这样做的目的是为了避免中文乱码)` , 正文部分需要指明charset ：`\"Content-Type:text/html;charset=UTF-8\\r\\n\\r\\n\"`\n\n3. 相关资料\n======\n- http://wdicc.com/sendmail-use-perl/\n- http://www.cnblogs.com/quitboy/p/4605694.html\n- http://www.chinaemail.com.cn/blog/content/667/\n","source":"_posts/Erlang发送邮件相关问题.md","raw":"title: Erlang发送邮件相关问题\ndate: 2015-10-22 18:22:11\ntags: [Erlang]\n---\nErlang 发送邮件相关问题\n====\n\n1. 协议相关\n=====\n一封邮件的发送的协议格式如下：\n```php\n\t\"HELO XXX\\r\\n\"\n\t\"AUTH LOGIN \\r\\r\"\n\t\"$Account\\r\\n\" ($Account为账号需要经过base64 encoding）\n\t\"$Password\\r\\n\" ($Password 为密码需要经过base64 encoding)\n\t\"DATA\\r\\n\"\n\t\"From: < $Account> \\r\\n\" ($Account 为发送者的email\n\t\"To : < $ToEmails >\\r\\n\" ($ToEmails 为发送者的列表）\n\t\"Subject: =?UTF-8?B? $Tittle ?=\\r\\n\"($Tittle 是邮件标题经过base64 编码后的字符串，这样做的目的是为了避免中文乱码）\n\t\"MIME-version: 1.0\\r\\n\"\n\t\"Content-Type:text/html;charset=UTF-8\\r\\n\\r\\n\"\n\t\"$DATA\\r\\n\\r\\n\" (正文内容）\n\t\"\\r\\n.\\r\\n\"(结束）\n\t\"QUIT\\r\\n\"(退出）\n```\n\n2.乱码问题\n=====\nErlang 处理中文，唯一办法就是转换成utf-8 ,所以在smtp协议里面就需要指明对应的编码，所以标题需要改为`\"Subject: =?UTF-8?B? $Tittle ?=\\r\\n\"($Tittle 是邮件标题经过base64编码后的字符串，这样做的目的是为了避免中文乱码)` , 正文部分需要指明charset ：`\"Content-Type:text/html;charset=UTF-8\\r\\n\\r\\n\"`\n\n3. 相关资料\n======\n- http://wdicc.com/sendmail-use-perl/\n- http://www.cnblogs.com/quitboy/p/4605694.html\n- http://www.chinaemail.com.cn/blog/content/667/\n","slug":"Erlang发送邮件相关问题","published":1,"updated":"2019-08-21T01:49:04.127Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzkm7pq30004jl9uccv1me6a","content":"<h1 id=\"Erlang-发送邮件相关问题\"><a href=\"#Erlang-发送邮件相关问题\" class=\"headerlink\" title=\"Erlang 发送邮件相关问题\"></a>Erlang 发送邮件相关问题</h1><ol>\n<li><h1 id=\"协议相关\"><a href=\"#协议相关\" class=\"headerlink\" title=\"协议相关\"></a>协议相关</h1>一封邮件的发送的协议格式如下：<pre><code class=\"php\"> &quot;HELO XXX\\r\\n&quot;\n &quot;AUTH LOGIN \\r\\r&quot;\n &quot;$Account\\r\\n&quot; ($Account为账号需要经过base64 encoding）\n &quot;$Password\\r\\n&quot; ($Password 为密码需要经过base64 encoding)\n &quot;DATA\\r\\n&quot;\n &quot;From: &lt; $Account&gt; \\r\\n&quot; ($Account 为发送者的email\n &quot;To : &lt; $ToEmails &gt;\\r\\n&quot; ($ToEmails 为发送者的列表）\n &quot;Subject: =?UTF-8?B? $Tittle ?=\\r\\n&quot;($Tittle 是邮件标题经过base64 编码后的字符串，这样做的目的是为了避免中文乱码）\n &quot;MIME-version: 1.0\\r\\n&quot;\n &quot;Content-Type:text/html;charset=UTF-8\\r\\n\\r\\n&quot;\n &quot;$DATA\\r\\n\\r\\n&quot; (正文内容）\n &quot;\\r\\n.\\r\\n&quot;(结束）\n &quot;QUIT\\r\\n&quot;(退出）\n</code></pre>\n</li>\n</ol>\n<h1 id=\"2-乱码问题\"><a href=\"#2-乱码问题\" class=\"headerlink\" title=\"2.乱码问题\"></a>2.乱码问题</h1><p>Erlang 处理中文，唯一办法就是转换成utf-8 ,所以在smtp协议里面就需要指明对应的编码，所以标题需要改为<code>&quot;Subject: =?UTF-8?B? $Tittle ?=\\r\\n&quot;($Tittle 是邮件标题经过base64编码后的字符串，这样做的目的是为了避免中文乱码)</code> , 正文部分需要指明charset ：<code>&quot;Content-Type:text/html;charset=UTF-8\\r\\n\\r\\n&quot;</code></p>\n<ol>\n<li><h1 id=\"相关资料\"><a href=\"#相关资料\" class=\"headerlink\" title=\"相关资料\"></a>相关资料</h1></li>\n</ol>\n<ul>\n<li><a href=\"http://wdicc.com/sendmail-use-perl/\" target=\"_blank\" rel=\"noopener\">http://wdicc.com/sendmail-use-perl/</a></li>\n<li><a href=\"http://www.cnblogs.com/quitboy/p/4605694.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/quitboy/p/4605694.html</a></li>\n<li><a href=\"http://www.chinaemail.com.cn/blog/content/667/\" target=\"_blank\" rel=\"noopener\">http://www.chinaemail.com.cn/blog/content/667/</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Erlang-发送邮件相关问题\"><a href=\"#Erlang-发送邮件相关问题\" class=\"headerlink\" title=\"Erlang 发送邮件相关问题\"></a>Erlang 发送邮件相关问题</h1><ol>\n<li><h1 id=\"协议相关\"><a href=\"#协议相关\" class=\"headerlink\" title=\"协议相关\"></a>协议相关</h1>一封邮件的发送的协议格式如下：<pre><code class=\"php\"> &quot;HELO XXX\\r\\n&quot;\n &quot;AUTH LOGIN \\r\\r&quot;\n &quot;$Account\\r\\n&quot; ($Account为账号需要经过base64 encoding）\n &quot;$Password\\r\\n&quot; ($Password 为密码需要经过base64 encoding)\n &quot;DATA\\r\\n&quot;\n &quot;From: &lt; $Account&gt; \\r\\n&quot; ($Account 为发送者的email\n &quot;To : &lt; $ToEmails &gt;\\r\\n&quot; ($ToEmails 为发送者的列表）\n &quot;Subject: =?UTF-8?B? $Tittle ?=\\r\\n&quot;($Tittle 是邮件标题经过base64 编码后的字符串，这样做的目的是为了避免中文乱码）\n &quot;MIME-version: 1.0\\r\\n&quot;\n &quot;Content-Type:text/html;charset=UTF-8\\r\\n\\r\\n&quot;\n &quot;$DATA\\r\\n\\r\\n&quot; (正文内容）\n &quot;\\r\\n.\\r\\n&quot;(结束）\n &quot;QUIT\\r\\n&quot;(退出）\n</code></pre>\n</li>\n</ol>\n<h1 id=\"2-乱码问题\"><a href=\"#2-乱码问题\" class=\"headerlink\" title=\"2.乱码问题\"></a>2.乱码问题</h1><p>Erlang 处理中文，唯一办法就是转换成utf-8 ,所以在smtp协议里面就需要指明对应的编码，所以标题需要改为<code>&quot;Subject: =?UTF-8?B? $Tittle ?=\\r\\n&quot;($Tittle 是邮件标题经过base64编码后的字符串，这样做的目的是为了避免中文乱码)</code> , 正文部分需要指明charset ：<code>&quot;Content-Type:text/html;charset=UTF-8\\r\\n\\r\\n&quot;</code></p>\n<ol>\n<li><h1 id=\"相关资料\"><a href=\"#相关资料\" class=\"headerlink\" title=\"相关资料\"></a>相关资料</h1></li>\n</ol>\n<ul>\n<li><a href=\"http://wdicc.com/sendmail-use-perl/\" target=\"_blank\" rel=\"noopener\">http://wdicc.com/sendmail-use-perl/</a></li>\n<li><a href=\"http://www.cnblogs.com/quitboy/p/4605694.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/quitboy/p/4605694.html</a></li>\n<li><a href=\"http://www.chinaemail.com.cn/blog/content/667/\" target=\"_blank\" rel=\"noopener\">http://www.chinaemail.com.cn/blog/content/667/</a></li>\n</ul>\n"},{"title":"Erlang通过NIF集成c代码示例","date":"2015-10-22T13:24:21.000Z","_content":"\nERLANG NIF 编写\n===\n\n很多时候一下计算量大，效率要求很高的地方也许使用c会好于erlang。\n\nErlang层代码\n====\n-  通过 `-on_load`模块属性，实现erlang vm 加载模块时同时加载c的共享库文件。\n-   nif的函数erlang入口为 func(args) -> erlang:nif_error({error,not_loaded}).\n\nC层代码\n====\n- 包含 erl_nif.h  , `#include<erl_nif.h>`，\n- 注册NIF ,这里分为了三步：\n  1. ErlNifFunc 数组，告诉erlang vm 库中实现的NIF，以及erlang函数名对应的c实现函数:\n\tstatic ErlNifFunc test_nifs[] =\n\t{ \n \t{\"hello\",1,&hello_1} \n\t};\n  2. ERL_NIF_INIT宏 将 ErlNifFunc数组联同所属模块的模块名告诉Erlang vm。`ERL_NIF_INIT(test_nif,test_nifs,NULL,NULL,NULL,NULL);`\n  3. c实现函数 `static ERL_NIF_TERM hello_1(ErlNifEnv * env,int argc,const ERL_NIF_TERM argv[])` , 函数接受3个参数，并返回一个ERL_NIF_TERM对象，第一个参数env就是前面提到过的ErlNifEnv 指针。第二个参数argc是Erlang调用NIF时传入的参数数目。第三个参数argv中的元素就是传入的各个参数（数目与argc中的一致）。\n\n3.编译c代码\n   `gcc -o test_nif.so -fpic -shared -I/usr/local/lib/erlang/erts-5.10.4/include test_nif.c`.\n\ntest_nif.c\n\n```c\n#include<erl_nif.h>\n#include<string.h>\nstatic ERL_NIF_TERM hello_1(ErlNifEnv * env,int argc,const ERL_NIF_TERM argv[])\n{\n \treturn enif_make_tuple2(env,enif_make_atom(env,\"hello\"),argv[0]);\n}\nstatic ErlNifFunc test_nifs[] =\n{ \n \t{\"hello\",1,&hello_1} \n};\nERL_NIF_INIT(test_nif,test_nifs,NULL,NULL,NULL,NULL);\n```\n\ntest_nif.erl\n\n```erlang\n-module(test_nif).\n-on_load(init/0).\n-export([hello/1]).\ninit()->\n \terlang:load_nif(\"./test_nif\",0);\nhello(Arg)->\n \terlang:nif_error({error, not_loaded}).\n ```\n\n","source":"_posts/Erlang通过NIF集成c代码示例.md","raw":"title: Erlang通过NIF集成c代码示例\ndate: 2015-10-22 21:24:21\ntags: [Erlang]\n---\n\nERLANG NIF 编写\n===\n\n很多时候一下计算量大，效率要求很高的地方也许使用c会好于erlang。\n\nErlang层代码\n====\n-  通过 `-on_load`模块属性，实现erlang vm 加载模块时同时加载c的共享库文件。\n-   nif的函数erlang入口为 func(args) -> erlang:nif_error({error,not_loaded}).\n\nC层代码\n====\n- 包含 erl_nif.h  , `#include<erl_nif.h>`，\n- 注册NIF ,这里分为了三步：\n  1. ErlNifFunc 数组，告诉erlang vm 库中实现的NIF，以及erlang函数名对应的c实现函数:\n\tstatic ErlNifFunc test_nifs[] =\n\t{ \n \t{\"hello\",1,&hello_1} \n\t};\n  2. ERL_NIF_INIT宏 将 ErlNifFunc数组联同所属模块的模块名告诉Erlang vm。`ERL_NIF_INIT(test_nif,test_nifs,NULL,NULL,NULL,NULL);`\n  3. c实现函数 `static ERL_NIF_TERM hello_1(ErlNifEnv * env,int argc,const ERL_NIF_TERM argv[])` , 函数接受3个参数，并返回一个ERL_NIF_TERM对象，第一个参数env就是前面提到过的ErlNifEnv 指针。第二个参数argc是Erlang调用NIF时传入的参数数目。第三个参数argv中的元素就是传入的各个参数（数目与argc中的一致）。\n\n3.编译c代码\n   `gcc -o test_nif.so -fpic -shared -I/usr/local/lib/erlang/erts-5.10.4/include test_nif.c`.\n\ntest_nif.c\n\n```c\n#include<erl_nif.h>\n#include<string.h>\nstatic ERL_NIF_TERM hello_1(ErlNifEnv * env,int argc,const ERL_NIF_TERM argv[])\n{\n \treturn enif_make_tuple2(env,enif_make_atom(env,\"hello\"),argv[0]);\n}\nstatic ErlNifFunc test_nifs[] =\n{ \n \t{\"hello\",1,&hello_1} \n};\nERL_NIF_INIT(test_nif,test_nifs,NULL,NULL,NULL,NULL);\n```\n\ntest_nif.erl\n\n```erlang\n-module(test_nif).\n-on_load(init/0).\n-export([hello/1]).\ninit()->\n \terlang:load_nif(\"./test_nif\",0);\nhello(Arg)->\n \terlang:nif_error({error, not_loaded}).\n ```\n\n","slug":"Erlang通过NIF集成c代码示例","published":1,"updated":"2019-08-21T01:49:04.127Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzkm7pq40005jl9u5npnhmds","content":"<h1 id=\"ERLANG-NIF-编写\"><a href=\"#ERLANG-NIF-编写\" class=\"headerlink\" title=\"ERLANG NIF 编写\"></a>ERLANG NIF 编写</h1><p>很多时候一下计算量大，效率要求很高的地方也许使用c会好于erlang。</p>\n<h1 id=\"Erlang层代码\"><a href=\"#Erlang层代码\" class=\"headerlink\" title=\"Erlang层代码\"></a>Erlang层代码</h1><ul>\n<li>通过 <code>-on_load</code>模块属性，实现erlang vm 加载模块时同时加载c的共享库文件。</li>\n<li>nif的函数erlang入口为 func(args) -&gt; erlang:nif_error({error,not_loaded}).</li>\n</ul>\n<h1 id=\"C层代码\"><a href=\"#C层代码\" class=\"headerlink\" title=\"C层代码\"></a>C层代码</h1><ul>\n<li>包含 erl_nif.h  , <code>#include&lt;erl_nif.h&gt;</code>，</li>\n<li>注册NIF ,这里分为了三步：<ol>\n<li>ErlNifFunc 数组，告诉erlang vm 库中实现的NIF，以及erlang函数名对应的c实现函数:<br>static ErlNifFunc test_nifs[] =<br>{<br>{“hello”,1,&amp;hello_1}<br>};</li>\n<li>ERL_NIF_INIT宏 将 ErlNifFunc数组联同所属模块的模块名告诉Erlang vm。<code>ERL_NIF_INIT(test_nif,test_nifs,NULL,NULL,NULL,NULL);</code></li>\n<li>c实现函数 <code>static ERL_NIF_TERM hello_1(ErlNifEnv * env,int argc,const ERL_NIF_TERM argv[])</code> , 函数接受3个参数，并返回一个ERL_NIF_TERM对象，第一个参数env就是前面提到过的ErlNifEnv 指针。第二个参数argc是Erlang调用NIF时传入的参数数目。第三个参数argv中的元素就是传入的各个参数（数目与argc中的一致）。</li>\n</ol>\n</li>\n</ul>\n<p>3.编译c代码<br>   <code>gcc -o test_nif.so -fpic -shared -I/usr/local/lib/erlang/erts-5.10.4/include test_nif.c</code>.</p>\n<p>test_nif.c</p>\n<pre><code class=\"c\">#include&lt;erl_nif.h&gt;\n#include&lt;string.h&gt;\nstatic ERL_NIF_TERM hello_1(ErlNifEnv * env,int argc,const ERL_NIF_TERM argv[])\n{\n     return enif_make_tuple2(env,enif_make_atom(env,&quot;hello&quot;),argv[0]);\n}\nstatic ErlNifFunc test_nifs[] =\n{ \n     {&quot;hello&quot;,1,&amp;hello_1} \n};\nERL_NIF_INIT(test_nif,test_nifs,NULL,NULL,NULL,NULL);\n</code></pre>\n<p>test_nif.erl</p>\n<pre><code class=\"erlang\">-module(test_nif).\n-on_load(init/0).\n-export([hello/1]).\ninit()-&gt;\n     erlang:load_nif(&quot;./test_nif&quot;,0);\nhello(Arg)-&gt;\n     erlang:nif_error({error, not_loaded}).\n</code></pre>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"ERLANG-NIF-编写\"><a href=\"#ERLANG-NIF-编写\" class=\"headerlink\" title=\"ERLANG NIF 编写\"></a>ERLANG NIF 编写</h1><p>很多时候一下计算量大，效率要求很高的地方也许使用c会好于erlang。</p>\n<h1 id=\"Erlang层代码\"><a href=\"#Erlang层代码\" class=\"headerlink\" title=\"Erlang层代码\"></a>Erlang层代码</h1><ul>\n<li>通过 <code>-on_load</code>模块属性，实现erlang vm 加载模块时同时加载c的共享库文件。</li>\n<li>nif的函数erlang入口为 func(args) -&gt; erlang:nif_error({error,not_loaded}).</li>\n</ul>\n<h1 id=\"C层代码\"><a href=\"#C层代码\" class=\"headerlink\" title=\"C层代码\"></a>C层代码</h1><ul>\n<li>包含 erl_nif.h  , <code>#include&lt;erl_nif.h&gt;</code>，</li>\n<li>注册NIF ,这里分为了三步：<ol>\n<li>ErlNifFunc 数组，告诉erlang vm 库中实现的NIF，以及erlang函数名对应的c实现函数:<br>static ErlNifFunc test_nifs[] =<br>{<br>{“hello”,1,&amp;hello_1}<br>};</li>\n<li>ERL_NIF_INIT宏 将 ErlNifFunc数组联同所属模块的模块名告诉Erlang vm。<code>ERL_NIF_INIT(test_nif,test_nifs,NULL,NULL,NULL,NULL);</code></li>\n<li>c实现函数 <code>static ERL_NIF_TERM hello_1(ErlNifEnv * env,int argc,const ERL_NIF_TERM argv[])</code> , 函数接受3个参数，并返回一个ERL_NIF_TERM对象，第一个参数env就是前面提到过的ErlNifEnv 指针。第二个参数argc是Erlang调用NIF时传入的参数数目。第三个参数argv中的元素就是传入的各个参数（数目与argc中的一致）。</li>\n</ol>\n</li>\n</ul>\n<p>3.编译c代码<br>   <code>gcc -o test_nif.so -fpic -shared -I/usr/local/lib/erlang/erts-5.10.4/include test_nif.c</code>.</p>\n<p>test_nif.c</p>\n<pre><code class=\"c\">#include&lt;erl_nif.h&gt;\n#include&lt;string.h&gt;\nstatic ERL_NIF_TERM hello_1(ErlNifEnv * env,int argc,const ERL_NIF_TERM argv[])\n{\n     return enif_make_tuple2(env,enif_make_atom(env,&quot;hello&quot;),argv[0]);\n}\nstatic ErlNifFunc test_nifs[] =\n{ \n     {&quot;hello&quot;,1,&amp;hello_1} \n};\nERL_NIF_INIT(test_nif,test_nifs,NULL,NULL,NULL,NULL);\n</code></pre>\n<p>test_nif.erl</p>\n<pre><code class=\"erlang\">-module(test_nif).\n-on_load(init/0).\n-export([hello/1]).\ninit()-&gt;\n     erlang:load_nif(&quot;./test_nif&quot;,0);\nhello(Arg)-&gt;\n     erlang:nif_error({error, not_loaded}).\n</code></pre>\n"},{"title":"MQTT_V1.3_协议详解","date":"2015-10-24T06:34:53.000Z","_content":"MQTT 协议详解\n====\n\n预览\n====\n```\n    %%        7   6   5   4      3     2   1      0\n    byte1     message_type   dupflag   QoSLV   RETAIN\n    byte2     Remaining Length\n    byte3      Variable header\n    byten       ....\n                    MSG\n```\nFixed header（固定头部）\n====\n```\n    %%        7   6   5   4      3     2   1      0\n    byte1     message_type   dupflag   QoSLV   RETAIN\n    byte2     Remaining Length\n```\n* message_type:消息类型，第4-7位比特，不同的值表示不同的意思，具体如下：\n    1. 1 ：CONNECT,客户端请求连接服务器\t       \n    2. 2 : CONNACK,连接应答\n    3. 3 ：PUBLISH ,发布一条消息      \t\n    4. 4 :  PUBACK, 发布应答        \t\n    5. 5 :  PUBREC, 发布被接收应答发布1        \t\n    6. 6 ：PUBREL ，发布释放应答发布2        \t\n    7. 7 : PUBCOMP,发布完成应答发布3        \t\n    8. 8 ：SUBSCRIBE,请求订阅        \t\n    9. 9 ：SUBACK,订阅应答        \t\n    10. 10 ：UNSUBSCRIBE ,取消订阅\n    11. 11 ：unsuback,取消订阅应答\n    12. 12 ：PINGREQ ,ping请求\n    13. 13 ：PINGRESP,ping回应\n    14. 14 ：DISCONNECT,客户端断开连接\n    15. 15 ：保留\n\n* DUP:用于标识是否是重发的发布，发布应答，订阅，取消订阅的消息，当QoS大于0，且设置必须应答时。\n* QoS:消息的发送保证级别；0：至多一次，1：至少1次 ；2：只有一次 3：保留\n* RETAIN：对发布消息有用，为1时标识发布的消息对新订阅的用户有用，且需要持久化，\n* Remaining Length:低7位为消息的字节数量，第8位为下一个字节也是长度标志位，最大为四个字节。\n\n\nVariable Header(可变头部)\n====\n某些MQTT的命令会包含一个可变的头部组件，它位于 固定头部（fixed header)和负载之间。\nProtocol name(协议名称）\n====\n协议名出现在一条MQTT 连接消息的可变头部中，这个字段是UTF编码，比如 MQIsdp 或MQTT\n\nProtocol version（协议版本）\n====\n协议版本字段出先在一条MQTT连接消息的可变头部中，占用一个字节。\n\nConnect flag（连接标识）\n====\nClean_session,WILL,Will QoS,Retain flags 出现在CONNECT 消息的可变头部。\n\nClean session flag\n====\n位置：在connect flag字节的 第1位（从0位开始），如果该位不置1则服务器需要持久化该客户端的订阅消息，以便下一次连接后继续使用。如果置1，则客户端断开后清空订阅信息，每次连接都需要重新订阅信息。\n\nWill QoS、Will flag 、Will Message\n====\n位置：在connect flag 字节的第3 和第4位\n這三個flag，就是在MQTT簡介裡被提到的 最後遺囑(Last Will and Testament) 機制所用的flag。這機制是這樣的，client在一開始發送CONNECT訊息給server要求建立連線時，就把要對哪個主題說什麼遺言一起傳給server，當它在不正常的情況下斷線時(比如說網路連線斷掉、裝置故障等等)，則這些訊息就會被server主動發佈到該主題上。如果是client主動發送DISCONNECT訊息給server要求斷線時，則此機制將不會有作用。\n\n要啟動此機制，首先就是要將Will flag設為1，這樣就代表要啟用，之後你設定遺言的QoS level為何，server會依照你設定的QoS level來幫你傳送訊息，最後設定此此則遺言是否要保留(Retain)在server上。如果有設定Will flag，則在pyaload內會需要定義Will Topic和Will Message，也就是要對哪個主題發送什麼樣的遺言。\n\nUser name 和 password 标识\n====\n位置：在connect flag 字节的第6和第7位\n客户端在连接时指明是否包含了登陆名称和登陆密码。\n\nKeep Alive timer（存活定时器）\n====\nkeep alive timer 出现在一个CONNECT消息的可变头部，定义了从客户端接受消息的最大间隔时间（秒），可用于服务端心跳包机制来判断与客户端的网络连接是否已经断开。keep alive timer 字段大小为两个字节，0表示客户端用于不会断开。\n\nConnect return code 返回码\n====\nconnect return code出现 在CONNACK 消息中，大小为一个字节，当前有意义的值是：\n- 0x00 : 接受连接\n- 0x01:  拒绝连接，协议版本不可用\n- 0x02:  连接失败，标识拒绝\n- 0x03:  服务器连接失败\n- 0x04:  用户名和密码错误\n- 0x05:  没有验证\n\nTopic name (订阅名称）\n====\ntopic name 出现在MQTT PUBLISH 消息的可变头部，用来标明发布消息所属的channel，订阅时使用该值来标明从哪里接收发布消息。\n\n","source":"_posts/MQTT-V1-3-协议详解.md","raw":"title: MQTT_V1.3_协议详解\ndate: 2015-10-24 14:34:53\ntags: [mqtt]\n---\nMQTT 协议详解\n====\n\n预览\n====\n```\n    %%        7   6   5   4      3     2   1      0\n    byte1     message_type   dupflag   QoSLV   RETAIN\n    byte2     Remaining Length\n    byte3      Variable header\n    byten       ....\n                    MSG\n```\nFixed header（固定头部）\n====\n```\n    %%        7   6   5   4      3     2   1      0\n    byte1     message_type   dupflag   QoSLV   RETAIN\n    byte2     Remaining Length\n```\n* message_type:消息类型，第4-7位比特，不同的值表示不同的意思，具体如下：\n    1. 1 ：CONNECT,客户端请求连接服务器\t       \n    2. 2 : CONNACK,连接应答\n    3. 3 ：PUBLISH ,发布一条消息      \t\n    4. 4 :  PUBACK, 发布应答        \t\n    5. 5 :  PUBREC, 发布被接收应答发布1        \t\n    6. 6 ：PUBREL ，发布释放应答发布2        \t\n    7. 7 : PUBCOMP,发布完成应答发布3        \t\n    8. 8 ：SUBSCRIBE,请求订阅        \t\n    9. 9 ：SUBACK,订阅应答        \t\n    10. 10 ：UNSUBSCRIBE ,取消订阅\n    11. 11 ：unsuback,取消订阅应答\n    12. 12 ：PINGREQ ,ping请求\n    13. 13 ：PINGRESP,ping回应\n    14. 14 ：DISCONNECT,客户端断开连接\n    15. 15 ：保留\n\n* DUP:用于标识是否是重发的发布，发布应答，订阅，取消订阅的消息，当QoS大于0，且设置必须应答时。\n* QoS:消息的发送保证级别；0：至多一次，1：至少1次 ；2：只有一次 3：保留\n* RETAIN：对发布消息有用，为1时标识发布的消息对新订阅的用户有用，且需要持久化，\n* Remaining Length:低7位为消息的字节数量，第8位为下一个字节也是长度标志位，最大为四个字节。\n\n\nVariable Header(可变头部)\n====\n某些MQTT的命令会包含一个可变的头部组件，它位于 固定头部（fixed header)和负载之间。\nProtocol name(协议名称）\n====\n协议名出现在一条MQTT 连接消息的可变头部中，这个字段是UTF编码，比如 MQIsdp 或MQTT\n\nProtocol version（协议版本）\n====\n协议版本字段出先在一条MQTT连接消息的可变头部中，占用一个字节。\n\nConnect flag（连接标识）\n====\nClean_session,WILL,Will QoS,Retain flags 出现在CONNECT 消息的可变头部。\n\nClean session flag\n====\n位置：在connect flag字节的 第1位（从0位开始），如果该位不置1则服务器需要持久化该客户端的订阅消息，以便下一次连接后继续使用。如果置1，则客户端断开后清空订阅信息，每次连接都需要重新订阅信息。\n\nWill QoS、Will flag 、Will Message\n====\n位置：在connect flag 字节的第3 和第4位\n這三個flag，就是在MQTT簡介裡被提到的 最後遺囑(Last Will and Testament) 機制所用的flag。這機制是這樣的，client在一開始發送CONNECT訊息給server要求建立連線時，就把要對哪個主題說什麼遺言一起傳給server，當它在不正常的情況下斷線時(比如說網路連線斷掉、裝置故障等等)，則這些訊息就會被server主動發佈到該主題上。如果是client主動發送DISCONNECT訊息給server要求斷線時，則此機制將不會有作用。\n\n要啟動此機制，首先就是要將Will flag設為1，這樣就代表要啟用，之後你設定遺言的QoS level為何，server會依照你設定的QoS level來幫你傳送訊息，最後設定此此則遺言是否要保留(Retain)在server上。如果有設定Will flag，則在pyaload內會需要定義Will Topic和Will Message，也就是要對哪個主題發送什麼樣的遺言。\n\nUser name 和 password 标识\n====\n位置：在connect flag 字节的第6和第7位\n客户端在连接时指明是否包含了登陆名称和登陆密码。\n\nKeep Alive timer（存活定时器）\n====\nkeep alive timer 出现在一个CONNECT消息的可变头部，定义了从客户端接受消息的最大间隔时间（秒），可用于服务端心跳包机制来判断与客户端的网络连接是否已经断开。keep alive timer 字段大小为两个字节，0表示客户端用于不会断开。\n\nConnect return code 返回码\n====\nconnect return code出现 在CONNACK 消息中，大小为一个字节，当前有意义的值是：\n- 0x00 : 接受连接\n- 0x01:  拒绝连接，协议版本不可用\n- 0x02:  连接失败，标识拒绝\n- 0x03:  服务器连接失败\n- 0x04:  用户名和密码错误\n- 0x05:  没有验证\n\nTopic name (订阅名称）\n====\ntopic name 出现在MQTT PUBLISH 消息的可变头部，用来标明发布消息所属的channel，订阅时使用该值来标明从哪里接收发布消息。\n\n","slug":"MQTT-V1-3-协议详解","published":1,"updated":"2019-08-21T01:49:04.128Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzkm7pq50006jl9uyo8t0two","content":"<h1 id=\"MQTT-协议详解\"><a href=\"#MQTT-协议详解\" class=\"headerlink\" title=\"MQTT 协议详解\"></a>MQTT 协议详解</h1><h1 id=\"预览\"><a href=\"#预览\" class=\"headerlink\" title=\"预览\"></a>预览</h1><pre><code>    %%        7   6   5   4      3     2   1      0\n    byte1     message_type   dupflag   QoSLV   RETAIN\n    byte2     Remaining Length\n    byte3      Variable header\n    byten       ....\n                    MSG\n</code></pre><h1 id=\"Fixed-header（固定头部）\"><a href=\"#Fixed-header（固定头部）\" class=\"headerlink\" title=\"Fixed header（固定头部）\"></a>Fixed header（固定头部）</h1><pre><code>    %%        7   6   5   4      3     2   1      0\n    byte1     message_type   dupflag   QoSLV   RETAIN\n    byte2     Remaining Length\n</code></pre><ul>\n<li><p>message_type:消息类型，第4-7位比特，不同的值表示不同的意思，具体如下：</p>\n<ol>\n<li>1 ：CONNECT,客户端请求连接服务器           </li>\n<li>2 : CONNACK,连接应答</li>\n<li>3 ：PUBLISH ,发布一条消息          </li>\n<li>4 :  PUBACK, 发布应答            </li>\n<li>5 :  PUBREC, 发布被接收应答发布1            </li>\n<li>6 ：PUBREL ，发布释放应答发布2            </li>\n<li>7 : PUBCOMP,发布完成应答发布3            </li>\n<li>8 ：SUBSCRIBE,请求订阅            </li>\n<li>9 ：SUBACK,订阅应答            </li>\n<li>10 ：UNSUBSCRIBE ,取消订阅</li>\n<li>11 ：unsuback,取消订阅应答</li>\n<li>12 ：PINGREQ ,ping请求</li>\n<li>13 ：PINGRESP,ping回应</li>\n<li>14 ：DISCONNECT,客户端断开连接</li>\n<li>15 ：保留</li>\n</ol>\n</li>\n<li><p>DUP:用于标识是否是重发的发布，发布应答，订阅，取消订阅的消息，当QoS大于0，且设置必须应答时。</p>\n</li>\n<li>QoS:消息的发送保证级别；0：至多一次，1：至少1次 ；2：只有一次 3：保留</li>\n<li>RETAIN：对发布消息有用，为1时标识发布的消息对新订阅的用户有用，且需要持久化，</li>\n<li>Remaining Length:低7位为消息的字节数量，第8位为下一个字节也是长度标志位，最大为四个字节。</li>\n</ul>\n<h1 id=\"Variable-Header-可变头部\"><a href=\"#Variable-Header-可变头部\" class=\"headerlink\" title=\"Variable Header(可变头部)\"></a>Variable Header(可变头部)</h1><p>某些MQTT的命令会包含一个可变的头部组件，它位于 固定头部（fixed header)和负载之间。</p>\n<h1 id=\"Protocol-name-协议名称）\"><a href=\"#Protocol-name-协议名称）\" class=\"headerlink\" title=\"Protocol name(协议名称）\"></a>Protocol name(协议名称）</h1><p>协议名出现在一条MQTT 连接消息的可变头部中，这个字段是UTF编码，比如 MQIsdp 或MQTT</p>\n<h1 id=\"Protocol-version（协议版本）\"><a href=\"#Protocol-version（协议版本）\" class=\"headerlink\" title=\"Protocol version（协议版本）\"></a>Protocol version（协议版本）</h1><p>协议版本字段出先在一条MQTT连接消息的可变头部中，占用一个字节。</p>\n<h1 id=\"Connect-flag（连接标识）\"><a href=\"#Connect-flag（连接标识）\" class=\"headerlink\" title=\"Connect flag（连接标识）\"></a>Connect flag（连接标识）</h1><p>Clean_session,WILL,Will QoS,Retain flags 出现在CONNECT 消息的可变头部。</p>\n<h1 id=\"Clean-session-flag\"><a href=\"#Clean-session-flag\" class=\"headerlink\" title=\"Clean session flag\"></a>Clean session flag</h1><p>位置：在connect flag字节的 第1位（从0位开始），如果该位不置1则服务器需要持久化该客户端的订阅消息，以便下一次连接后继续使用。如果置1，则客户端断开后清空订阅信息，每次连接都需要重新订阅信息。</p>\n<h1 id=\"Will-QoS、Will-flag-、Will-Message\"><a href=\"#Will-QoS、Will-flag-、Will-Message\" class=\"headerlink\" title=\"Will QoS、Will flag 、Will Message\"></a>Will QoS、Will flag 、Will Message</h1><p>位置：在connect flag 字节的第3 和第4位<br>這三個flag，就是在MQTT簡介裡被提到的 最後遺囑(Last Will and Testament) 機制所用的flag。這機制是這樣的，client在一開始發送CONNECT訊息給server要求建立連線時，就把要對哪個主題說什麼遺言一起傳給server，當它在不正常的情況下斷線時(比如說網路連線斷掉、裝置故障等等)，則這些訊息就會被server主動發佈到該主題上。如果是client主動發送DISCONNECT訊息給server要求斷線時，則此機制將不會有作用。</p>\n<p>要啟動此機制，首先就是要將Will flag設為1，這樣就代表要啟用，之後你設定遺言的QoS level為何，server會依照你設定的QoS level來幫你傳送訊息，最後設定此此則遺言是否要保留(Retain)在server上。如果有設定Will flag，則在pyaload內會需要定義Will Topic和Will Message，也就是要對哪個主題發送什麼樣的遺言。</p>\n<h1 id=\"User-name-和-password-标识\"><a href=\"#User-name-和-password-标识\" class=\"headerlink\" title=\"User name 和 password 标识\"></a>User name 和 password 标识</h1><p>位置：在connect flag 字节的第6和第7位<br>客户端在连接时指明是否包含了登陆名称和登陆密码。</p>\n<h1 id=\"Keep-Alive-timer（存活定时器）\"><a href=\"#Keep-Alive-timer（存活定时器）\" class=\"headerlink\" title=\"Keep Alive timer（存活定时器）\"></a>Keep Alive timer（存活定时器）</h1><p>keep alive timer 出现在一个CONNECT消息的可变头部，定义了从客户端接受消息的最大间隔时间（秒），可用于服务端心跳包机制来判断与客户端的网络连接是否已经断开。keep alive timer 字段大小为两个字节，0表示客户端用于不会断开。</p>\n<h1 id=\"Connect-return-code-返回码\"><a href=\"#Connect-return-code-返回码\" class=\"headerlink\" title=\"Connect return code 返回码\"></a>Connect return code 返回码</h1><p>connect return code出现 在CONNACK 消息中，大小为一个字节，当前有意义的值是：</p>\n<ul>\n<li>0x00 : 接受连接</li>\n<li>0x01:  拒绝连接，协议版本不可用</li>\n<li>0x02:  连接失败，标识拒绝</li>\n<li>0x03:  服务器连接失败</li>\n<li>0x04:  用户名和密码错误</li>\n<li>0x05:  没有验证</li>\n</ul>\n<h1 id=\"Topic-name-订阅名称）\"><a href=\"#Topic-name-订阅名称）\" class=\"headerlink\" title=\"Topic name (订阅名称）\"></a>Topic name (订阅名称）</h1><p>topic name 出现在MQTT PUBLISH 消息的可变头部，用来标明发布消息所属的channel，订阅时使用该值来标明从哪里接收发布消息。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"MQTT-协议详解\"><a href=\"#MQTT-协议详解\" class=\"headerlink\" title=\"MQTT 协议详解\"></a>MQTT 协议详解</h1><h1 id=\"预览\"><a href=\"#预览\" class=\"headerlink\" title=\"预览\"></a>预览</h1><pre><code>    %%        7   6   5   4      3     2   1      0\n    byte1     message_type   dupflag   QoSLV   RETAIN\n    byte2     Remaining Length\n    byte3      Variable header\n    byten       ....\n                    MSG\n</code></pre><h1 id=\"Fixed-header（固定头部）\"><a href=\"#Fixed-header（固定头部）\" class=\"headerlink\" title=\"Fixed header（固定头部）\"></a>Fixed header（固定头部）</h1><pre><code>    %%        7   6   5   4      3     2   1      0\n    byte1     message_type   dupflag   QoSLV   RETAIN\n    byte2     Remaining Length\n</code></pre><ul>\n<li><p>message_type:消息类型，第4-7位比特，不同的值表示不同的意思，具体如下：</p>\n<ol>\n<li>1 ：CONNECT,客户端请求连接服务器           </li>\n<li>2 : CONNACK,连接应答</li>\n<li>3 ：PUBLISH ,发布一条消息          </li>\n<li>4 :  PUBACK, 发布应答            </li>\n<li>5 :  PUBREC, 发布被接收应答发布1            </li>\n<li>6 ：PUBREL ，发布释放应答发布2            </li>\n<li>7 : PUBCOMP,发布完成应答发布3            </li>\n<li>8 ：SUBSCRIBE,请求订阅            </li>\n<li>9 ：SUBACK,订阅应答            </li>\n<li>10 ：UNSUBSCRIBE ,取消订阅</li>\n<li>11 ：unsuback,取消订阅应答</li>\n<li>12 ：PINGREQ ,ping请求</li>\n<li>13 ：PINGRESP,ping回应</li>\n<li>14 ：DISCONNECT,客户端断开连接</li>\n<li>15 ：保留</li>\n</ol>\n</li>\n<li><p>DUP:用于标识是否是重发的发布，发布应答，订阅，取消订阅的消息，当QoS大于0，且设置必须应答时。</p>\n</li>\n<li>QoS:消息的发送保证级别；0：至多一次，1：至少1次 ；2：只有一次 3：保留</li>\n<li>RETAIN：对发布消息有用，为1时标识发布的消息对新订阅的用户有用，且需要持久化，</li>\n<li>Remaining Length:低7位为消息的字节数量，第8位为下一个字节也是长度标志位，最大为四个字节。</li>\n</ul>\n<h1 id=\"Variable-Header-可变头部\"><a href=\"#Variable-Header-可变头部\" class=\"headerlink\" title=\"Variable Header(可变头部)\"></a>Variable Header(可变头部)</h1><p>某些MQTT的命令会包含一个可变的头部组件，它位于 固定头部（fixed header)和负载之间。</p>\n<h1 id=\"Protocol-name-协议名称）\"><a href=\"#Protocol-name-协议名称）\" class=\"headerlink\" title=\"Protocol name(协议名称）\"></a>Protocol name(协议名称）</h1><p>协议名出现在一条MQTT 连接消息的可变头部中，这个字段是UTF编码，比如 MQIsdp 或MQTT</p>\n<h1 id=\"Protocol-version（协议版本）\"><a href=\"#Protocol-version（协议版本）\" class=\"headerlink\" title=\"Protocol version（协议版本）\"></a>Protocol version（协议版本）</h1><p>协议版本字段出先在一条MQTT连接消息的可变头部中，占用一个字节。</p>\n<h1 id=\"Connect-flag（连接标识）\"><a href=\"#Connect-flag（连接标识）\" class=\"headerlink\" title=\"Connect flag（连接标识）\"></a>Connect flag（连接标识）</h1><p>Clean_session,WILL,Will QoS,Retain flags 出现在CONNECT 消息的可变头部。</p>\n<h1 id=\"Clean-session-flag\"><a href=\"#Clean-session-flag\" class=\"headerlink\" title=\"Clean session flag\"></a>Clean session flag</h1><p>位置：在connect flag字节的 第1位（从0位开始），如果该位不置1则服务器需要持久化该客户端的订阅消息，以便下一次连接后继续使用。如果置1，则客户端断开后清空订阅信息，每次连接都需要重新订阅信息。</p>\n<h1 id=\"Will-QoS、Will-flag-、Will-Message\"><a href=\"#Will-QoS、Will-flag-、Will-Message\" class=\"headerlink\" title=\"Will QoS、Will flag 、Will Message\"></a>Will QoS、Will flag 、Will Message</h1><p>位置：在connect flag 字节的第3 和第4位<br>這三個flag，就是在MQTT簡介裡被提到的 最後遺囑(Last Will and Testament) 機制所用的flag。這機制是這樣的，client在一開始發送CONNECT訊息給server要求建立連線時，就把要對哪個主題說什麼遺言一起傳給server，當它在不正常的情況下斷線時(比如說網路連線斷掉、裝置故障等等)，則這些訊息就會被server主動發佈到該主題上。如果是client主動發送DISCONNECT訊息給server要求斷線時，則此機制將不會有作用。</p>\n<p>要啟動此機制，首先就是要將Will flag設為1，這樣就代表要啟用，之後你設定遺言的QoS level為何，server會依照你設定的QoS level來幫你傳送訊息，最後設定此此則遺言是否要保留(Retain)在server上。如果有設定Will flag，則在pyaload內會需要定義Will Topic和Will Message，也就是要對哪個主題發送什麼樣的遺言。</p>\n<h1 id=\"User-name-和-password-标识\"><a href=\"#User-name-和-password-标识\" class=\"headerlink\" title=\"User name 和 password 标识\"></a>User name 和 password 标识</h1><p>位置：在connect flag 字节的第6和第7位<br>客户端在连接时指明是否包含了登陆名称和登陆密码。</p>\n<h1 id=\"Keep-Alive-timer（存活定时器）\"><a href=\"#Keep-Alive-timer（存活定时器）\" class=\"headerlink\" title=\"Keep Alive timer（存活定时器）\"></a>Keep Alive timer（存活定时器）</h1><p>keep alive timer 出现在一个CONNECT消息的可变头部，定义了从客户端接受消息的最大间隔时间（秒），可用于服务端心跳包机制来判断与客户端的网络连接是否已经断开。keep alive timer 字段大小为两个字节，0表示客户端用于不会断开。</p>\n<h1 id=\"Connect-return-code-返回码\"><a href=\"#Connect-return-code-返回码\" class=\"headerlink\" title=\"Connect return code 返回码\"></a>Connect return code 返回码</h1><p>connect return code出现 在CONNACK 消息中，大小为一个字节，当前有意义的值是：</p>\n<ul>\n<li>0x00 : 接受连接</li>\n<li>0x01:  拒绝连接，协议版本不可用</li>\n<li>0x02:  连接失败，标识拒绝</li>\n<li>0x03:  服务器连接失败</li>\n<li>0x04:  用户名和密码错误</li>\n<li>0x05:  没有验证</li>\n</ul>\n<h1 id=\"Topic-name-订阅名称）\"><a href=\"#Topic-name-订阅名称）\" class=\"headerlink\" title=\"Topic name (订阅名称）\"></a>Topic name (订阅名称）</h1><p>topic name 出现在MQTT PUBLISH 消息的可变头部，用来标明发布消息所属的channel，订阅时使用该值来标明从哪里接收发布消息。</p>\n"},{"title":"Nginx配置","date":"2015-11-16T03:50:57.000Z","_content":"Nginx配置文件详细说明\n\n在此记录下Nginx服务器nginx.conf的配置文件说明, 部分注释收集与网络.\n\n#运行用户\nuser www-data;    \n#启动进程,通常设置成和cpu的数量相等\nworker_processes  1;\n\n#全局错误日志及PID文件\nerror_log  /var/log/nginx/error.log;\npid        /var/run/nginx.pid;\n\n#工作模式及连接数上限\n```\nevents {\n    use   epoll;             #epoll是多路复用IO(I/O Multiplexing)中的一种方式,但是仅用于linux2.6以上内核,可以大大提高nginx的性能\n    worker_connections  1024;#单个后台worker process进程的最大并发链接数\n    # multi_accept on; \n}```\n\n#设定http服务器，利用它的反向代理功能提供负载均衡支持\n```\nhttp {\n  #设定mime类型,类型由mime.type文件定义\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n    #设定日志格式\n    access_log    /var/log/nginx/access.log;\n\n    #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件，对于普通应用，\n    #必须设为 on,如果用来进行下载等应用磁盘IO重负载应用，可设置为 off，以平衡磁盘与网络I/O处理速度，降低系统的uptime.\n    sendfile        on;\n    #tcp_nopush     on;\n\n    #连接超时时间\n    #keepalive_timeout  0;\n    keepalive_timeout  65;\n    tcp_nodelay        on;\n    \n    #开启gzip压缩\n    gzip  on;\n    gzip_disable \"MSIE [1-6]\\.(?!.*SV1)\";\n\n    #设定请求缓冲\n    client_header_buffer_size    1k;\n    large_client_header_buffers  4 4k;\n\n    include /etc/nginx/conf.d/*.conf;\n    include /etc/nginx/sites-enabled/*;\n\n    #设定负载均衡的服务器列表\n     upstream mysvr {\n    #weigth参数表示权值，权值越高被分配到的几率越大\n    #本机上的Squid开启3128端口\n    server 192.168.8.1:3128 weight=5;\n    server 192.168.8.2:80  weight=1;\n    server 192.168.8.3:80  weight=6;\n    }\n\n\n   server {\n    #侦听80端口\n        listen       80;\n        #定义使用www.xx.com访问\n        server_name  www.xx.com;\n\n        #设定本虚拟主机的访问日志\n        access_log  logs/www.xx.com.access.log  main;\n\n    #默认请求\n    location / {\n          root   /root;      #定义服务器的默认网站根目录位置\n          index index.php index.html index.htm;   #定义首页索引文件的名称\n\n          fastcgi_pass  www.xx.com;\n         fastcgi_param  SCRIPT_FILENAME  $document_root/$fastcgi_script_name; \n          include /etc/nginx/fastcgi_params;\n        }\n\n    # 定义错误提示页面\n    error_page   500 502 503 504 /50x.html;  \n        location = /50x.html {\n        root   /root;\n    }\n\n    #静态文件，nginx自己处理\n    location ~ ^/(images|javascript|js|css|flash|media|static)/ {\n        root /var/www/virtual/htdocs;\n        #过期30天，静态文件不怎么更新，过期可以设大一点，如果频繁更新，则可以设置得小一点。\n        expires 30d;\n    }\n    #PHP 脚本请求全部转发到 FastCGI处理. 使用FastCGI默认配置.\n    location ~ \\.php$ {\n        root /root;\n        fastcgi_pass 127.0.0.1:9000;\n        fastcgi_index index.php;\n        fastcgi_param SCRIPT_FILENAME /home/www/www$fastcgi_script_name;\n        include fastcgi_params;\n    }\n    #设定查看Nginx状态的地址\n    location /NginxStatus {\n        stub_status            on;\n        access_log              on;\n        auth_basic              \"NginxStatus\";\n        auth_basic_user_file  conf/htpasswd;\n    }\n    #禁止访问 .htxxx 文件\n    location ~ /\\.ht {\n        deny all;\n    }\n     \n     }\n}\n```\n以上是一些基本的配置,使用Nginx最大的好处就是负载均衡\n\n如果要使用负载均衡的话,可以修改配置http节点如下：\n\n#设定http服务器，利用它的反向代理功能提供负载均衡支持\n```\nhttp {\n     #设定mime类型,类型由mime.type文件定义\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n    #设定日志格式\n    access_log    /var/log/nginx/access.log;\n\n    #省略上文有的一些配置节点\n\n    #。。。。。。。。。。\n\n    #设定负载均衡的服务器列表\n     upstream mysvr {\n    #weigth参数表示权值，权值越高被分配到的几率越大\n    server 192.168.8.1x:3128 weight=5;#本机上的Squid开启3128端口\n    server 192.168.8.2x:80  weight=1;\n    server 192.168.8.3x:80  weight=6;\n    }\n\n   upstream mysvr2 {\n    #weigth参数表示权值，权值越高被分配到的几率越大\n\n    server 192.168.8.x:80  weight=1;\n    server 192.168.8.x:80  weight=6;\n    }\n\n   #第一个虚拟服务器\n   server {\n    #侦听192.168.8.x的80端口\n        listen       80;\n        server_name  192.168.8.x;\n\n      #对aspx后缀的进行负载均衡请求\n    location ~ .*\\.aspx$ {\n\n         root   /root;      #定义服务器的默认网站根目录位置\n          index index.php index.html index.htm;   #定义首页索引文件的名称\n\n          proxy_pass  http://mysvr ;#请求转向mysvr 定义的服务器列表\n\n          #以下是一些反向代理的配置可删除.\n\n          proxy_redirect off;\n\n          #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP\n          proxy_set_header Host $host;\n          proxy_set_header X-Real-IP $remote_addr;\n          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n          client_max_body_size 10m;    #允许客户端请求的最大单文件字节数\n          client_body_buffer_size 128k;  #缓冲区代理缓冲用户端请求的最大字节数，\n          proxy_connect_timeout 90;  #nginx跟后端服务器连接超时时间(代理连接超时)\n          proxy_send_timeout 90;        #后端服务器数据回传时间(代理发送超时)\n          proxy_read_timeout 90;         #连接成功后，后端服务器响应时间(代理接收超时)\n          proxy_buffer_size 4k;             #设置代理服务器（nginx）保存用户头信息的缓冲区大小\n          proxy_buffers 4 32k;               #proxy_buffers缓冲区，网页平均在32k以下的话，这样设置\n          proxy_busy_buffers_size 64k;    #高负荷下缓冲大小（proxy_buffers*2）\n          proxy_temp_file_write_size 64k;  #设定缓存文件夹大小，大于这个值，将从upstream服务器传\n\n       }\n\n     }\n}\n```\n","source":"_posts/Nginx配置.md","raw":"title: Nginx配置\ndate: 2015-11-16 11:50:57\ntags: [Nginx]\n---\nNginx配置文件详细说明\n\n在此记录下Nginx服务器nginx.conf的配置文件说明, 部分注释收集与网络.\n\n#运行用户\nuser www-data;    \n#启动进程,通常设置成和cpu的数量相等\nworker_processes  1;\n\n#全局错误日志及PID文件\nerror_log  /var/log/nginx/error.log;\npid        /var/run/nginx.pid;\n\n#工作模式及连接数上限\n```\nevents {\n    use   epoll;             #epoll是多路复用IO(I/O Multiplexing)中的一种方式,但是仅用于linux2.6以上内核,可以大大提高nginx的性能\n    worker_connections  1024;#单个后台worker process进程的最大并发链接数\n    # multi_accept on; \n}```\n\n#设定http服务器，利用它的反向代理功能提供负载均衡支持\n```\nhttp {\n  #设定mime类型,类型由mime.type文件定义\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n    #设定日志格式\n    access_log    /var/log/nginx/access.log;\n\n    #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件，对于普通应用，\n    #必须设为 on,如果用来进行下载等应用磁盘IO重负载应用，可设置为 off，以平衡磁盘与网络I/O处理速度，降低系统的uptime.\n    sendfile        on;\n    #tcp_nopush     on;\n\n    #连接超时时间\n    #keepalive_timeout  0;\n    keepalive_timeout  65;\n    tcp_nodelay        on;\n    \n    #开启gzip压缩\n    gzip  on;\n    gzip_disable \"MSIE [1-6]\\.(?!.*SV1)\";\n\n    #设定请求缓冲\n    client_header_buffer_size    1k;\n    large_client_header_buffers  4 4k;\n\n    include /etc/nginx/conf.d/*.conf;\n    include /etc/nginx/sites-enabled/*;\n\n    #设定负载均衡的服务器列表\n     upstream mysvr {\n    #weigth参数表示权值，权值越高被分配到的几率越大\n    #本机上的Squid开启3128端口\n    server 192.168.8.1:3128 weight=5;\n    server 192.168.8.2:80  weight=1;\n    server 192.168.8.3:80  weight=6;\n    }\n\n\n   server {\n    #侦听80端口\n        listen       80;\n        #定义使用www.xx.com访问\n        server_name  www.xx.com;\n\n        #设定本虚拟主机的访问日志\n        access_log  logs/www.xx.com.access.log  main;\n\n    #默认请求\n    location / {\n          root   /root;      #定义服务器的默认网站根目录位置\n          index index.php index.html index.htm;   #定义首页索引文件的名称\n\n          fastcgi_pass  www.xx.com;\n         fastcgi_param  SCRIPT_FILENAME  $document_root/$fastcgi_script_name; \n          include /etc/nginx/fastcgi_params;\n        }\n\n    # 定义错误提示页面\n    error_page   500 502 503 504 /50x.html;  \n        location = /50x.html {\n        root   /root;\n    }\n\n    #静态文件，nginx自己处理\n    location ~ ^/(images|javascript|js|css|flash|media|static)/ {\n        root /var/www/virtual/htdocs;\n        #过期30天，静态文件不怎么更新，过期可以设大一点，如果频繁更新，则可以设置得小一点。\n        expires 30d;\n    }\n    #PHP 脚本请求全部转发到 FastCGI处理. 使用FastCGI默认配置.\n    location ~ \\.php$ {\n        root /root;\n        fastcgi_pass 127.0.0.1:9000;\n        fastcgi_index index.php;\n        fastcgi_param SCRIPT_FILENAME /home/www/www$fastcgi_script_name;\n        include fastcgi_params;\n    }\n    #设定查看Nginx状态的地址\n    location /NginxStatus {\n        stub_status            on;\n        access_log              on;\n        auth_basic              \"NginxStatus\";\n        auth_basic_user_file  conf/htpasswd;\n    }\n    #禁止访问 .htxxx 文件\n    location ~ /\\.ht {\n        deny all;\n    }\n     \n     }\n}\n```\n以上是一些基本的配置,使用Nginx最大的好处就是负载均衡\n\n如果要使用负载均衡的话,可以修改配置http节点如下：\n\n#设定http服务器，利用它的反向代理功能提供负载均衡支持\n```\nhttp {\n     #设定mime类型,类型由mime.type文件定义\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n    #设定日志格式\n    access_log    /var/log/nginx/access.log;\n\n    #省略上文有的一些配置节点\n\n    #。。。。。。。。。。\n\n    #设定负载均衡的服务器列表\n     upstream mysvr {\n    #weigth参数表示权值，权值越高被分配到的几率越大\n    server 192.168.8.1x:3128 weight=5;#本机上的Squid开启3128端口\n    server 192.168.8.2x:80  weight=1;\n    server 192.168.8.3x:80  weight=6;\n    }\n\n   upstream mysvr2 {\n    #weigth参数表示权值，权值越高被分配到的几率越大\n\n    server 192.168.8.x:80  weight=1;\n    server 192.168.8.x:80  weight=6;\n    }\n\n   #第一个虚拟服务器\n   server {\n    #侦听192.168.8.x的80端口\n        listen       80;\n        server_name  192.168.8.x;\n\n      #对aspx后缀的进行负载均衡请求\n    location ~ .*\\.aspx$ {\n\n         root   /root;      #定义服务器的默认网站根目录位置\n          index index.php index.html index.htm;   #定义首页索引文件的名称\n\n          proxy_pass  http://mysvr ;#请求转向mysvr 定义的服务器列表\n\n          #以下是一些反向代理的配置可删除.\n\n          proxy_redirect off;\n\n          #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP\n          proxy_set_header Host $host;\n          proxy_set_header X-Real-IP $remote_addr;\n          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n          client_max_body_size 10m;    #允许客户端请求的最大单文件字节数\n          client_body_buffer_size 128k;  #缓冲区代理缓冲用户端请求的最大字节数，\n          proxy_connect_timeout 90;  #nginx跟后端服务器连接超时时间(代理连接超时)\n          proxy_send_timeout 90;        #后端服务器数据回传时间(代理发送超时)\n          proxy_read_timeout 90;         #连接成功后，后端服务器响应时间(代理接收超时)\n          proxy_buffer_size 4k;             #设置代理服务器（nginx）保存用户头信息的缓冲区大小\n          proxy_buffers 4 32k;               #proxy_buffers缓冲区，网页平均在32k以下的话，这样设置\n          proxy_busy_buffers_size 64k;    #高负荷下缓冲大小（proxy_buffers*2）\n          proxy_temp_file_write_size 64k;  #设定缓存文件夹大小，大于这个值，将从upstream服务器传\n\n       }\n\n     }\n}\n```\n","slug":"Nginx配置","published":1,"updated":"2019-08-21T01:49:04.128Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzkm7pq70009jl9u479qhc33","content":"<p>Nginx配置文件详细说明</p>\n<p>在此记录下Nginx服务器nginx.conf的配置文件说明, 部分注释收集与网络.</p>\n<p>#运行用户<br>user www-data;    </p>\n<p>#启动进程,通常设置成和cpu的数量相等<br>worker_processes  1;</p>\n<p>#全局错误日志及PID文件<br>error_log  /var/log/nginx/error.log;<br>pid        /var/run/nginx.pid;</p>\n<p>#工作模式及连接数上限</p>\n<pre><code>events {\n    use   epoll;             #epoll是多路复用IO(I/O Multiplexing)中的一种方式,但是仅用于linux2.6以上内核,可以大大提高nginx的性能\n    worker_connections  1024;#单个后台worker process进程的最大并发链接数\n    # multi_accept on; \n}\n</code></pre><p>#设定http服务器，利用它的反向代理功能提供负载均衡支持</p>\n<pre><code>http {\n  #设定mime类型,类型由mime.type文件定义\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n    #设定日志格式\n    access_log    /var/log/nginx/access.log;\n\n    #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件，对于普通应用，\n    #必须设为 on,如果用来进行下载等应用磁盘IO重负载应用，可设置为 off，以平衡磁盘与网络I/O处理速度，降低系统的uptime.\n    sendfile        on;\n    #tcp_nopush     on;\n\n    #连接超时时间\n    #keepalive_timeout  0;\n    keepalive_timeout  65;\n    tcp_nodelay        on;\n\n    #开启gzip压缩\n    gzip  on;\n    gzip_disable &quot;MSIE [1-6]\\.(?!.*SV1)&quot;;\n\n    #设定请求缓冲\n    client_header_buffer_size    1k;\n    large_client_header_buffers  4 4k;\n\n    include /etc/nginx/conf.d/*.conf;\n    include /etc/nginx/sites-enabled/*;\n\n    #设定负载均衡的服务器列表\n     upstream mysvr {\n    #weigth参数表示权值，权值越高被分配到的几率越大\n    #本机上的Squid开启3128端口\n    server 192.168.8.1:3128 weight=5;\n    server 192.168.8.2:80  weight=1;\n    server 192.168.8.3:80  weight=6;\n    }\n\n\n   server {\n    #侦听80端口\n        listen       80;\n        #定义使用www.xx.com访问\n        server_name  www.xx.com;\n\n        #设定本虚拟主机的访问日志\n        access_log  logs/www.xx.com.access.log  main;\n\n    #默认请求\n    location / {\n          root   /root;      #定义服务器的默认网站根目录位置\n          index index.php index.html index.htm;   #定义首页索引文件的名称\n\n          fastcgi_pass  www.xx.com;\n         fastcgi_param  SCRIPT_FILENAME  $document_root/$fastcgi_script_name; \n          include /etc/nginx/fastcgi_params;\n        }\n\n    # 定义错误提示页面\n    error_page   500 502 503 504 /50x.html;  \n        location = /50x.html {\n        root   /root;\n    }\n\n    #静态文件，nginx自己处理\n    location ~ ^/(images|javascript|js|css|flash|media|static)/ {\n        root /var/www/virtual/htdocs;\n        #过期30天，静态文件不怎么更新，过期可以设大一点，如果频繁更新，则可以设置得小一点。\n        expires 30d;\n    }\n    #PHP 脚本请求全部转发到 FastCGI处理. 使用FastCGI默认配置.\n    location ~ \\.php$ {\n        root /root;\n        fastcgi_pass 127.0.0.1:9000;\n        fastcgi_index index.php;\n        fastcgi_param SCRIPT_FILENAME /home/www/www$fastcgi_script_name;\n        include fastcgi_params;\n    }\n    #设定查看Nginx状态的地址\n    location /NginxStatus {\n        stub_status            on;\n        access_log              on;\n        auth_basic              &quot;NginxStatus&quot;;\n        auth_basic_user_file  conf/htpasswd;\n    }\n    #禁止访问 .htxxx 文件\n    location ~ /\\.ht {\n        deny all;\n    }\n\n     }\n}\n</code></pre><p>以上是一些基本的配置,使用Nginx最大的好处就是负载均衡</p>\n<p>如果要使用负载均衡的话,可以修改配置http节点如下：</p>\n<p>#设定http服务器，利用它的反向代理功能提供负载均衡支持</p>\n<pre><code>http {\n     #设定mime类型,类型由mime.type文件定义\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n    #设定日志格式\n    access_log    /var/log/nginx/access.log;\n\n    #省略上文有的一些配置节点\n\n    #。。。。。。。。。。\n\n    #设定负载均衡的服务器列表\n     upstream mysvr {\n    #weigth参数表示权值，权值越高被分配到的几率越大\n    server 192.168.8.1x:3128 weight=5;#本机上的Squid开启3128端口\n    server 192.168.8.2x:80  weight=1;\n    server 192.168.8.3x:80  weight=6;\n    }\n\n   upstream mysvr2 {\n    #weigth参数表示权值，权值越高被分配到的几率越大\n\n    server 192.168.8.x:80  weight=1;\n    server 192.168.8.x:80  weight=6;\n    }\n\n   #第一个虚拟服务器\n   server {\n    #侦听192.168.8.x的80端口\n        listen       80;\n        server_name  192.168.8.x;\n\n      #对aspx后缀的进行负载均衡请求\n    location ~ .*\\.aspx$ {\n\n         root   /root;      #定义服务器的默认网站根目录位置\n          index index.php index.html index.htm;   #定义首页索引文件的名称\n\n          proxy_pass  http://mysvr ;#请求转向mysvr 定义的服务器列表\n\n          #以下是一些反向代理的配置可删除.\n\n          proxy_redirect off;\n\n          #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP\n          proxy_set_header Host $host;\n          proxy_set_header X-Real-IP $remote_addr;\n          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n          client_max_body_size 10m;    #允许客户端请求的最大单文件字节数\n          client_body_buffer_size 128k;  #缓冲区代理缓冲用户端请求的最大字节数，\n          proxy_connect_timeout 90;  #nginx跟后端服务器连接超时时间(代理连接超时)\n          proxy_send_timeout 90;        #后端服务器数据回传时间(代理发送超时)\n          proxy_read_timeout 90;         #连接成功后，后端服务器响应时间(代理接收超时)\n          proxy_buffer_size 4k;             #设置代理服务器（nginx）保存用户头信息的缓冲区大小\n          proxy_buffers 4 32k;               #proxy_buffers缓冲区，网页平均在32k以下的话，这样设置\n          proxy_busy_buffers_size 64k;    #高负荷下缓冲大小（proxy_buffers*2）\n          proxy_temp_file_write_size 64k;  #设定缓存文件夹大小，大于这个值，将从upstream服务器传\n\n       }\n\n     }\n}\n</code></pre>","site":{"data":{}},"excerpt":"","more":"<p>Nginx配置文件详细说明</p>\n<p>在此记录下Nginx服务器nginx.conf的配置文件说明, 部分注释收集与网络.</p>\n<p>#运行用户<br>user www-data;    </p>\n<p>#启动进程,通常设置成和cpu的数量相等<br>worker_processes  1;</p>\n<p>#全局错误日志及PID文件<br>error_log  /var/log/nginx/error.log;<br>pid        /var/run/nginx.pid;</p>\n<p>#工作模式及连接数上限</p>\n<pre><code>events {\n    use   epoll;             #epoll是多路复用IO(I/O Multiplexing)中的一种方式,但是仅用于linux2.6以上内核,可以大大提高nginx的性能\n    worker_connections  1024;#单个后台worker process进程的最大并发链接数\n    # multi_accept on; \n}\n</code></pre><p>#设定http服务器，利用它的反向代理功能提供负载均衡支持</p>\n<pre><code>http {\n  #设定mime类型,类型由mime.type文件定义\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n    #设定日志格式\n    access_log    /var/log/nginx/access.log;\n\n    #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件，对于普通应用，\n    #必须设为 on,如果用来进行下载等应用磁盘IO重负载应用，可设置为 off，以平衡磁盘与网络I/O处理速度，降低系统的uptime.\n    sendfile        on;\n    #tcp_nopush     on;\n\n    #连接超时时间\n    #keepalive_timeout  0;\n    keepalive_timeout  65;\n    tcp_nodelay        on;\n\n    #开启gzip压缩\n    gzip  on;\n    gzip_disable &quot;MSIE [1-6]\\.(?!.*SV1)&quot;;\n\n    #设定请求缓冲\n    client_header_buffer_size    1k;\n    large_client_header_buffers  4 4k;\n\n    include /etc/nginx/conf.d/*.conf;\n    include /etc/nginx/sites-enabled/*;\n\n    #设定负载均衡的服务器列表\n     upstream mysvr {\n    #weigth参数表示权值，权值越高被分配到的几率越大\n    #本机上的Squid开启3128端口\n    server 192.168.8.1:3128 weight=5;\n    server 192.168.8.2:80  weight=1;\n    server 192.168.8.3:80  weight=6;\n    }\n\n\n   server {\n    #侦听80端口\n        listen       80;\n        #定义使用www.xx.com访问\n        server_name  www.xx.com;\n\n        #设定本虚拟主机的访问日志\n        access_log  logs/www.xx.com.access.log  main;\n\n    #默认请求\n    location / {\n          root   /root;      #定义服务器的默认网站根目录位置\n          index index.php index.html index.htm;   #定义首页索引文件的名称\n\n          fastcgi_pass  www.xx.com;\n         fastcgi_param  SCRIPT_FILENAME  $document_root/$fastcgi_script_name; \n          include /etc/nginx/fastcgi_params;\n        }\n\n    # 定义错误提示页面\n    error_page   500 502 503 504 /50x.html;  \n        location = /50x.html {\n        root   /root;\n    }\n\n    #静态文件，nginx自己处理\n    location ~ ^/(images|javascript|js|css|flash|media|static)/ {\n        root /var/www/virtual/htdocs;\n        #过期30天，静态文件不怎么更新，过期可以设大一点，如果频繁更新，则可以设置得小一点。\n        expires 30d;\n    }\n    #PHP 脚本请求全部转发到 FastCGI处理. 使用FastCGI默认配置.\n    location ~ \\.php$ {\n        root /root;\n        fastcgi_pass 127.0.0.1:9000;\n        fastcgi_index index.php;\n        fastcgi_param SCRIPT_FILENAME /home/www/www$fastcgi_script_name;\n        include fastcgi_params;\n    }\n    #设定查看Nginx状态的地址\n    location /NginxStatus {\n        stub_status            on;\n        access_log              on;\n        auth_basic              &quot;NginxStatus&quot;;\n        auth_basic_user_file  conf/htpasswd;\n    }\n    #禁止访问 .htxxx 文件\n    location ~ /\\.ht {\n        deny all;\n    }\n\n     }\n}\n</code></pre><p>以上是一些基本的配置,使用Nginx最大的好处就是负载均衡</p>\n<p>如果要使用负载均衡的话,可以修改配置http节点如下：</p>\n<p>#设定http服务器，利用它的反向代理功能提供负载均衡支持</p>\n<pre><code>http {\n     #设定mime类型,类型由mime.type文件定义\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n    #设定日志格式\n    access_log    /var/log/nginx/access.log;\n\n    #省略上文有的一些配置节点\n\n    #。。。。。。。。。。\n\n    #设定负载均衡的服务器列表\n     upstream mysvr {\n    #weigth参数表示权值，权值越高被分配到的几率越大\n    server 192.168.8.1x:3128 weight=5;#本机上的Squid开启3128端口\n    server 192.168.8.2x:80  weight=1;\n    server 192.168.8.3x:80  weight=6;\n    }\n\n   upstream mysvr2 {\n    #weigth参数表示权值，权值越高被分配到的几率越大\n\n    server 192.168.8.x:80  weight=1;\n    server 192.168.8.x:80  weight=6;\n    }\n\n   #第一个虚拟服务器\n   server {\n    #侦听192.168.8.x的80端口\n        listen       80;\n        server_name  192.168.8.x;\n\n      #对aspx后缀的进行负载均衡请求\n    location ~ .*\\.aspx$ {\n\n         root   /root;      #定义服务器的默认网站根目录位置\n          index index.php index.html index.htm;   #定义首页索引文件的名称\n\n          proxy_pass  http://mysvr ;#请求转向mysvr 定义的服务器列表\n\n          #以下是一些反向代理的配置可删除.\n\n          proxy_redirect off;\n\n          #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP\n          proxy_set_header Host $host;\n          proxy_set_header X-Real-IP $remote_addr;\n          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n          client_max_body_size 10m;    #允许客户端请求的最大单文件字节数\n          client_body_buffer_size 128k;  #缓冲区代理缓冲用户端请求的最大字节数，\n          proxy_connect_timeout 90;  #nginx跟后端服务器连接超时时间(代理连接超时)\n          proxy_send_timeout 90;        #后端服务器数据回传时间(代理发送超时)\n          proxy_read_timeout 90;         #连接成功后，后端服务器响应时间(代理接收超时)\n          proxy_buffer_size 4k;             #设置代理服务器（nginx）保存用户头信息的缓冲区大小\n          proxy_buffers 4 32k;               #proxy_buffers缓冲区，网页平均在32k以下的话，这样设置\n          proxy_busy_buffers_size 64k;    #高负荷下缓冲大小（proxy_buffers*2）\n          proxy_temp_file_write_size 64k;  #设定缓存文件夹大小，大于这个值，将从upstream服务器传\n\n       }\n\n     }\n}\n</code></pre>"},{"title":"linux下写swift","date":"2015-12-10T02:42:07.000Z","_content":"swift 终于开源了，赶紧用linux尝尝鲜。\n目前swift支持的linux版本有 ubuntu15.10 和ubuntu 14.04.下面我会用Ubuntu14.04.1来尝尝鲜。\n\n\n安装\n=====\n具体的手动安装教程可以在swift的[github仓库](https://github.com/apple/swift)查看.\n\n当然，苹果也提供的ubuntu的swift安装包，如果不想折腾就直接下载安装吧：\n- 使用`wget`获取安装包：`wget https://swift.org/builds/ubuntu1404/swift-2.2-SNAPSHOT-2015-12-01-b/swift-2.2-SNAPSHOT-2015-12-01-b-ubuntu14.04.tar.gz`\n\n-解压：`tar -zxvf swift-2.2-SNAPSHOT-2015-12-01-b-ubuntu14.04.tar.gz`\n\n-添加swift路径到PATH变量： `export PATH=/path/to/swift-2.2-SNAPSHOT-2015-12-01-b-ubuntu14.04/usr/bin/:\"${PATH}\"`\n\n-确保所有的swift依赖包都安装了：1. apt-get update  2. sudo apt-get install git cmake ninja-build clang uuid-dev libicu-dev icu-devtools libbsd-dev libedit-dev libxml2-dev libsqlite3-dev swig libpython-dev libncurses5-dev pkg-config\n\n安装完后输入`swift --version`会出现版本信息时，那么恭喜你安装成功了，赶紧用swift 去coding一些有趣的东西吧。\n```swift\nroot@localhost:/mnt/hgfs/workspace# swift --version\nSwift version 2.2-dev (LLVM 46be9ff861, Clang 4deb154edc, Swift 778f82939c)\nTarget: x86_64-unknown-linux-gnu\n```\n\n\nREPL\n=====\nswift 提供了一个终端 REPL(read eval print loop) 进行交互\n```swift\n\nroot@localhost:/mnt/hgfs/workspace/mpreader# swift\nWelcome to Swift version 2.2-dev (LLVM 46be9ff861, Clang 4deb154edc, Swift 778f82939c). Type :help for assistance.\n 1>  \n 2>  \n 16> let sum = 100\nsum: Int = 100\n17> if sum > 10 { print(\"\\(sum) bigger than 10\")}\n44 bigger than 10\n 18> if sum > 10 { \n 19.     print(\"\\(sum) bigger than 10\") \n 20.  \n 21. } \n44 bigger than 10\n```\n退出REPL的命令是`:q`\n\n编译swift文件\n=====\n`root@localhost:/mnt/hgfs/workspace# vim testSwift.swift`\n```swift\nimport Foundation\nimport Glibc\n\n\nlet player = [\"rock\", \"paper\", \"scissors\", \"lizard\", \"spock\"]\n\nsrandom(UInt32(NSDate().timeIntervalSince1970))\nfor count in 1...3 {\n    print(count)\n    sleep(1)\n}\n\nprint(player[random() % player.count]);\n```\n\n执行 `swift testSwift.swift` 就会执行testSwift.swift文件的内容。\n```shell\nroot@localhost:/mnt/hgfs/workspace# swift main.swift \n1\n2\n3\nrock\n```\n\n构建swift程序包\n======\nswift同时开源了包管理项目，一个swift bao的文件组成如下 ：\n```\nexample-package-playingcard \n├── Sources │ \n    ├── PlayingCard.swift │ \n    ├── Rank.swift \n    │ └── Suit.swift \n└── Package.swift\n```\n由源代码文件在`source`目录下，和 `manifest file` 文件Package.swift组成，`Package.swift`就是定义一个package类的实例，用于表述包的基本信息和其依赖的包：\n```swift\nimport PackageDescription \nlet package = Package( name: \"DeckOfPlayingCards\", targets: [], dependencies: [ .Package(url: \"https://github.com/apple/example-package-fisheryates.git\", majorVersion: 1), .Package(url: \"https://github.com/apple/example-package-playingcard.git\", majorVersion: 1), ] )\n```\n通过`swift build` 就会编译并且生成包的执行文件 ：`./.build/debug/packagename`\n","source":"_posts/coding-with-swift-on-linux.md","raw":"title: linux下写swift\ndate: 2015-12-10 10:42:07\ntags: [Swift]\n---\nswift 终于开源了，赶紧用linux尝尝鲜。\n目前swift支持的linux版本有 ubuntu15.10 和ubuntu 14.04.下面我会用Ubuntu14.04.1来尝尝鲜。\n\n\n安装\n=====\n具体的手动安装教程可以在swift的[github仓库](https://github.com/apple/swift)查看.\n\n当然，苹果也提供的ubuntu的swift安装包，如果不想折腾就直接下载安装吧：\n- 使用`wget`获取安装包：`wget https://swift.org/builds/ubuntu1404/swift-2.2-SNAPSHOT-2015-12-01-b/swift-2.2-SNAPSHOT-2015-12-01-b-ubuntu14.04.tar.gz`\n\n-解压：`tar -zxvf swift-2.2-SNAPSHOT-2015-12-01-b-ubuntu14.04.tar.gz`\n\n-添加swift路径到PATH变量： `export PATH=/path/to/swift-2.2-SNAPSHOT-2015-12-01-b-ubuntu14.04/usr/bin/:\"${PATH}\"`\n\n-确保所有的swift依赖包都安装了：1. apt-get update  2. sudo apt-get install git cmake ninja-build clang uuid-dev libicu-dev icu-devtools libbsd-dev libedit-dev libxml2-dev libsqlite3-dev swig libpython-dev libncurses5-dev pkg-config\n\n安装完后输入`swift --version`会出现版本信息时，那么恭喜你安装成功了，赶紧用swift 去coding一些有趣的东西吧。\n```swift\nroot@localhost:/mnt/hgfs/workspace# swift --version\nSwift version 2.2-dev (LLVM 46be9ff861, Clang 4deb154edc, Swift 778f82939c)\nTarget: x86_64-unknown-linux-gnu\n```\n\n\nREPL\n=====\nswift 提供了一个终端 REPL(read eval print loop) 进行交互\n```swift\n\nroot@localhost:/mnt/hgfs/workspace/mpreader# swift\nWelcome to Swift version 2.2-dev (LLVM 46be9ff861, Clang 4deb154edc, Swift 778f82939c). Type :help for assistance.\n 1>  \n 2>  \n 16> let sum = 100\nsum: Int = 100\n17> if sum > 10 { print(\"\\(sum) bigger than 10\")}\n44 bigger than 10\n 18> if sum > 10 { \n 19.     print(\"\\(sum) bigger than 10\") \n 20.  \n 21. } \n44 bigger than 10\n```\n退出REPL的命令是`:q`\n\n编译swift文件\n=====\n`root@localhost:/mnt/hgfs/workspace# vim testSwift.swift`\n```swift\nimport Foundation\nimport Glibc\n\n\nlet player = [\"rock\", \"paper\", \"scissors\", \"lizard\", \"spock\"]\n\nsrandom(UInt32(NSDate().timeIntervalSince1970))\nfor count in 1...3 {\n    print(count)\n    sleep(1)\n}\n\nprint(player[random() % player.count]);\n```\n\n执行 `swift testSwift.swift` 就会执行testSwift.swift文件的内容。\n```shell\nroot@localhost:/mnt/hgfs/workspace# swift main.swift \n1\n2\n3\nrock\n```\n\n构建swift程序包\n======\nswift同时开源了包管理项目，一个swift bao的文件组成如下 ：\n```\nexample-package-playingcard \n├── Sources │ \n    ├── PlayingCard.swift │ \n    ├── Rank.swift \n    │ └── Suit.swift \n└── Package.swift\n```\n由源代码文件在`source`目录下，和 `manifest file` 文件Package.swift组成，`Package.swift`就是定义一个package类的实例，用于表述包的基本信息和其依赖的包：\n```swift\nimport PackageDescription \nlet package = Package( name: \"DeckOfPlayingCards\", targets: [], dependencies: [ .Package(url: \"https://github.com/apple/example-package-fisheryates.git\", majorVersion: 1), .Package(url: \"https://github.com/apple/example-package-playingcard.git\", majorVersion: 1), ] )\n```\n通过`swift build` 就会编译并且生成包的执行文件 ：`./.build/debug/packagename`\n","slug":"coding-with-swift-on-linux","published":1,"updated":"2019-08-21T01:49:04.128Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzkm7pq8000ajl9uxj9mnnk4","content":"<p>swift 终于开源了，赶紧用linux尝尝鲜。<br>目前swift支持的linux版本有 ubuntu15.10 和ubuntu 14.04.下面我会用Ubuntu14.04.1来尝尝鲜。</p>\n<h1 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h1><p>具体的手动安装教程可以在swift的<a href=\"https://github.com/apple/swift\" target=\"_blank\" rel=\"noopener\">github仓库</a>查看.</p>\n<p>当然，苹果也提供的ubuntu的swift安装包，如果不想折腾就直接下载安装吧：</p>\n<ul>\n<li>使用<code>wget</code>获取安装包：<code>wget https://swift.org/builds/ubuntu1404/swift-2.2-SNAPSHOT-2015-12-01-b/swift-2.2-SNAPSHOT-2015-12-01-b-ubuntu14.04.tar.gz</code></li>\n</ul>\n<p>-解压：<code>tar -zxvf swift-2.2-SNAPSHOT-2015-12-01-b-ubuntu14.04.tar.gz</code></p>\n<p>-添加swift路径到PATH变量： <code>export PATH=/path/to/swift-2.2-SNAPSHOT-2015-12-01-b-ubuntu14.04/usr/bin/:&quot;${PATH}&quot;</code></p>\n<p>-确保所有的swift依赖包都安装了：1. apt-get update  2. sudo apt-get install git cmake ninja-build clang uuid-dev libicu-dev icu-devtools libbsd-dev libedit-dev libxml2-dev libsqlite3-dev swig libpython-dev libncurses5-dev pkg-config</p>\n<p>安装完后输入<code>swift --version</code>会出现版本信息时，那么恭喜你安装成功了，赶紧用swift 去coding一些有趣的东西吧。</p>\n<pre><code class=\"swift\">root@localhost:/mnt/hgfs/workspace# swift --version\nSwift version 2.2-dev (LLVM 46be9ff861, Clang 4deb154edc, Swift 778f82939c)\nTarget: x86_64-unknown-linux-gnu\n</code></pre>\n<h1 id=\"REPL\"><a href=\"#REPL\" class=\"headerlink\" title=\"REPL\"></a>REPL</h1><p>swift 提供了一个终端 REPL(read eval print loop) 进行交互</p>\n<pre><code class=\"swift\">\nroot@localhost:/mnt/hgfs/workspace/mpreader# swift\nWelcome to Swift version 2.2-dev (LLVM 46be9ff861, Clang 4deb154edc, Swift 778f82939c). Type :help for assistance.\n 1&gt;  \n 2&gt;  \n 16&gt; let sum = 100\nsum: Int = 100\n17&gt; if sum &gt; 10 { print(&quot;\\(sum) bigger than 10&quot;)}\n44 bigger than 10\n 18&gt; if sum &gt; 10 { \n 19.     print(&quot;\\(sum) bigger than 10&quot;) \n 20.  \n 21. } \n44 bigger than 10\n</code></pre>\n<p>退出REPL的命令是<code>:q</code></p>\n<h1 id=\"编译swift文件\"><a href=\"#编译swift文件\" class=\"headerlink\" title=\"编译swift文件\"></a>编译swift文件</h1><p><code>root@localhost:/mnt/hgfs/workspace# vim testSwift.swift</code></p>\n<pre><code class=\"swift\">import Foundation\nimport Glibc\n\n\nlet player = [&quot;rock&quot;, &quot;paper&quot;, &quot;scissors&quot;, &quot;lizard&quot;, &quot;spock&quot;]\n\nsrandom(UInt32(NSDate().timeIntervalSince1970))\nfor count in 1...3 {\n    print(count)\n    sleep(1)\n}\n\nprint(player[random() % player.count]);\n</code></pre>\n<p>执行 <code>swift testSwift.swift</code> 就会执行testSwift.swift文件的内容。</p>\n<pre><code class=\"shell\">root@localhost:/mnt/hgfs/workspace# swift main.swift \n1\n2\n3\nrock\n</code></pre>\n<h1 id=\"构建swift程序包\"><a href=\"#构建swift程序包\" class=\"headerlink\" title=\"构建swift程序包\"></a>构建swift程序包</h1><p>swift同时开源了包管理项目，一个swift bao的文件组成如下 ：</p>\n<pre><code>example-package-playingcard \n├── Sources │ \n    ├── PlayingCard.swift │ \n    ├── Rank.swift \n    │ └── Suit.swift \n└── Package.swift\n</code></pre><p>由源代码文件在<code>source</code>目录下，和 <code>manifest file</code> 文件Package.swift组成，<code>Package.swift</code>就是定义一个package类的实例，用于表述包的基本信息和其依赖的包：</p>\n<pre><code class=\"swift\">import PackageDescription \nlet package = Package( name: &quot;DeckOfPlayingCards&quot;, targets: [], dependencies: [ .Package(url: &quot;https://github.com/apple/example-package-fisheryates.git&quot;, majorVersion: 1), .Package(url: &quot;https://github.com/apple/example-package-playingcard.git&quot;, majorVersion: 1), ] )\n</code></pre>\n<p>通过<code>swift build</code> 就会编译并且生成包的执行文件 ：<code>./.build/debug/packagename</code></p>\n","site":{"data":{}},"excerpt":"","more":"<p>swift 终于开源了，赶紧用linux尝尝鲜。<br>目前swift支持的linux版本有 ubuntu15.10 和ubuntu 14.04.下面我会用Ubuntu14.04.1来尝尝鲜。</p>\n<h1 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h1><p>具体的手动安装教程可以在swift的<a href=\"https://github.com/apple/swift\" target=\"_blank\" rel=\"noopener\">github仓库</a>查看.</p>\n<p>当然，苹果也提供的ubuntu的swift安装包，如果不想折腾就直接下载安装吧：</p>\n<ul>\n<li>使用<code>wget</code>获取安装包：<code>wget https://swift.org/builds/ubuntu1404/swift-2.2-SNAPSHOT-2015-12-01-b/swift-2.2-SNAPSHOT-2015-12-01-b-ubuntu14.04.tar.gz</code></li>\n</ul>\n<p>-解压：<code>tar -zxvf swift-2.2-SNAPSHOT-2015-12-01-b-ubuntu14.04.tar.gz</code></p>\n<p>-添加swift路径到PATH变量： <code>export PATH=/path/to/swift-2.2-SNAPSHOT-2015-12-01-b-ubuntu14.04/usr/bin/:&quot;${PATH}&quot;</code></p>\n<p>-确保所有的swift依赖包都安装了：1. apt-get update  2. sudo apt-get install git cmake ninja-build clang uuid-dev libicu-dev icu-devtools libbsd-dev libedit-dev libxml2-dev libsqlite3-dev swig libpython-dev libncurses5-dev pkg-config</p>\n<p>安装完后输入<code>swift --version</code>会出现版本信息时，那么恭喜你安装成功了，赶紧用swift 去coding一些有趣的东西吧。</p>\n<pre><code class=\"swift\">root@localhost:/mnt/hgfs/workspace# swift --version\nSwift version 2.2-dev (LLVM 46be9ff861, Clang 4deb154edc, Swift 778f82939c)\nTarget: x86_64-unknown-linux-gnu\n</code></pre>\n<h1 id=\"REPL\"><a href=\"#REPL\" class=\"headerlink\" title=\"REPL\"></a>REPL</h1><p>swift 提供了一个终端 REPL(read eval print loop) 进行交互</p>\n<pre><code class=\"swift\">\nroot@localhost:/mnt/hgfs/workspace/mpreader# swift\nWelcome to Swift version 2.2-dev (LLVM 46be9ff861, Clang 4deb154edc, Swift 778f82939c). Type :help for assistance.\n 1&gt;  \n 2&gt;  \n 16&gt; let sum = 100\nsum: Int = 100\n17&gt; if sum &gt; 10 { print(&quot;\\(sum) bigger than 10&quot;)}\n44 bigger than 10\n 18&gt; if sum &gt; 10 { \n 19.     print(&quot;\\(sum) bigger than 10&quot;) \n 20.  \n 21. } \n44 bigger than 10\n</code></pre>\n<p>退出REPL的命令是<code>:q</code></p>\n<h1 id=\"编译swift文件\"><a href=\"#编译swift文件\" class=\"headerlink\" title=\"编译swift文件\"></a>编译swift文件</h1><p><code>root@localhost:/mnt/hgfs/workspace# vim testSwift.swift</code></p>\n<pre><code class=\"swift\">import Foundation\nimport Glibc\n\n\nlet player = [&quot;rock&quot;, &quot;paper&quot;, &quot;scissors&quot;, &quot;lizard&quot;, &quot;spock&quot;]\n\nsrandom(UInt32(NSDate().timeIntervalSince1970))\nfor count in 1...3 {\n    print(count)\n    sleep(1)\n}\n\nprint(player[random() % player.count]);\n</code></pre>\n<p>执行 <code>swift testSwift.swift</code> 就会执行testSwift.swift文件的内容。</p>\n<pre><code class=\"shell\">root@localhost:/mnt/hgfs/workspace# swift main.swift \n1\n2\n3\nrock\n</code></pre>\n<h1 id=\"构建swift程序包\"><a href=\"#构建swift程序包\" class=\"headerlink\" title=\"构建swift程序包\"></a>构建swift程序包</h1><p>swift同时开源了包管理项目，一个swift bao的文件组成如下 ：</p>\n<pre><code>example-package-playingcard \n├── Sources │ \n    ├── PlayingCard.swift │ \n    ├── Rank.swift \n    │ └── Suit.swift \n└── Package.swift\n</code></pre><p>由源代码文件在<code>source</code>目录下，和 <code>manifest file</code> 文件Package.swift组成，<code>Package.swift</code>就是定义一个package类的实例，用于表述包的基本信息和其依赖的包：</p>\n<pre><code class=\"swift\">import PackageDescription \nlet package = Package( name: &quot;DeckOfPlayingCards&quot;, targets: [], dependencies: [ .Package(url: &quot;https://github.com/apple/example-package-fisheryates.git&quot;, majorVersion: 1), .Package(url: &quot;https://github.com/apple/example-package-playingcard.git&quot;, majorVersion: 1), ] )\n</code></pre>\n<p>通过<code>swift build</code> 就会编译并且生成包的执行文件 ：<code>./.build/debug/packagename</code></p>\n"},{"title":"io_lib:format 中文乱码探究","date":"2015-12-09T03:11:26.000Z","_content":"\n最近发现erlang项目的配置文件某些中文显示会乱码，先说下配置文件的实现：\n 1. 由file:consult/1读取配置的原始文件（一系列的erlang term），获取到原始的 erlang term\n 2. 再转化成erlang 代码 然后再会写到文件。\n\n问题就出在了转化erlang 代码这里，我们使用的是`io_lib:format(\"~p\",[data])` 来将erlang term 转化成字符串再回写到文件，而 `io:format/2`关于`~p/~w`在官方文档里面有这样的描述：\n>w\n>    Writes data with the standard syntax. This is used to output Erlang terms. Atoms are printed within quotes if they contain embedded non-printable \n>    characters, and floats are printed accurately as the shortest, correctly rounded string.\n>p\n>  Writes the data with standard syntax in the same way as ~w, but breaks terms whose printed representation is longer than one line into many lines and \n>     indents each line sensibly. It also tries to detect lists of printable characters and to output these as strings. The Unicode translation modifier is used for\n>     determining what characters are printable. \n\n也就是说，当我们使用`io:format(\"~p\",[Data])`来显示数据时，会根据data的binary数据是否可以转化成unicode可打印字符来打印数据，这时候中文的unicode就会每个字节逐个转化unicode\n因此：\n```erlang\n6> Bin1=unicode:characters_to_binary(\"书鬼\").\n<<228,185,166,233,172,188>>\n7> io:format(\"~p\",[Bin1]).\n<<\"ä¹¦é¬¼\">>ok\n8> Bin2=unicode:characters_to_binary(\"书盲\").\n<<228,185,166,231,155,178>>\n9> io:format(\"~p\",[Bin2]).    \n<<228,185,166,231,155,178>>ok\n\n48> io:format(\"~w\",[Bin1]).\n<<228,185,166,233,172,188>>ok\n49> io:format(\"~w\",[Bin2]).\n<<228,185,166,231,155,178>>ok\n```\n\n","source":"_posts/different-between-p-and-w-in-io-format.md","raw":"title: io_lib:format 中文乱码探究\ndate: 2015-12-09 11:11:26\ntags: [Erlang]\n---\n\n最近发现erlang项目的配置文件某些中文显示会乱码，先说下配置文件的实现：\n 1. 由file:consult/1读取配置的原始文件（一系列的erlang term），获取到原始的 erlang term\n 2. 再转化成erlang 代码 然后再会写到文件。\n\n问题就出在了转化erlang 代码这里，我们使用的是`io_lib:format(\"~p\",[data])` 来将erlang term 转化成字符串再回写到文件，而 `io:format/2`关于`~p/~w`在官方文档里面有这样的描述：\n>w\n>    Writes data with the standard syntax. This is used to output Erlang terms. Atoms are printed within quotes if they contain embedded non-printable \n>    characters, and floats are printed accurately as the shortest, correctly rounded string.\n>p\n>  Writes the data with standard syntax in the same way as ~w, but breaks terms whose printed representation is longer than one line into many lines and \n>     indents each line sensibly. It also tries to detect lists of printable characters and to output these as strings. The Unicode translation modifier is used for\n>     determining what characters are printable. \n\n也就是说，当我们使用`io:format(\"~p\",[Data])`来显示数据时，会根据data的binary数据是否可以转化成unicode可打印字符来打印数据，这时候中文的unicode就会每个字节逐个转化unicode\n因此：\n```erlang\n6> Bin1=unicode:characters_to_binary(\"书鬼\").\n<<228,185,166,233,172,188>>\n7> io:format(\"~p\",[Bin1]).\n<<\"ä¹¦é¬¼\">>ok\n8> Bin2=unicode:characters_to_binary(\"书盲\").\n<<228,185,166,231,155,178>>\n9> io:format(\"~p\",[Bin2]).    \n<<228,185,166,231,155,178>>ok\n\n48> io:format(\"~w\",[Bin1]).\n<<228,185,166,233,172,188>>ok\n49> io:format(\"~w\",[Bin2]).\n<<228,185,166,231,155,178>>ok\n```\n\n","slug":"different-between-p-and-w-in-io-format","published":1,"updated":"2019-08-21T01:49:04.129Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzkm7pqb000cjl9ur3fw0tyy","content":"<p>最近发现erlang项目的配置文件某些中文显示会乱码，先说下配置文件的实现：</p>\n<ol>\n<li>由file:consult/1读取配置的原始文件（一系列的erlang term），获取到原始的 erlang term</li>\n<li>再转化成erlang 代码 然后再会写到文件。</li>\n</ol>\n<p>问题就出在了转化erlang 代码这里，我们使用的是<code>io_lib:format(&quot;~p&quot;,[data])</code> 来将erlang term 转化成字符串再回写到文件，而 <code>io:format/2</code>关于<code>~p/~w</code>在官方文档里面有这样的描述：</p>\n<blockquote>\n<p>w<br>   Writes data with the standard syntax. This is used to output Erlang terms. Atoms are printed within quotes if they contain embedded non-printable<br>   characters, and floats are printed accurately as the shortest, correctly rounded string.<br>p<br> Writes the data with standard syntax in the same way as ~w, but breaks terms whose printed representation is longer than one line into many lines and<br>    indents each line sensibly. It also tries to detect lists of printable characters and to output these as strings. The Unicode translation modifier is used for<br>    determining what characters are printable. </p>\n</blockquote>\n<p>也就是说，当我们使用<code>io:format(&quot;~p&quot;,[Data])</code>来显示数据时，会根据data的binary数据是否可以转化成unicode可打印字符来打印数据，这时候中文的unicode就会每个字节逐个转化unicode<br>因此：</p>\n<pre><code class=\"erlang\">6&gt; Bin1=unicode:characters_to_binary(&quot;书鬼&quot;).\n&lt;&lt;228,185,166,233,172,188&gt;&gt;\n7&gt; io:format(&quot;~p&quot;,[Bin1]).\n&lt;&lt;&quot;ä¹¦é¬¼&quot;&gt;&gt;ok\n8&gt; Bin2=unicode:characters_to_binary(&quot;书盲&quot;).\n&lt;&lt;228,185,166,231,155,178&gt;&gt;\n9&gt; io:format(&quot;~p&quot;,[Bin2]).    \n&lt;&lt;228,185,166,231,155,178&gt;&gt;ok\n\n48&gt; io:format(&quot;~w&quot;,[Bin1]).\n&lt;&lt;228,185,166,233,172,188&gt;&gt;ok\n49&gt; io:format(&quot;~w&quot;,[Bin2]).\n&lt;&lt;228,185,166,231,155,178&gt;&gt;ok\n</code></pre>\n","site":{"data":{}},"excerpt":"","more":"<p>最近发现erlang项目的配置文件某些中文显示会乱码，先说下配置文件的实现：</p>\n<ol>\n<li>由file:consult/1读取配置的原始文件（一系列的erlang term），获取到原始的 erlang term</li>\n<li>再转化成erlang 代码 然后再会写到文件。</li>\n</ol>\n<p>问题就出在了转化erlang 代码这里，我们使用的是<code>io_lib:format(&quot;~p&quot;,[data])</code> 来将erlang term 转化成字符串再回写到文件，而 <code>io:format/2</code>关于<code>~p/~w</code>在官方文档里面有这样的描述：</p>\n<blockquote>\n<p>w<br>   Writes data with the standard syntax. This is used to output Erlang terms. Atoms are printed within quotes if they contain embedded non-printable<br>   characters, and floats are printed accurately as the shortest, correctly rounded string.<br>p<br> Writes the data with standard syntax in the same way as ~w, but breaks terms whose printed representation is longer than one line into many lines and<br>    indents each line sensibly. It also tries to detect lists of printable characters and to output these as strings. The Unicode translation modifier is used for<br>    determining what characters are printable. </p>\n</blockquote>\n<p>也就是说，当我们使用<code>io:format(&quot;~p&quot;,[Data])</code>来显示数据时，会根据data的binary数据是否可以转化成unicode可打印字符来打印数据，这时候中文的unicode就会每个字节逐个转化unicode<br>因此：</p>\n<pre><code class=\"erlang\">6&gt; Bin1=unicode:characters_to_binary(&quot;书鬼&quot;).\n&lt;&lt;228,185,166,233,172,188&gt;&gt;\n7&gt; io:format(&quot;~p&quot;,[Bin1]).\n&lt;&lt;&quot;ä¹¦é¬¼&quot;&gt;&gt;ok\n8&gt; Bin2=unicode:characters_to_binary(&quot;书盲&quot;).\n&lt;&lt;228,185,166,231,155,178&gt;&gt;\n9&gt; io:format(&quot;~p&quot;,[Bin2]).    \n&lt;&lt;228,185,166,231,155,178&gt;&gt;ok\n\n48&gt; io:format(&quot;~w&quot;,[Bin1]).\n&lt;&lt;228,185,166,233,172,188&gt;&gt;ok\n49&gt; io:format(&quot;~w&quot;,[Bin2]).\n&lt;&lt;228,185,166,231,155,178&gt;&gt;ok\n</code></pre>\n"},{"title":"Riak安装与MapReduce测试","date":"2015-10-22T12:33:37.000Z","_content":"Riak安装与MapReduce测试\n===\n1.安装环境:\n=====\n1. Ubuntu 14.04\n2. riak-2.1.1 源码编译\n3. erlang版本R16B03-1(注意 riak目前还不支持R17以上的erlang 版本)\n\n2.依赖安装\n=====\n1. ssl :sudo apt-get install libssl0.9.8\n2. pam library: sudo apt-get install libpam0g-dev\n\n3.下载并编译riak\n=====\n1. 下载:`wget http://s3.amazonaws.com/downloads.basho.com/riak/2.1/2.1.1/riak-2.1.1.tar.gz`\n2. 解压:`tar zxvf riak-2.1.1.tar.gz`\n3. 编译:`cd riak-2.1.1 && make`\n\n4.构建riak集群\n=====\n1. 生成riak node实例:`make devrel DEVNODES=$N`,其中N是想要生成的节点数\n2. 配置riak node ：riak的配置文件位于 $RIAK_HOME/dev/dev*/etc/riak.conf,可以配置节点名称,HTTP服务监听IP和端口,PCB 协议监听IP和端口storage backend(存储后端) 等。\n3. 启动riak node :`$RIAK_NODE_ROOT/bin/riak start`\n4. 组成集群\n\n  1. 加入集群： `$RIAK_NODE_ROOT/bin/riak-admin cluster join $NODENAME`\n  2. `$RIAK_NODE_ROOT/bin/riak-admin cluster plan`\n  3. 提交:`$RIAK_NODE_ROOT/bin/riak-admin cluster commit`\n  4. 查看集群状态:`$RIAK_NODE_ROOT/bin/riak-admin member-status`\n\n5.相关官方文档\n=====\n1. riak.conf 配置文件：`http://docs.basho.com/riak/2.1.1/ops/building/configuration/`\n2. riak和riak-admin:`http://docs.basho.com/riak/2.1.1/ops/running/tools/riak/` 、`http://docs.basho.com/riak/2.1.1/ops/running/tools/riak-admin/`\n3. 存储后端的选择：`http://docs.basho.com/riak/latest/ops/building/planning/backends/`\n4. MapReduce:`http://docs.basho.com/riak/2.1.1/dev/advanced/mapreduce/`\n\n6.MapReduce 实践\n=====\nMapReduce是Riak主要用于非主键查询的方法，但是MapReduce 操作的代价是十分昂贵的，甚至会降低生产环境集群的性能。因此，应当尽量少用MapReduce，并且永远不要用于实时查询。Riak允许你通过Erlang或者Javascript来进行MapReduce操作，但是从Riak2.0开始，javascript开始被弃用。\nMapReduce测试：\n五台机器，组成集群：\n一台 \nmodel name      : Intel(R) Core(TM) i5-4460  CPU @ 3.20GHz\nMemTotal:        1429236 kB\n四台\nIntel(R) Xeon(R) CPU E5-2620 0 @ 2.00GHz\nMemTotal:       65897328 kB\n\n\n在erlang shell里面输入：\n```erlang\n    {A,B,C}=erlang:now(),\n    {ok, Soc1} = riakc_pb_socket:start_link(\"127.0.0.1\", 10017),\n    Map =fun(V, _, _) ->\n        {struct, PropList} = mochijson2:decode(riak_object:get_value(V)),\n        U = proplists:get_value(<<\"user_id\">>, PropList),\n        [dict:from_list([{U, 1}])]\n    end,\n    Reduce = fun(Results, _) ->\n        Return =\n        lists:foldl(fun(D, Acc) ->\n        dict:merge(fun(_, X, Y) -> X + Y end, D, Acc)\n        end, dict:new(), lists:flatten([Results])),\n        [Return]\n    end,\n    Reslut = riakc_pb_socket:mapred_bucket(Soc1, <<\"user_read_log4\">>, [{map, {qfun, Map}, none, false}, {reduce, {qfun, \t\tReduce}, none, true}], 6000000),\n    {A1,B1,C1}=erlang:now(),\n    (A1* 1000000000000 + B1*1000000 + C1)  - (A* 1000000000000 + B*1000000+ C).\n```\n\n%通过PCB接口，使用erlang进行MapReduce处理 240080 条数据，耗时 62112283 微秒，约等于 62s\n\n```shell\n  root@localhost:/data/riak-2.1.1# date +%s\n\t1442537754\n\troot@localhost:/data/riak-2.1.1# curl -XPOST -H\"content-type: application/json\"\\\n        http://localhost:10018/mapred --data @-<<\\EOF\n    \t{\"inputs\":\"user_read_log4\",\"query\":[{\"map\":{\"language\":\"javascript\",\"source\":\"\n    \tfunction(v) {\n    \tvar data=Riak.mapValuesJson(v)[0];\n    \tvar r={};\n    \tr[data.user_id]=1;\n   \treturn [r];\n    \t}\",\"keep\":false}},\n    \t{\"reduce\":{\"language\":\"javascript\",\"source\":\"\n    \tfunction(v){\n                    var i, j, r = {}, w;\n                for (i = 0; i < v.length; i += 1) {\n                    for (w in v[i]) {\n                        if (v[i].hasOwnProperty(w)) {\n                            if (r[w]) { r[w] += v[i][w]; }\n                            else { r[w] = v[i][w]; }\n                        }\n                    }\n                }\n                return [r];\n    \t}\"\n    \t}}],\"timeout\":1000000}\n \tEOF\n\troot@localhost:/data/riak-2.1.1# date +%s\n\t1442538003\n```\n\n\n%通过http接口，使用javascript 进行Mapreduce 处理240080 条数据，1442538003-1442537754=249s\n\n```erlang\n\tmap_javascript()->\n    \t{A,B,C}=erlang:now(),\n    \t{ok, Soc1} = riakc_pb_socket:start_link(\"127.0.0.1\", 10017),\n    \tMap= <<\"function(v) { var data=Riak.mapValuesJson(v)[0];var r={};r[data.user_id]=1;return [r];}\">>,\n    \tReduce= <<\"function(v){var i, j, r = {}, w;for (i = 0; i < v.length; i += 1) {for (w in v[i]) \\\n           {if (v[i].hasOwnProperty(w)) {if (r[w]) { r[w] += v[i][w]; }else { r[w] = v[i][w]; }}}}return [r];}\" >>,\n    \tResult=riakc_pb_socket:mapred_bucket(Soc1, <<\"user_read_log4\">>, [{map, {jsanon, Map}, none, false}, {reduce, {jsanon, Reduce}, none, true}], 6000000),\n    \t{A1,B1,C1}=erlang:now(),\n    \t{Result,(A1* 1000000000000 + B1*1000000 + C1)  - (A* 1000000000000 + B*1000000+ C)}.\n\n\t(book_club_server@localhost)11> bus_user_read_behaviortrace_handler:map_javascript().\n\t{{ok,[{1,\n       \t[{struct,[{<<\"201507301601028734\">>,27301},\n                 {<<\"201507301601028728\">>,26948},\n                 {<<\"201507301601028735\">>,23250},\n                 {<<\"201507301601028733\">>,27156},\n                 {<<\"201507301601028730\">>,27175},\n                 {<<\"201507301601028732\">>,26993},\n                 {<<\"201507301601028727\">>,26930},\n                 {<<\"201507301601028729\">>,27177},\n                 {<<\"201507301601028731\">>,27150}]}]}]},240914091}\n```\n%通过PCB协议接口，使用Javascript 进行MapReduce处理240080 条数据，耗时 240914091微妙 ，约240秒.\n```\n\n\n通过上面的测试，我们就可以知道为什么Riak自己都不推荐使用Javascript 进行MapReduce了，使用Erlang  的进行MapReduce的效率几乎是 javascript 的4倍。\n\n\n\n","source":"_posts/Riak安装与MapReduce测试.md","raw":"title: Riak安装与MapReduce测试\ndate: 2015-10-22 20:33:37\ntags: [Riak,MapReduce]\n---\nRiak安装与MapReduce测试\n===\n1.安装环境:\n=====\n1. Ubuntu 14.04\n2. riak-2.1.1 源码编译\n3. erlang版本R16B03-1(注意 riak目前还不支持R17以上的erlang 版本)\n\n2.依赖安装\n=====\n1. ssl :sudo apt-get install libssl0.9.8\n2. pam library: sudo apt-get install libpam0g-dev\n\n3.下载并编译riak\n=====\n1. 下载:`wget http://s3.amazonaws.com/downloads.basho.com/riak/2.1/2.1.1/riak-2.1.1.tar.gz`\n2. 解压:`tar zxvf riak-2.1.1.tar.gz`\n3. 编译:`cd riak-2.1.1 && make`\n\n4.构建riak集群\n=====\n1. 生成riak node实例:`make devrel DEVNODES=$N`,其中N是想要生成的节点数\n2. 配置riak node ：riak的配置文件位于 $RIAK_HOME/dev/dev*/etc/riak.conf,可以配置节点名称,HTTP服务监听IP和端口,PCB 协议监听IP和端口storage backend(存储后端) 等。\n3. 启动riak node :`$RIAK_NODE_ROOT/bin/riak start`\n4. 组成集群\n\n  1. 加入集群： `$RIAK_NODE_ROOT/bin/riak-admin cluster join $NODENAME`\n  2. `$RIAK_NODE_ROOT/bin/riak-admin cluster plan`\n  3. 提交:`$RIAK_NODE_ROOT/bin/riak-admin cluster commit`\n  4. 查看集群状态:`$RIAK_NODE_ROOT/bin/riak-admin member-status`\n\n5.相关官方文档\n=====\n1. riak.conf 配置文件：`http://docs.basho.com/riak/2.1.1/ops/building/configuration/`\n2. riak和riak-admin:`http://docs.basho.com/riak/2.1.1/ops/running/tools/riak/` 、`http://docs.basho.com/riak/2.1.1/ops/running/tools/riak-admin/`\n3. 存储后端的选择：`http://docs.basho.com/riak/latest/ops/building/planning/backends/`\n4. MapReduce:`http://docs.basho.com/riak/2.1.1/dev/advanced/mapreduce/`\n\n6.MapReduce 实践\n=====\nMapReduce是Riak主要用于非主键查询的方法，但是MapReduce 操作的代价是十分昂贵的，甚至会降低生产环境集群的性能。因此，应当尽量少用MapReduce，并且永远不要用于实时查询。Riak允许你通过Erlang或者Javascript来进行MapReduce操作，但是从Riak2.0开始，javascript开始被弃用。\nMapReduce测试：\n五台机器，组成集群：\n一台 \nmodel name      : Intel(R) Core(TM) i5-4460  CPU @ 3.20GHz\nMemTotal:        1429236 kB\n四台\nIntel(R) Xeon(R) CPU E5-2620 0 @ 2.00GHz\nMemTotal:       65897328 kB\n\n\n在erlang shell里面输入：\n```erlang\n    {A,B,C}=erlang:now(),\n    {ok, Soc1} = riakc_pb_socket:start_link(\"127.0.0.1\", 10017),\n    Map =fun(V, _, _) ->\n        {struct, PropList} = mochijson2:decode(riak_object:get_value(V)),\n        U = proplists:get_value(<<\"user_id\">>, PropList),\n        [dict:from_list([{U, 1}])]\n    end,\n    Reduce = fun(Results, _) ->\n        Return =\n        lists:foldl(fun(D, Acc) ->\n        dict:merge(fun(_, X, Y) -> X + Y end, D, Acc)\n        end, dict:new(), lists:flatten([Results])),\n        [Return]\n    end,\n    Reslut = riakc_pb_socket:mapred_bucket(Soc1, <<\"user_read_log4\">>, [{map, {qfun, Map}, none, false}, {reduce, {qfun, \t\tReduce}, none, true}], 6000000),\n    {A1,B1,C1}=erlang:now(),\n    (A1* 1000000000000 + B1*1000000 + C1)  - (A* 1000000000000 + B*1000000+ C).\n```\n\n%通过PCB接口，使用erlang进行MapReduce处理 240080 条数据，耗时 62112283 微秒，约等于 62s\n\n```shell\n  root@localhost:/data/riak-2.1.1# date +%s\n\t1442537754\n\troot@localhost:/data/riak-2.1.1# curl -XPOST -H\"content-type: application/json\"\\\n        http://localhost:10018/mapred --data @-<<\\EOF\n    \t{\"inputs\":\"user_read_log4\",\"query\":[{\"map\":{\"language\":\"javascript\",\"source\":\"\n    \tfunction(v) {\n    \tvar data=Riak.mapValuesJson(v)[0];\n    \tvar r={};\n    \tr[data.user_id]=1;\n   \treturn [r];\n    \t}\",\"keep\":false}},\n    \t{\"reduce\":{\"language\":\"javascript\",\"source\":\"\n    \tfunction(v){\n                    var i, j, r = {}, w;\n                for (i = 0; i < v.length; i += 1) {\n                    for (w in v[i]) {\n                        if (v[i].hasOwnProperty(w)) {\n                            if (r[w]) { r[w] += v[i][w]; }\n                            else { r[w] = v[i][w]; }\n                        }\n                    }\n                }\n                return [r];\n    \t}\"\n    \t}}],\"timeout\":1000000}\n \tEOF\n\troot@localhost:/data/riak-2.1.1# date +%s\n\t1442538003\n```\n\n\n%通过http接口，使用javascript 进行Mapreduce 处理240080 条数据，1442538003-1442537754=249s\n\n```erlang\n\tmap_javascript()->\n    \t{A,B,C}=erlang:now(),\n    \t{ok, Soc1} = riakc_pb_socket:start_link(\"127.0.0.1\", 10017),\n    \tMap= <<\"function(v) { var data=Riak.mapValuesJson(v)[0];var r={};r[data.user_id]=1;return [r];}\">>,\n    \tReduce= <<\"function(v){var i, j, r = {}, w;for (i = 0; i < v.length; i += 1) {for (w in v[i]) \\\n           {if (v[i].hasOwnProperty(w)) {if (r[w]) { r[w] += v[i][w]; }else { r[w] = v[i][w]; }}}}return [r];}\" >>,\n    \tResult=riakc_pb_socket:mapred_bucket(Soc1, <<\"user_read_log4\">>, [{map, {jsanon, Map}, none, false}, {reduce, {jsanon, Reduce}, none, true}], 6000000),\n    \t{A1,B1,C1}=erlang:now(),\n    \t{Result,(A1* 1000000000000 + B1*1000000 + C1)  - (A* 1000000000000 + B*1000000+ C)}.\n\n\t(book_club_server@localhost)11> bus_user_read_behaviortrace_handler:map_javascript().\n\t{{ok,[{1,\n       \t[{struct,[{<<\"201507301601028734\">>,27301},\n                 {<<\"201507301601028728\">>,26948},\n                 {<<\"201507301601028735\">>,23250},\n                 {<<\"201507301601028733\">>,27156},\n                 {<<\"201507301601028730\">>,27175},\n                 {<<\"201507301601028732\">>,26993},\n                 {<<\"201507301601028727\">>,26930},\n                 {<<\"201507301601028729\">>,27177},\n                 {<<\"201507301601028731\">>,27150}]}]}]},240914091}\n```\n%通过PCB协议接口，使用Javascript 进行MapReduce处理240080 条数据，耗时 240914091微妙 ，约240秒.\n```\n\n\n通过上面的测试，我们就可以知道为什么Riak自己都不推荐使用Javascript 进行MapReduce了，使用Erlang  的进行MapReduce的效率几乎是 javascript 的4倍。\n\n\n\n","slug":"Riak安装与MapReduce测试","published":1,"updated":"2019-08-21T01:49:04.128Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzkm7pqc000ejl9uh9v83fjg","content":"<h1 id=\"Riak安装与MapReduce测试\"><a href=\"#Riak安装与MapReduce测试\" class=\"headerlink\" title=\"Riak安装与MapReduce测试\"></a>Riak安装与MapReduce测试</h1><h1 id=\"1-安装环境\"><a href=\"#1-安装环境\" class=\"headerlink\" title=\"1.安装环境:\"></a>1.安装环境:</h1><ol>\n<li>Ubuntu 14.04</li>\n<li>riak-2.1.1 源码编译</li>\n<li>erlang版本R16B03-1(注意 riak目前还不支持R17以上的erlang 版本)</li>\n</ol>\n<h1 id=\"2-依赖安装\"><a href=\"#2-依赖安装\" class=\"headerlink\" title=\"2.依赖安装\"></a>2.依赖安装</h1><ol>\n<li>ssl :sudo apt-get install libssl0.9.8</li>\n<li>pam library: sudo apt-get install libpam0g-dev</li>\n</ol>\n<h1 id=\"3-下载并编译riak\"><a href=\"#3-下载并编译riak\" class=\"headerlink\" title=\"3.下载并编译riak\"></a>3.下载并编译riak</h1><ol>\n<li>下载:<code>wget http://s3.amazonaws.com/downloads.basho.com/riak/2.1/2.1.1/riak-2.1.1.tar.gz</code></li>\n<li>解压:<code>tar zxvf riak-2.1.1.tar.gz</code></li>\n<li>编译:<code>cd riak-2.1.1 &amp;&amp; make</code></li>\n</ol>\n<h1 id=\"4-构建riak集群\"><a href=\"#4-构建riak集群\" class=\"headerlink\" title=\"4.构建riak集群\"></a>4.构建riak集群</h1><ol>\n<li>生成riak node实例:<code>make devrel DEVNODES=$N</code>,其中N是想要生成的节点数</li>\n<li>配置riak node ：riak的配置文件位于 $RIAK_HOME/dev/dev*/etc/riak.conf,可以配置节点名称,HTTP服务监听IP和端口,PCB 协议监听IP和端口storage backend(存储后端) 等。</li>\n<li>启动riak node :<code>$RIAK_NODE_ROOT/bin/riak start</code></li>\n<li><p>组成集群</p>\n<ol>\n<li>加入集群： <code>$RIAK_NODE_ROOT/bin/riak-admin cluster join $NODENAME</code></li>\n<li><code>$RIAK_NODE_ROOT/bin/riak-admin cluster plan</code></li>\n<li>提交:<code>$RIAK_NODE_ROOT/bin/riak-admin cluster commit</code></li>\n<li>查看集群状态:<code>$RIAK_NODE_ROOT/bin/riak-admin member-status</code></li>\n</ol>\n</li>\n</ol>\n<h1 id=\"5-相关官方文档\"><a href=\"#5-相关官方文档\" class=\"headerlink\" title=\"5.相关官方文档\"></a>5.相关官方文档</h1><ol>\n<li>riak.conf 配置文件：<code>http://docs.basho.com/riak/2.1.1/ops/building/configuration/</code></li>\n<li>riak和riak-admin:<code>http://docs.basho.com/riak/2.1.1/ops/running/tools/riak/</code> 、<code>http://docs.basho.com/riak/2.1.1/ops/running/tools/riak-admin/</code></li>\n<li>存储后端的选择：<code>http://docs.basho.com/riak/latest/ops/building/planning/backends/</code></li>\n<li>MapReduce:<code>http://docs.basho.com/riak/2.1.1/dev/advanced/mapreduce/</code></li>\n</ol>\n<h1 id=\"6-MapReduce-实践\"><a href=\"#6-MapReduce-实践\" class=\"headerlink\" title=\"6.MapReduce 实践\"></a>6.MapReduce 实践</h1><p>MapReduce是Riak主要用于非主键查询的方法，但是MapReduce 操作的代价是十分昂贵的，甚至会降低生产环境集群的性能。因此，应当尽量少用MapReduce，并且永远不要用于实时查询。Riak允许你通过Erlang或者Javascript来进行MapReduce操作，但是从Riak2.0开始，javascript开始被弃用。<br>MapReduce测试：<br>五台机器，组成集群：<br>一台<br>model name      : Intel(R) Core(TM) i5-4460  CPU @ 3.20GHz<br>MemTotal:        1429236 kB<br>四台<br>Intel(R) Xeon(R) CPU E5-2620 0 @ 2.00GHz<br>MemTotal:       65897328 kB</p>\n<p>在erlang shell里面输入：</p>\n<pre><code class=\"erlang\">    {A,B,C}=erlang:now(),\n    {ok, Soc1} = riakc_pb_socket:start_link(&quot;127.0.0.1&quot;, 10017),\n    Map =fun(V, _, _) -&gt;\n        {struct, PropList} = mochijson2:decode(riak_object:get_value(V)),\n        U = proplists:get_value(&lt;&lt;&quot;user_id&quot;&gt;&gt;, PropList),\n        [dict:from_list([{U, 1}])]\n    end,\n    Reduce = fun(Results, _) -&gt;\n        Return =\n        lists:foldl(fun(D, Acc) -&gt;\n        dict:merge(fun(_, X, Y) -&gt; X + Y end, D, Acc)\n        end, dict:new(), lists:flatten([Results])),\n        [Return]\n    end,\n    Reslut = riakc_pb_socket:mapred_bucket(Soc1, &lt;&lt;&quot;user_read_log4&quot;&gt;&gt;, [{map, {qfun, Map}, none, false}, {reduce, {qfun,         Reduce}, none, true}], 6000000),\n    {A1,B1,C1}=erlang:now(),\n    (A1* 1000000000000 + B1*1000000 + C1)  - (A* 1000000000000 + B*1000000+ C).\n</code></pre>\n<p>%通过PCB接口，使用erlang进行MapReduce处理 240080 条数据，耗时 62112283 微秒，约等于 62s</p>\n<pre><code class=\"shell\">  root@localhost:/data/riak-2.1.1# date +%s\n    1442537754\n    root@localhost:/data/riak-2.1.1# curl -XPOST -H&quot;content-type: application/json&quot;\\\n        http://localhost:10018/mapred --data @-&lt;&lt;\\EOF\n        {&quot;inputs&quot;:&quot;user_read_log4&quot;,&quot;query&quot;:[{&quot;map&quot;:{&quot;language&quot;:&quot;javascript&quot;,&quot;source&quot;:&quot;\n        function(v) {\n        var data=Riak.mapValuesJson(v)[0];\n        var r={};\n        r[data.user_id]=1;\n       return [r];\n        }&quot;,&quot;keep&quot;:false}},\n        {&quot;reduce&quot;:{&quot;language&quot;:&quot;javascript&quot;,&quot;source&quot;:&quot;\n        function(v){\n                    var i, j, r = {}, w;\n                for (i = 0; i &lt; v.length; i += 1) {\n                    for (w in v[i]) {\n                        if (v[i].hasOwnProperty(w)) {\n                            if (r[w]) { r[w] += v[i][w]; }\n                            else { r[w] = v[i][w]; }\n                        }\n                    }\n                }\n                return [r];\n        }&quot;\n        }}],&quot;timeout&quot;:1000000}\n     EOF\n    root@localhost:/data/riak-2.1.1# date +%s\n    1442538003\n</code></pre>\n<p>%通过http接口，使用javascript 进行Mapreduce 处理240080 条数据，1442538003-1442537754=249s</p>\n<pre><code class=\"erlang\">    map_javascript()-&gt;\n        {A,B,C}=erlang:now(),\n        {ok, Soc1} = riakc_pb_socket:start_link(&quot;127.0.0.1&quot;, 10017),\n        Map= &lt;&lt;&quot;function(v) { var data=Riak.mapValuesJson(v)[0];var r={};r[data.user_id]=1;return [r];}&quot;&gt;&gt;,\n        Reduce= &lt;&lt;&quot;function(v){var i, j, r = {}, w;for (i = 0; i &lt; v.length; i += 1) {for (w in v[i]) \\\n           {if (v[i].hasOwnProperty(w)) {if (r[w]) { r[w] += v[i][w]; }else { r[w] = v[i][w]; }}}}return [r];}&quot; &gt;&gt;,\n        Result=riakc_pb_socket:mapred_bucket(Soc1, &lt;&lt;&quot;user_read_log4&quot;&gt;&gt;, [{map, {jsanon, Map}, none, false}, {reduce, {jsanon, Reduce}, none, true}], 6000000),\n        {A1,B1,C1}=erlang:now(),\n        {Result,(A1* 1000000000000 + B1*1000000 + C1)  - (A* 1000000000000 + B*1000000+ C)}.\n\n    (book_club_server@localhost)11&gt; bus_user_read_behaviortrace_handler:map_javascript().\n    {{ok,[{1,\n           [{struct,[{&lt;&lt;&quot;201507301601028734&quot;&gt;&gt;,27301},\n                 {&lt;&lt;&quot;201507301601028728&quot;&gt;&gt;,26948},\n                 {&lt;&lt;&quot;201507301601028735&quot;&gt;&gt;,23250},\n                 {&lt;&lt;&quot;201507301601028733&quot;&gt;&gt;,27156},\n                 {&lt;&lt;&quot;201507301601028730&quot;&gt;&gt;,27175},\n                 {&lt;&lt;&quot;201507301601028732&quot;&gt;&gt;,26993},\n                 {&lt;&lt;&quot;201507301601028727&quot;&gt;&gt;,26930},\n                 {&lt;&lt;&quot;201507301601028729&quot;&gt;&gt;,27177},\n                 {&lt;&lt;&quot;201507301601028731&quot;&gt;&gt;,27150}]}]}]},240914091}\n</code></pre>\n<p>%通过PCB协议接口，使用Javascript 进行MapReduce处理240080 条数据，耗时 240914091微妙 ，约240秒.<br><code>`</code></p>\n<p>通过上面的测试，我们就可以知道为什么Riak自己都不推荐使用Javascript 进行MapReduce了，使用Erlang  的进行MapReduce的效率几乎是 javascript 的4倍。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Riak安装与MapReduce测试\"><a href=\"#Riak安装与MapReduce测试\" class=\"headerlink\" title=\"Riak安装与MapReduce测试\"></a>Riak安装与MapReduce测试</h1><h1 id=\"1-安装环境\"><a href=\"#1-安装环境\" class=\"headerlink\" title=\"1.安装环境:\"></a>1.安装环境:</h1><ol>\n<li>Ubuntu 14.04</li>\n<li>riak-2.1.1 源码编译</li>\n<li>erlang版本R16B03-1(注意 riak目前还不支持R17以上的erlang 版本)</li>\n</ol>\n<h1 id=\"2-依赖安装\"><a href=\"#2-依赖安装\" class=\"headerlink\" title=\"2.依赖安装\"></a>2.依赖安装</h1><ol>\n<li>ssl :sudo apt-get install libssl0.9.8</li>\n<li>pam library: sudo apt-get install libpam0g-dev</li>\n</ol>\n<h1 id=\"3-下载并编译riak\"><a href=\"#3-下载并编译riak\" class=\"headerlink\" title=\"3.下载并编译riak\"></a>3.下载并编译riak</h1><ol>\n<li>下载:<code>wget http://s3.amazonaws.com/downloads.basho.com/riak/2.1/2.1.1/riak-2.1.1.tar.gz</code></li>\n<li>解压:<code>tar zxvf riak-2.1.1.tar.gz</code></li>\n<li>编译:<code>cd riak-2.1.1 &amp;&amp; make</code></li>\n</ol>\n<h1 id=\"4-构建riak集群\"><a href=\"#4-构建riak集群\" class=\"headerlink\" title=\"4.构建riak集群\"></a>4.构建riak集群</h1><ol>\n<li>生成riak node实例:<code>make devrel DEVNODES=$N</code>,其中N是想要生成的节点数</li>\n<li>配置riak node ：riak的配置文件位于 $RIAK_HOME/dev/dev*/etc/riak.conf,可以配置节点名称,HTTP服务监听IP和端口,PCB 协议监听IP和端口storage backend(存储后端) 等。</li>\n<li>启动riak node :<code>$RIAK_NODE_ROOT/bin/riak start</code></li>\n<li><p>组成集群</p>\n<ol>\n<li>加入集群： <code>$RIAK_NODE_ROOT/bin/riak-admin cluster join $NODENAME</code></li>\n<li><code>$RIAK_NODE_ROOT/bin/riak-admin cluster plan</code></li>\n<li>提交:<code>$RIAK_NODE_ROOT/bin/riak-admin cluster commit</code></li>\n<li>查看集群状态:<code>$RIAK_NODE_ROOT/bin/riak-admin member-status</code></li>\n</ol>\n</li>\n</ol>\n<h1 id=\"5-相关官方文档\"><a href=\"#5-相关官方文档\" class=\"headerlink\" title=\"5.相关官方文档\"></a>5.相关官方文档</h1><ol>\n<li>riak.conf 配置文件：<code>http://docs.basho.com/riak/2.1.1/ops/building/configuration/</code></li>\n<li>riak和riak-admin:<code>http://docs.basho.com/riak/2.1.1/ops/running/tools/riak/</code> 、<code>http://docs.basho.com/riak/2.1.1/ops/running/tools/riak-admin/</code></li>\n<li>存储后端的选择：<code>http://docs.basho.com/riak/latest/ops/building/planning/backends/</code></li>\n<li>MapReduce:<code>http://docs.basho.com/riak/2.1.1/dev/advanced/mapreduce/</code></li>\n</ol>\n<h1 id=\"6-MapReduce-实践\"><a href=\"#6-MapReduce-实践\" class=\"headerlink\" title=\"6.MapReduce 实践\"></a>6.MapReduce 实践</h1><p>MapReduce是Riak主要用于非主键查询的方法，但是MapReduce 操作的代价是十分昂贵的，甚至会降低生产环境集群的性能。因此，应当尽量少用MapReduce，并且永远不要用于实时查询。Riak允许你通过Erlang或者Javascript来进行MapReduce操作，但是从Riak2.0开始，javascript开始被弃用。<br>MapReduce测试：<br>五台机器，组成集群：<br>一台<br>model name      : Intel(R) Core(TM) i5-4460  CPU @ 3.20GHz<br>MemTotal:        1429236 kB<br>四台<br>Intel(R) Xeon(R) CPU E5-2620 0 @ 2.00GHz<br>MemTotal:       65897328 kB</p>\n<p>在erlang shell里面输入：</p>\n<pre><code class=\"erlang\">    {A,B,C}=erlang:now(),\n    {ok, Soc1} = riakc_pb_socket:start_link(&quot;127.0.0.1&quot;, 10017),\n    Map =fun(V, _, _) -&gt;\n        {struct, PropList} = mochijson2:decode(riak_object:get_value(V)),\n        U = proplists:get_value(&lt;&lt;&quot;user_id&quot;&gt;&gt;, PropList),\n        [dict:from_list([{U, 1}])]\n    end,\n    Reduce = fun(Results, _) -&gt;\n        Return =\n        lists:foldl(fun(D, Acc) -&gt;\n        dict:merge(fun(_, X, Y) -&gt; X + Y end, D, Acc)\n        end, dict:new(), lists:flatten([Results])),\n        [Return]\n    end,\n    Reslut = riakc_pb_socket:mapred_bucket(Soc1, &lt;&lt;&quot;user_read_log4&quot;&gt;&gt;, [{map, {qfun, Map}, none, false}, {reduce, {qfun,         Reduce}, none, true}], 6000000),\n    {A1,B1,C1}=erlang:now(),\n    (A1* 1000000000000 + B1*1000000 + C1)  - (A* 1000000000000 + B*1000000+ C).\n</code></pre>\n<p>%通过PCB接口，使用erlang进行MapReduce处理 240080 条数据，耗时 62112283 微秒，约等于 62s</p>\n<pre><code class=\"shell\">  root@localhost:/data/riak-2.1.1# date +%s\n    1442537754\n    root@localhost:/data/riak-2.1.1# curl -XPOST -H&quot;content-type: application/json&quot;\\\n        http://localhost:10018/mapred --data @-&lt;&lt;\\EOF\n        {&quot;inputs&quot;:&quot;user_read_log4&quot;,&quot;query&quot;:[{&quot;map&quot;:{&quot;language&quot;:&quot;javascript&quot;,&quot;source&quot;:&quot;\n        function(v) {\n        var data=Riak.mapValuesJson(v)[0];\n        var r={};\n        r[data.user_id]=1;\n       return [r];\n        }&quot;,&quot;keep&quot;:false}},\n        {&quot;reduce&quot;:{&quot;language&quot;:&quot;javascript&quot;,&quot;source&quot;:&quot;\n        function(v){\n                    var i, j, r = {}, w;\n                for (i = 0; i &lt; v.length; i += 1) {\n                    for (w in v[i]) {\n                        if (v[i].hasOwnProperty(w)) {\n                            if (r[w]) { r[w] += v[i][w]; }\n                            else { r[w] = v[i][w]; }\n                        }\n                    }\n                }\n                return [r];\n        }&quot;\n        }}],&quot;timeout&quot;:1000000}\n     EOF\n    root@localhost:/data/riak-2.1.1# date +%s\n    1442538003\n</code></pre>\n<p>%通过http接口，使用javascript 进行Mapreduce 处理240080 条数据，1442538003-1442537754=249s</p>\n<pre><code class=\"erlang\">    map_javascript()-&gt;\n        {A,B,C}=erlang:now(),\n        {ok, Soc1} = riakc_pb_socket:start_link(&quot;127.0.0.1&quot;, 10017),\n        Map= &lt;&lt;&quot;function(v) { var data=Riak.mapValuesJson(v)[0];var r={};r[data.user_id]=1;return [r];}&quot;&gt;&gt;,\n        Reduce= &lt;&lt;&quot;function(v){var i, j, r = {}, w;for (i = 0; i &lt; v.length; i += 1) {for (w in v[i]) \\\n           {if (v[i].hasOwnProperty(w)) {if (r[w]) { r[w] += v[i][w]; }else { r[w] = v[i][w]; }}}}return [r];}&quot; &gt;&gt;,\n        Result=riakc_pb_socket:mapred_bucket(Soc1, &lt;&lt;&quot;user_read_log4&quot;&gt;&gt;, [{map, {jsanon, Map}, none, false}, {reduce, {jsanon, Reduce}, none, true}], 6000000),\n        {A1,B1,C1}=erlang:now(),\n        {Result,(A1* 1000000000000 + B1*1000000 + C1)  - (A* 1000000000000 + B*1000000+ C)}.\n\n    (book_club_server@localhost)11&gt; bus_user_read_behaviortrace_handler:map_javascript().\n    {{ok,[{1,\n           [{struct,[{&lt;&lt;&quot;201507301601028734&quot;&gt;&gt;,27301},\n                 {&lt;&lt;&quot;201507301601028728&quot;&gt;&gt;,26948},\n                 {&lt;&lt;&quot;201507301601028735&quot;&gt;&gt;,23250},\n                 {&lt;&lt;&quot;201507301601028733&quot;&gt;&gt;,27156},\n                 {&lt;&lt;&quot;201507301601028730&quot;&gt;&gt;,27175},\n                 {&lt;&lt;&quot;201507301601028732&quot;&gt;&gt;,26993},\n                 {&lt;&lt;&quot;201507301601028727&quot;&gt;&gt;,26930},\n                 {&lt;&lt;&quot;201507301601028729&quot;&gt;&gt;,27177},\n                 {&lt;&lt;&quot;201507301601028731&quot;&gt;&gt;,27150}]}]}]},240914091}\n</code></pre>\n<p>%通过PCB协议接口，使用Javascript 进行MapReduce处理240080 条数据，耗时 240914091微妙 ，约240秒.<br><code>`</code></p>\n<p>通过上面的测试，我们就可以知道为什么Riak自己都不推荐使用Javascript 进行MapReduce了，使用Erlang  的进行MapReduce的效率几乎是 javascript 的4倍。</p>\n"},{"title":"ejabberd_receiver分析","date":"2015-10-22T12:10:51.000Z","_content":"\nejabberd_receiver 分析\n=====\n`ejabberd_receiver`是ejabberd 中 网关层的数据receive模块，客户端发送的数据通过`ejabberd_receiver` 接收并通过xml port解析后发送给 ejabberd_c2s的实例处理，至于它的加密、压缩、解压之类的就不说了。\n\n主要说一下这个shaper（字母翻译：脉冲整形器，个人理解，流量控制）机制,什么意思呢？\n\n原来 `ejabberd_receiver`会根据本次socket接收到的包的大小，判断是否需要缓冲一会再接收下一个socket包，这里用到了socket参数`{active, once}`\n\n算法如下：\n    根据本次收到的包的大小 和 maxrate 算出应该缓冲多少s，再算出上一次 到 本次接收数据包的时间间隔来决定是否需要缓冲。\n\nshaper:update/2:\n\n```erlang\nupdate(none, _Size) -> {none, 0};\nupdate(#maxrate{} = State, Size) ->\n    MinInterv = 1000 * Size /(2 * State#maxrate.maxrate - State#maxrate.lastrate),\n    Interv = (now_to_usec(now()) - State#maxrate.lasttime) /1000, \n    ?DEBUG(\"State: ~p, Size=~p~nM=~p, I=~p~n\",\n    [State, Size, MinInterv, Interv]),\n    Pause = if \n                MinInterv > Interv ->\n                    1 + trunc(MinInterv - Interv);\n                true -> 0\n            end,\n    NextNow = now_to_usec(now()) + Pause * 1000,\n    {State#maxrate{lastrate =(State#maxrate.lastrate + 1000000 * Size / (NextNow - State#maxrate.lasttime)) / 2, lasttime = NextNow},\n    Pause}.\n```\n\nejabberd_receive:process_date/2\n\n```erlang\nprocess_data(Data,#state{xml_stream_state = XMLStreamState,shaper_state = ShaperState, c2s_pid = C2SPid} =State) ->\n    ?DEBUG(\"Received XML on stream = ~p\", [(Data)]),\n    XMLStreamState1 = xml_stream:parse(XMLStreamState, Data),\n    lager:info(\"XMLStreamState1 ~p\",[XMLStreamState1]),\n    {NewShaperState, Pause} = shaper:update(ShaperState, byte_size(Data)),\n    lager:info(\"pause :~p \\n pid :~p\",[Pause,C2SPid]),\n    if\n        C2SPid == undefined ->\n            ok;\n        Pause > 0 ->\n            erlang:start_timer(Pause, self(), activate);\n        true ->\n            activate_socket(State)\n    end,\n    State#state{xml_stream_state = XMLStreamState1,shaper_state = NewShaperState}.\n```\n","source":"_posts/ejabberd-receiver分析.md","raw":"title: ejabberd_receiver分析\ndate: 2015-10-22 20:10:51\ntags: [Ejabberd]\n---\n\nejabberd_receiver 分析\n=====\n`ejabberd_receiver`是ejabberd 中 网关层的数据receive模块，客户端发送的数据通过`ejabberd_receiver` 接收并通过xml port解析后发送给 ejabberd_c2s的实例处理，至于它的加密、压缩、解压之类的就不说了。\n\n主要说一下这个shaper（字母翻译：脉冲整形器，个人理解，流量控制）机制,什么意思呢？\n\n原来 `ejabberd_receiver`会根据本次socket接收到的包的大小，判断是否需要缓冲一会再接收下一个socket包，这里用到了socket参数`{active, once}`\n\n算法如下：\n    根据本次收到的包的大小 和 maxrate 算出应该缓冲多少s，再算出上一次 到 本次接收数据包的时间间隔来决定是否需要缓冲。\n\nshaper:update/2:\n\n```erlang\nupdate(none, _Size) -> {none, 0};\nupdate(#maxrate{} = State, Size) ->\n    MinInterv = 1000 * Size /(2 * State#maxrate.maxrate - State#maxrate.lastrate),\n    Interv = (now_to_usec(now()) - State#maxrate.lasttime) /1000, \n    ?DEBUG(\"State: ~p, Size=~p~nM=~p, I=~p~n\",\n    [State, Size, MinInterv, Interv]),\n    Pause = if \n                MinInterv > Interv ->\n                    1 + trunc(MinInterv - Interv);\n                true -> 0\n            end,\n    NextNow = now_to_usec(now()) + Pause * 1000,\n    {State#maxrate{lastrate =(State#maxrate.lastrate + 1000000 * Size / (NextNow - State#maxrate.lasttime)) / 2, lasttime = NextNow},\n    Pause}.\n```\n\nejabberd_receive:process_date/2\n\n```erlang\nprocess_data(Data,#state{xml_stream_state = XMLStreamState,shaper_state = ShaperState, c2s_pid = C2SPid} =State) ->\n    ?DEBUG(\"Received XML on stream = ~p\", [(Data)]),\n    XMLStreamState1 = xml_stream:parse(XMLStreamState, Data),\n    lager:info(\"XMLStreamState1 ~p\",[XMLStreamState1]),\n    {NewShaperState, Pause} = shaper:update(ShaperState, byte_size(Data)),\n    lager:info(\"pause :~p \\n pid :~p\",[Pause,C2SPid]),\n    if\n        C2SPid == undefined ->\n            ok;\n        Pause > 0 ->\n            erlang:start_timer(Pause, self(), activate);\n        true ->\n            activate_socket(State)\n    end,\n    State#state{xml_stream_state = XMLStreamState1,shaper_state = NewShaperState}.\n```\n","slug":"ejabberd-receiver分析","published":1,"updated":"2019-08-21T01:49:04.129Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzkm7pqg000hjl9ueio7zpyd","content":"<h1 id=\"ejabberd-receiver-分析\"><a href=\"#ejabberd-receiver-分析\" class=\"headerlink\" title=\"ejabberd_receiver 分析\"></a>ejabberd_receiver 分析</h1><p><code>ejabberd_receiver</code>是ejabberd 中 网关层的数据receive模块，客户端发送的数据通过<code>ejabberd_receiver</code> 接收并通过xml port解析后发送给 ejabberd_c2s的实例处理，至于它的加密、压缩、解压之类的就不说了。</p>\n<p>主要说一下这个shaper（字母翻译：脉冲整形器，个人理解，流量控制）机制,什么意思呢？</p>\n<p>原来 <code>ejabberd_receiver</code>会根据本次socket接收到的包的大小，判断是否需要缓冲一会再接收下一个socket包，这里用到了socket参数<code>{active, once}</code></p>\n<p>算法如下：<br>    根据本次收到的包的大小 和 maxrate 算出应该缓冲多少s，再算出上一次 到 本次接收数据包的时间间隔来决定是否需要缓冲。</p>\n<p>shaper:update/2:</p>\n<pre><code class=\"erlang\">update(none, _Size) -&gt; {none, 0};\nupdate(#maxrate{} = State, Size) -&gt;\n    MinInterv = 1000 * Size /(2 * State#maxrate.maxrate - State#maxrate.lastrate),\n    Interv = (now_to_usec(now()) - State#maxrate.lasttime) /1000, \n    ?DEBUG(&quot;State: ~p, Size=~p~nM=~p, I=~p~n&quot;,\n    [State, Size, MinInterv, Interv]),\n    Pause = if \n                MinInterv &gt; Interv -&gt;\n                    1 + trunc(MinInterv - Interv);\n                true -&gt; 0\n            end,\n    NextNow = now_to_usec(now()) + Pause * 1000,\n    {State#maxrate{lastrate =(State#maxrate.lastrate + 1000000 * Size / (NextNow - State#maxrate.lasttime)) / 2, lasttime = NextNow},\n    Pause}.\n</code></pre>\n<p>ejabberd_receive:process_date/2</p>\n<pre><code class=\"erlang\">process_data(Data,#state{xml_stream_state = XMLStreamState,shaper_state = ShaperState, c2s_pid = C2SPid} =State) -&gt;\n    ?DEBUG(&quot;Received XML on stream = ~p&quot;, [(Data)]),\n    XMLStreamState1 = xml_stream:parse(XMLStreamState, Data),\n    lager:info(&quot;XMLStreamState1 ~p&quot;,[XMLStreamState1]),\n    {NewShaperState, Pause} = shaper:update(ShaperState, byte_size(Data)),\n    lager:info(&quot;pause :~p \\n pid :~p&quot;,[Pause,C2SPid]),\n    if\n        C2SPid == undefined -&gt;\n            ok;\n        Pause &gt; 0 -&gt;\n            erlang:start_timer(Pause, self(), activate);\n        true -&gt;\n            activate_socket(State)\n    end,\n    State#state{xml_stream_state = XMLStreamState1,shaper_state = NewShaperState}.\n</code></pre>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"ejabberd-receiver-分析\"><a href=\"#ejabberd-receiver-分析\" class=\"headerlink\" title=\"ejabberd_receiver 分析\"></a>ejabberd_receiver 分析</h1><p><code>ejabberd_receiver</code>是ejabberd 中 网关层的数据receive模块，客户端发送的数据通过<code>ejabberd_receiver</code> 接收并通过xml port解析后发送给 ejabberd_c2s的实例处理，至于它的加密、压缩、解压之类的就不说了。</p>\n<p>主要说一下这个shaper（字母翻译：脉冲整形器，个人理解，流量控制）机制,什么意思呢？</p>\n<p>原来 <code>ejabberd_receiver</code>会根据本次socket接收到的包的大小，判断是否需要缓冲一会再接收下一个socket包，这里用到了socket参数<code>{active, once}</code></p>\n<p>算法如下：<br>    根据本次收到的包的大小 和 maxrate 算出应该缓冲多少s，再算出上一次 到 本次接收数据包的时间间隔来决定是否需要缓冲。</p>\n<p>shaper:update/2:</p>\n<pre><code class=\"erlang\">update(none, _Size) -&gt; {none, 0};\nupdate(#maxrate{} = State, Size) -&gt;\n    MinInterv = 1000 * Size /(2 * State#maxrate.maxrate - State#maxrate.lastrate),\n    Interv = (now_to_usec(now()) - State#maxrate.lasttime) /1000, \n    ?DEBUG(&quot;State: ~p, Size=~p~nM=~p, I=~p~n&quot;,\n    [State, Size, MinInterv, Interv]),\n    Pause = if \n                MinInterv &gt; Interv -&gt;\n                    1 + trunc(MinInterv - Interv);\n                true -&gt; 0\n            end,\n    NextNow = now_to_usec(now()) + Pause * 1000,\n    {State#maxrate{lastrate =(State#maxrate.lastrate + 1000000 * Size / (NextNow - State#maxrate.lasttime)) / 2, lasttime = NextNow},\n    Pause}.\n</code></pre>\n<p>ejabberd_receive:process_date/2</p>\n<pre><code class=\"erlang\">process_data(Data,#state{xml_stream_state = XMLStreamState,shaper_state = ShaperState, c2s_pid = C2SPid} =State) -&gt;\n    ?DEBUG(&quot;Received XML on stream = ~p&quot;, [(Data)]),\n    XMLStreamState1 = xml_stream:parse(XMLStreamState, Data),\n    lager:info(&quot;XMLStreamState1 ~p&quot;,[XMLStreamState1]),\n    {NewShaperState, Pause} = shaper:update(ShaperState, byte_size(Data)),\n    lager:info(&quot;pause :~p \\n pid :~p&quot;,[Pause,C2SPid]),\n    if\n        C2SPid == undefined -&gt;\n            ok;\n        Pause &gt; 0 -&gt;\n            erlang:start_timer(Pause, self(), activate);\n        true -&gt;\n            activate_socket(State)\n    end,\n    State#state{xml_stream_state = XMLStreamState1,shaper_state = NewShaperState}.\n</code></pre>\n"},{"title":"githubConnectionWay","date":"2016-01-05T02:38:49.000Z","_content":"Github https和ssh连接的区别\n===================\n有个项目在`push` 一直都需要输入帐号密码，发现原来是因为使用了https来连接；\n使用https方式连接的话，`.git/config`里面的url配置是`https://github.com/XXX/XXX.git`,这样的话，每次push都需要输入帐号密码了。\n而使用ssh方式连接的话，`.git/config`里面的url配置是`\n[git@github.com](mailto:git@github.com):XXX/XXX.git`,这样的话，只要配置好了ssh key，就只需要输入`passphrase`就ok了。\n\n至于如何设置连接方式?\n\n可以通过`git remote set-url  origin`设置\n\n```\ngit remote set-url  origin [git@github.com](mailto:git@github.com):XXX/XXX.git ```\n","source":"_posts/githubConnectionWay.md","raw":"title: githubConnectionWay\ndate: 2016-01-05 10:38:49\ntags: [Git]\n---\nGithub https和ssh连接的区别\n===================\n有个项目在`push` 一直都需要输入帐号密码，发现原来是因为使用了https来连接；\n使用https方式连接的话，`.git/config`里面的url配置是`https://github.com/XXX/XXX.git`,这样的话，每次push都需要输入帐号密码了。\n而使用ssh方式连接的话，`.git/config`里面的url配置是`\n[git@github.com](mailto:git@github.com):XXX/XXX.git`,这样的话，只要配置好了ssh key，就只需要输入`passphrase`就ok了。\n\n至于如何设置连接方式?\n\n可以通过`git remote set-url  origin`设置\n\n```\ngit remote set-url  origin [git@github.com](mailto:git@github.com):XXX/XXX.git ```\n","slug":"githubConnectionWay","published":1,"updated":"2019-08-21T01:49:04.129Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzkm7pqh000jjl9uz8p61ho1","content":"<h1 id=\"Github-https和ssh连接的区别\"><a href=\"#Github-https和ssh连接的区别\" class=\"headerlink\" title=\"Github https和ssh连接的区别\"></a>Github https和ssh连接的区别</h1><p>有个项目在<code>push</code> 一直都需要输入帐号密码，发现原来是因为使用了https来连接；<br>使用https方式连接的话，<code>.git/config</code>里面的url配置是<code>https://github.com/XXX/XXX.git</code>,这样的话，每次push都需要输入帐号密码了。<br>而使用ssh方式连接的话，<code>.git/config</code>里面的url配置是<code>[git@github.com](mailto:git@github.com):XXX/XXX.git</code>,这样的话，只要配置好了ssh key，就只需要输入<code>passphrase</code>就ok了。</p>\n<p>至于如何设置连接方式?</p>\n<p>可以通过<code>git remote set-url  origin</code>设置</p>\n<pre><code>git remote set-url  origin [git@github.com](mailto:git@github.com):XXX/XXX.git\n</code></pre>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Github-https和ssh连接的区别\"><a href=\"#Github-https和ssh连接的区别\" class=\"headerlink\" title=\"Github https和ssh连接的区别\"></a>Github https和ssh连接的区别</h1><p>有个项目在<code>push</code> 一直都需要输入帐号密码，发现原来是因为使用了https来连接；<br>使用https方式连接的话，<code>.git/config</code>里面的url配置是<code>https://github.com/XXX/XXX.git</code>,这样的话，每次push都需要输入帐号密码了。<br>而使用ssh方式连接的话，<code>.git/config</code>里面的url配置是<code>[git@github.com](mailto:git@github.com):XXX/XXX.git</code>,这样的话，只要配置好了ssh key，就只需要输入<code>passphrase</code>就ok了。</p>\n<p>至于如何设置连接方式?</p>\n<p>可以通过<code>git remote set-url  origin</code>设置</p>\n<pre><code>git remote set-url  origin [git@github.com](mailto:git@github.com):XXX/XXX.git\n</code></pre>"},{"title":"goa请求处理解析","date":"2016-08-16T07:39:41.000Z","_content":"##### 1. 入口\n`app.MountXXXController` -> \n`service.Mux.Handle(\"GET\", \"/add/:left/:right\", ctrl.MuxHandler(\"Add\", h, nil))` ->` ctrl.MuxHandler(\"Add\", h, nil)`\n\n\n在 ` ctrl.MuxHandler(\"Add\", h, nil)` 中返回一个 先Invoke用户实现的对应请求的逻辑方法,再依次Invoke middleware 的函数：\n```golang\n// MuxHandler wraps a request handler into a MuxHandler. The MuxHandler initializes the request\n// context by loading the request state, invokes the handler and in case of error invokes the\n// controller (if there is one) or Service error handler.\n// This function is intended for the controller generated code. User code should not need to call\n// it directly.\nfunc (ctrl *Controller) MuxHandler(name string, hdlr Handler, unm Unmarshaler) MuxHandler {\n\t// Use closure to enable late computation of handlers to ensure all middleware has been\n\t// registered.\n\tvar handler Handler\n\n\treturn func(rw http.ResponseWriter, req *http.Request, params url.Values) {\n\t\t// Build handler middleware chains on first invocation\n\t\tif handler == nil {\n\t\t\thandler = func(ctx context.Context, rw http.ResponseWriter, req *http.Request) error {\n\t\t\t\tif !ContextResponse(ctx).Written() {\n\t\t\t\t\treturn hdlr(ctx, rw, req)\n\t\t\t\t}\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tchain := append(ctrl.Service.middleware, ctrl.middleware...)\n\t\t\tml := len(chain)\n\t\t\tfor i := range chain {\n\t\t\t\thandler = chain[ml-i-1](handler)\n\t\t\t}\n\t\t}\n\n\t\t// Build context\n\t\tctx := NewContext(WithAction(ctrl.Context, name), rw, req, params)\n\n\t\t// Protect against request bodies with unreasonable length\n\t\tif ctrl.MaxRequestBodyLength > 0 {\n\t\t\treq.Body = http.MaxBytesReader(rw, req.Body, ctrl.MaxRequestBodyLength)\n\t\t}\n\n\t\t// Load body if any\n\t\tif req.ContentLength > 0 && unm != nil {\n\t\t\tif err := unm(ctx, ctrl.Service, req); err != nil {\n\t\t\t\tif err.Error() == \"http: request body too large\" {\n\t\t\t\t\tmsg := fmt.Sprintf(\"request body length exceeds %d bytes\", ctrl.MaxRequestBodyLength)\n\t\t\t\t\terr = ErrRequestBodyTooLarge(msg)\n\t\t\t\t} else {\n\t\t\t\t\terr = ErrBadRequest(err)\n\t\t\t\t}\n\t\t\t\tctx = WithError(ctx, err)\n\t\t\t}\n\t\t}\n\n\t\t// Invoke handler\n\t\tif err := handler(ctx, ContextResponse(ctx), req); err != nil {\n\t\t\tLogError(ctx, \"uncaught error\", \"err\", err)\n\t\t\trespBody := fmt.Sprintf(\"Internal error: %s\", err) // Sprintf catches panics\n\t\t\tctrl.Service.Send(ctx, 500, respBody)\n\t\t}\n\t}\n}\n```\n\n而`service.Mux.Handle(\"GET\", \"/add/:left/:right\", ctrl.MuxHandler(\"Add\", h, nil))` 就是告诉 httptreemux 请求 url对应hander是 ctrl.MuxHandler\n```golang\nfunc (m *mux) Handle(method, path string, handle MuxHandler) {\n\ththandle := func(rw http.ResponseWriter, req *http.Request, htparams map[string]string) {\n\t\tparams := req.URL.Query()\n\t\tfor n, p := range htparams {\n\t\t\tparams.Set(n, p)\n\t\t}\n\t\thandle(rw, req, params)\n\t}\n\tm.handles[method+path] = handle\n\tm.router.Handle(method, path, hthandle)\n}\n```\n","source":"_posts/goa请求处理解析.md","raw":"title: goa请求处理解析\ndate: 2016-08-16 15:39:41\ntags: [micro service,golang]\n---\n##### 1. 入口\n`app.MountXXXController` -> \n`service.Mux.Handle(\"GET\", \"/add/:left/:right\", ctrl.MuxHandler(\"Add\", h, nil))` ->` ctrl.MuxHandler(\"Add\", h, nil)`\n\n\n在 ` ctrl.MuxHandler(\"Add\", h, nil)` 中返回一个 先Invoke用户实现的对应请求的逻辑方法,再依次Invoke middleware 的函数：\n```golang\n// MuxHandler wraps a request handler into a MuxHandler. The MuxHandler initializes the request\n// context by loading the request state, invokes the handler and in case of error invokes the\n// controller (if there is one) or Service error handler.\n// This function is intended for the controller generated code. User code should not need to call\n// it directly.\nfunc (ctrl *Controller) MuxHandler(name string, hdlr Handler, unm Unmarshaler) MuxHandler {\n\t// Use closure to enable late computation of handlers to ensure all middleware has been\n\t// registered.\n\tvar handler Handler\n\n\treturn func(rw http.ResponseWriter, req *http.Request, params url.Values) {\n\t\t// Build handler middleware chains on first invocation\n\t\tif handler == nil {\n\t\t\thandler = func(ctx context.Context, rw http.ResponseWriter, req *http.Request) error {\n\t\t\t\tif !ContextResponse(ctx).Written() {\n\t\t\t\t\treturn hdlr(ctx, rw, req)\n\t\t\t\t}\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tchain := append(ctrl.Service.middleware, ctrl.middleware...)\n\t\t\tml := len(chain)\n\t\t\tfor i := range chain {\n\t\t\t\thandler = chain[ml-i-1](handler)\n\t\t\t}\n\t\t}\n\n\t\t// Build context\n\t\tctx := NewContext(WithAction(ctrl.Context, name), rw, req, params)\n\n\t\t// Protect against request bodies with unreasonable length\n\t\tif ctrl.MaxRequestBodyLength > 0 {\n\t\t\treq.Body = http.MaxBytesReader(rw, req.Body, ctrl.MaxRequestBodyLength)\n\t\t}\n\n\t\t// Load body if any\n\t\tif req.ContentLength > 0 && unm != nil {\n\t\t\tif err := unm(ctx, ctrl.Service, req); err != nil {\n\t\t\t\tif err.Error() == \"http: request body too large\" {\n\t\t\t\t\tmsg := fmt.Sprintf(\"request body length exceeds %d bytes\", ctrl.MaxRequestBodyLength)\n\t\t\t\t\terr = ErrRequestBodyTooLarge(msg)\n\t\t\t\t} else {\n\t\t\t\t\terr = ErrBadRequest(err)\n\t\t\t\t}\n\t\t\t\tctx = WithError(ctx, err)\n\t\t\t}\n\t\t}\n\n\t\t// Invoke handler\n\t\tif err := handler(ctx, ContextResponse(ctx), req); err != nil {\n\t\t\tLogError(ctx, \"uncaught error\", \"err\", err)\n\t\t\trespBody := fmt.Sprintf(\"Internal error: %s\", err) // Sprintf catches panics\n\t\t\tctrl.Service.Send(ctx, 500, respBody)\n\t\t}\n\t}\n}\n```\n\n而`service.Mux.Handle(\"GET\", \"/add/:left/:right\", ctrl.MuxHandler(\"Add\", h, nil))` 就是告诉 httptreemux 请求 url对应hander是 ctrl.MuxHandler\n```golang\nfunc (m *mux) Handle(method, path string, handle MuxHandler) {\n\ththandle := func(rw http.ResponseWriter, req *http.Request, htparams map[string]string) {\n\t\tparams := req.URL.Query()\n\t\tfor n, p := range htparams {\n\t\t\tparams.Set(n, p)\n\t\t}\n\t\thandle(rw, req, params)\n\t}\n\tm.handles[method+path] = handle\n\tm.router.Handle(method, path, hthandle)\n}\n```\n","slug":"goa请求处理解析","published":1,"updated":"2019-08-21T01:49:04.130Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzkm7pqj000ljl9uwp1l9bpq","content":"<h5 id=\"1-入口\"><a href=\"#1-入口\" class=\"headerlink\" title=\"1. 入口\"></a>1. 入口</h5><p><code>app.MountXXXController</code> -&gt;<br><code>service.Mux.Handle(&quot;GET&quot;, &quot;/add/:left/:right&quot;, ctrl.MuxHandler(&quot;Add&quot;, h, nil))</code> -&gt;<code>ctrl.MuxHandler(&quot;Add&quot;, h, nil)</code></p>\n<p>在 <code>ctrl.MuxHandler(&quot;Add&quot;, h, nil)</code> 中返回一个 先Invoke用户实现的对应请求的逻辑方法,再依次Invoke middleware 的函数：</p>\n<pre><code class=\"golang\">// MuxHandler wraps a request handler into a MuxHandler. The MuxHandler initializes the request\n// context by loading the request state, invokes the handler and in case of error invokes the\n// controller (if there is one) or Service error handler.\n// This function is intended for the controller generated code. User code should not need to call\n// it directly.\nfunc (ctrl *Controller) MuxHandler(name string, hdlr Handler, unm Unmarshaler) MuxHandler {\n    // Use closure to enable late computation of handlers to ensure all middleware has been\n    // registered.\n    var handler Handler\n\n    return func(rw http.ResponseWriter, req *http.Request, params url.Values) {\n        // Build handler middleware chains on first invocation\n        if handler == nil {\n            handler = func(ctx context.Context, rw http.ResponseWriter, req *http.Request) error {\n                if !ContextResponse(ctx).Written() {\n                    return hdlr(ctx, rw, req)\n                }\n                return nil\n            }\n            chain := append(ctrl.Service.middleware, ctrl.middleware...)\n            ml := len(chain)\n            for i := range chain {\n                handler = chain[ml-i-1](handler)\n            }\n        }\n\n        // Build context\n        ctx := NewContext(WithAction(ctrl.Context, name), rw, req, params)\n\n        // Protect against request bodies with unreasonable length\n        if ctrl.MaxRequestBodyLength &gt; 0 {\n            req.Body = http.MaxBytesReader(rw, req.Body, ctrl.MaxRequestBodyLength)\n        }\n\n        // Load body if any\n        if req.ContentLength &gt; 0 &amp;&amp; unm != nil {\n            if err := unm(ctx, ctrl.Service, req); err != nil {\n                if err.Error() == &quot;http: request body too large&quot; {\n                    msg := fmt.Sprintf(&quot;request body length exceeds %d bytes&quot;, ctrl.MaxRequestBodyLength)\n                    err = ErrRequestBodyTooLarge(msg)\n                } else {\n                    err = ErrBadRequest(err)\n                }\n                ctx = WithError(ctx, err)\n            }\n        }\n\n        // Invoke handler\n        if err := handler(ctx, ContextResponse(ctx), req); err != nil {\n            LogError(ctx, &quot;uncaught error&quot;, &quot;err&quot;, err)\n            respBody := fmt.Sprintf(&quot;Internal error: %s&quot;, err) // Sprintf catches panics\n            ctrl.Service.Send(ctx, 500, respBody)\n        }\n    }\n}\n</code></pre>\n<p>而<code>service.Mux.Handle(&quot;GET&quot;, &quot;/add/:left/:right&quot;, ctrl.MuxHandler(&quot;Add&quot;, h, nil))</code> 就是告诉 httptreemux 请求 url对应hander是 ctrl.MuxHandler</p>\n<pre><code class=\"golang\">func (m *mux) Handle(method, path string, handle MuxHandler) {\n    hthandle := func(rw http.ResponseWriter, req *http.Request, htparams map[string]string) {\n        params := req.URL.Query()\n        for n, p := range htparams {\n            params.Set(n, p)\n        }\n        handle(rw, req, params)\n    }\n    m.handles[method+path] = handle\n    m.router.Handle(method, path, hthandle)\n}\n</code></pre>\n","site":{"data":{}},"excerpt":"","more":"<h5 id=\"1-入口\"><a href=\"#1-入口\" class=\"headerlink\" title=\"1. 入口\"></a>1. 入口</h5><p><code>app.MountXXXController</code> -&gt;<br><code>service.Mux.Handle(&quot;GET&quot;, &quot;/add/:left/:right&quot;, ctrl.MuxHandler(&quot;Add&quot;, h, nil))</code> -&gt;<code>ctrl.MuxHandler(&quot;Add&quot;, h, nil)</code></p>\n<p>在 <code>ctrl.MuxHandler(&quot;Add&quot;, h, nil)</code> 中返回一个 先Invoke用户实现的对应请求的逻辑方法,再依次Invoke middleware 的函数：</p>\n<pre><code class=\"golang\">// MuxHandler wraps a request handler into a MuxHandler. The MuxHandler initializes the request\n// context by loading the request state, invokes the handler and in case of error invokes the\n// controller (if there is one) or Service error handler.\n// This function is intended for the controller generated code. User code should not need to call\n// it directly.\nfunc (ctrl *Controller) MuxHandler(name string, hdlr Handler, unm Unmarshaler) MuxHandler {\n    // Use closure to enable late computation of handlers to ensure all middleware has been\n    // registered.\n    var handler Handler\n\n    return func(rw http.ResponseWriter, req *http.Request, params url.Values) {\n        // Build handler middleware chains on first invocation\n        if handler == nil {\n            handler = func(ctx context.Context, rw http.ResponseWriter, req *http.Request) error {\n                if !ContextResponse(ctx).Written() {\n                    return hdlr(ctx, rw, req)\n                }\n                return nil\n            }\n            chain := append(ctrl.Service.middleware, ctrl.middleware...)\n            ml := len(chain)\n            for i := range chain {\n                handler = chain[ml-i-1](handler)\n            }\n        }\n\n        // Build context\n        ctx := NewContext(WithAction(ctrl.Context, name), rw, req, params)\n\n        // Protect against request bodies with unreasonable length\n        if ctrl.MaxRequestBodyLength &gt; 0 {\n            req.Body = http.MaxBytesReader(rw, req.Body, ctrl.MaxRequestBodyLength)\n        }\n\n        // Load body if any\n        if req.ContentLength &gt; 0 &amp;&amp; unm != nil {\n            if err := unm(ctx, ctrl.Service, req); err != nil {\n                if err.Error() == &quot;http: request body too large&quot; {\n                    msg := fmt.Sprintf(&quot;request body length exceeds %d bytes&quot;, ctrl.MaxRequestBodyLength)\n                    err = ErrRequestBodyTooLarge(msg)\n                } else {\n                    err = ErrBadRequest(err)\n                }\n                ctx = WithError(ctx, err)\n            }\n        }\n\n        // Invoke handler\n        if err := handler(ctx, ContextResponse(ctx), req); err != nil {\n            LogError(ctx, &quot;uncaught error&quot;, &quot;err&quot;, err)\n            respBody := fmt.Sprintf(&quot;Internal error: %s&quot;, err) // Sprintf catches panics\n            ctrl.Service.Send(ctx, 500, respBody)\n        }\n    }\n}\n</code></pre>\n<p>而<code>service.Mux.Handle(&quot;GET&quot;, &quot;/add/:left/:right&quot;, ctrl.MuxHandler(&quot;Add&quot;, h, nil))</code> 就是告诉 httptreemux 请求 url对应hander是 ctrl.MuxHandler</p>\n<pre><code class=\"golang\">func (m *mux) Handle(method, path string, handle MuxHandler) {\n    hthandle := func(rw http.ResponseWriter, req *http.Request, htparams map[string]string) {\n        params := req.URL.Query()\n        for n, p := range htparams {\n            params.Set(n, p)\n        }\n        handle(rw, req, params)\n    }\n    m.handles[method+path] = handle\n    m.router.Handle(method, path, hthandle)\n}\n</code></pre>\n"},{"title":"hexo的archive分页问题","date":"2015-10-26T18:37:11.000Z","_content":"在配置hexo的过程中，希望的效果是首页的文章分页，然后 archives和tags的文章不分页。\n开始以为是主题的代码实现bug，蒙头去改。后来才发现是配置问题，在hexo的[issue](https://github.com/hexojs/hexo/issues/1553)里面也有这样的记录.\n本人的hexo版本是 3.0 ，步骤如下：\n1.安装 hexo-generator-archive： `npm hexo-generator-archive --save`\n2.配置`_config.yml`，修改：\n\n```shell\n# Pagination\n## Set per_page to 0 to disable pagination\nper_page: 6\npagination_dir: page\narchive_generator:\n  yearly: true\n  monthly: true\n  per_page: 0\ncategory_generator:\n  per_page: 0\ntag_generator:\n  per_page: 0\n```\n\n\n","source":"_posts/hexo的archive分页问题.md","raw":"title: hexo的archive分页问题\ndate: 2015-10-27 02:37:11\ntags: [hexo]\n---\n在配置hexo的过程中，希望的效果是首页的文章分页，然后 archives和tags的文章不分页。\n开始以为是主题的代码实现bug，蒙头去改。后来才发现是配置问题，在hexo的[issue](https://github.com/hexojs/hexo/issues/1553)里面也有这样的记录.\n本人的hexo版本是 3.0 ，步骤如下：\n1.安装 hexo-generator-archive： `npm hexo-generator-archive --save`\n2.配置`_config.yml`，修改：\n\n```shell\n# Pagination\n## Set per_page to 0 to disable pagination\nper_page: 6\npagination_dir: page\narchive_generator:\n  yearly: true\n  monthly: true\n  per_page: 0\ncategory_generator:\n  per_page: 0\ntag_generator:\n  per_page: 0\n```\n\n\n","slug":"hexo的archive分页问题","published":1,"updated":"2019-08-21T01:49:04.130Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzkm7pqk000njl9usndlbyw2","content":"<p>在配置hexo的过程中，希望的效果是首页的文章分页，然后 archives和tags的文章不分页。<br>开始以为是主题的代码实现bug，蒙头去改。后来才发现是配置问题，在hexo的<a href=\"https://github.com/hexojs/hexo/issues/1553\" target=\"_blank\" rel=\"noopener\">issue</a>里面也有这样的记录.<br>本人的hexo版本是 3.0 ，步骤如下：<br>1.安装 hexo-generator-archive： <code>npm hexo-generator-archive --save</code><br>2.配置<code>_config.yml</code>，修改：</p>\n<pre><code class=\"shell\"># Pagination\n## Set per_page to 0 to disable pagination\nper_page: 6\npagination_dir: page\narchive_generator:\n  yearly: true\n  monthly: true\n  per_page: 0\ncategory_generator:\n  per_page: 0\ntag_generator:\n  per_page: 0\n</code></pre>\n","site":{"data":{}},"excerpt":"","more":"<p>在配置hexo的过程中，希望的效果是首页的文章分页，然后 archives和tags的文章不分页。<br>开始以为是主题的代码实现bug，蒙头去改。后来才发现是配置问题，在hexo的<a href=\"https://github.com/hexojs/hexo/issues/1553\" target=\"_blank\" rel=\"noopener\">issue</a>里面也有这样的记录.<br>本人的hexo版本是 3.0 ，步骤如下：<br>1.安装 hexo-generator-archive： <code>npm hexo-generator-archive --save</code><br>2.配置<code>_config.yml</code>，修改：</p>\n<pre><code class=\"shell\"># Pagination\n## Set per_page to 0 to disable pagination\nper_page: 6\npagination_dir: page\narchive_generator:\n  yearly: true\n  monthly: true\n  per_page: 0\ncategory_generator:\n  per_page: 0\ntag_generator:\n  per_page: 0\n</code></pre>\n"},{"title":"restfulWebServices2","date":"2016-01-05T02:40:28.000Z","_content":"\n##Restful web Services ----第 2章 笔记\n###识别资源\n开发RESTful Web 服务的首要步骤之一就是设计资源模型，资源模型对所有客户端用来与服务器交互的资源加以识别和分类。\n\n###如何选择资源粒度\n通过网络效率、表达的多少以及客户端的易用程度来帮助确定资源的粒度。\n粗粒度设计便于富客户端应用程序。而更精细的资源粒度可以更好地满足缓存的要求。因此，应从客户端和网络的角度确定资源的粒度。下列因素可能会进一步影响资源粒度：\n- 可缓存性\n- 修改频率\n- 可变性\n仔细设计资源粒度，以确保使用更多缓存，减小修改频率；或将不可变数据从使用缓存较少、修改频率更高或可变数据分离出来，这样可以改善客户端和服务端的效率。\n\n###如何将资源组织为集合\n将资源组织为集合，可以让客户端及服务器将一组资源视为一个资源来引用，在集合上执行查询，甚至将集合作为工厂来创建新资源。\n\n基于应用程序特有条件来识别相似的资源，常见的例子有，共享同一数据库`Schema` 的资源、有相同特性`attribute`或属性`property`的资源或客户端看起来是相似的资源。\n\n###如何支持计算或处理函数\n将处理函数视为一个资源，使用HTTP GET来获取表述，其中包含处理函数输出。使用查询参数来为处理函数提供输入。REST只适用于应用程序领域中的“事物”或“实体”资源，这是对REST架构约束最常见的理解之一。\n\n###何时及如何使用控制器来操作资源\n就RESTful Web服务而言，控制器能帮助提升服务器与客户端的独立程度，改善网络效率，并让服务器以原子操作的形式来实现复杂操作。控制器是一种能以原子方式修改资源的资源，它能帮助服务器抽象复杂的业务操作，并为客户端提供触发这些操作的途径。\n\n例子：\n>客户端向要提供某书的30天免费在线版本，并带有15%折扣。服务器上维护了一个集合，其中包含所有正在提供30天免费访问的图书，客户端可以提交POST请求将该书添加到集合中：\n```shell\n#向三十天免费访问图书列表添加图书的请求\nPOST /30daybookoffers HTTP/1.1\nHost: www.example.org\nContent-Type:application/x-www-urlencoded\nid=1234&from=2009-10-10&to=2000-11-10\n#响应\nHTTP/1.1 201 Created\nLocation: http://www.example.org/30dayebookoffer/1234\nContent-length:0\n```\n如果业务上要求以原子凡是完成这两个修改，那么可以使用控制器资源：即添加折扣及30天免费访问的请求。\n\n在请求中，参数` op=updateDiscount`和 `op=30dayOffer`用来标识操作，这样就会导致穿隧，穿隧会降低协议层面上的可见性，因为请求的可见部分（例如请求URI、使用HTTP方法、请求头和媒体类型）并不会明确地描述操作。要不惜一切代价避免穿隧，针对每个操作使用不同的资源。\n","source":"_posts/restfulWebServices2.md","raw":"title: restfulWebServices2\ndate: 2016-01-05 10:40:28\ntags: [Web,Restful]\n---\n\n##Restful web Services ----第 2章 笔记\n###识别资源\n开发RESTful Web 服务的首要步骤之一就是设计资源模型，资源模型对所有客户端用来与服务器交互的资源加以识别和分类。\n\n###如何选择资源粒度\n通过网络效率、表达的多少以及客户端的易用程度来帮助确定资源的粒度。\n粗粒度设计便于富客户端应用程序。而更精细的资源粒度可以更好地满足缓存的要求。因此，应从客户端和网络的角度确定资源的粒度。下列因素可能会进一步影响资源粒度：\n- 可缓存性\n- 修改频率\n- 可变性\n仔细设计资源粒度，以确保使用更多缓存，减小修改频率；或将不可变数据从使用缓存较少、修改频率更高或可变数据分离出来，这样可以改善客户端和服务端的效率。\n\n###如何将资源组织为集合\n将资源组织为集合，可以让客户端及服务器将一组资源视为一个资源来引用，在集合上执行查询，甚至将集合作为工厂来创建新资源。\n\n基于应用程序特有条件来识别相似的资源，常见的例子有，共享同一数据库`Schema` 的资源、有相同特性`attribute`或属性`property`的资源或客户端看起来是相似的资源。\n\n###如何支持计算或处理函数\n将处理函数视为一个资源，使用HTTP GET来获取表述，其中包含处理函数输出。使用查询参数来为处理函数提供输入。REST只适用于应用程序领域中的“事物”或“实体”资源，这是对REST架构约束最常见的理解之一。\n\n###何时及如何使用控制器来操作资源\n就RESTful Web服务而言，控制器能帮助提升服务器与客户端的独立程度，改善网络效率，并让服务器以原子操作的形式来实现复杂操作。控制器是一种能以原子方式修改资源的资源，它能帮助服务器抽象复杂的业务操作，并为客户端提供触发这些操作的途径。\n\n例子：\n>客户端向要提供某书的30天免费在线版本，并带有15%折扣。服务器上维护了一个集合，其中包含所有正在提供30天免费访问的图书，客户端可以提交POST请求将该书添加到集合中：\n```shell\n#向三十天免费访问图书列表添加图书的请求\nPOST /30daybookoffers HTTP/1.1\nHost: www.example.org\nContent-Type:application/x-www-urlencoded\nid=1234&from=2009-10-10&to=2000-11-10\n#响应\nHTTP/1.1 201 Created\nLocation: http://www.example.org/30dayebookoffer/1234\nContent-length:0\n```\n如果业务上要求以原子凡是完成这两个修改，那么可以使用控制器资源：即添加折扣及30天免费访问的请求。\n\n在请求中，参数` op=updateDiscount`和 `op=30dayOffer`用来标识操作，这样就会导致穿隧，穿隧会降低协议层面上的可见性，因为请求的可见部分（例如请求URI、使用HTTP方法、请求头和媒体类型）并不会明确地描述操作。要不惜一切代价避免穿隧，针对每个操作使用不同的资源。\n","slug":"restfulWebServices2","published":1,"updated":"2019-08-21T01:49:04.130Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzkm7pql000pjl9uskqgd5am","content":"<p>##Restful web Services —-第 2章 笔记</p>\n<p>###识别资源<br>开发RESTful Web 服务的首要步骤之一就是设计资源模型，资源模型对所有客户端用来与服务器交互的资源加以识别和分类。</p>\n<p>###如何选择资源粒度<br>通过网络效率、表达的多少以及客户端的易用程度来帮助确定资源的粒度。<br>粗粒度设计便于富客户端应用程序。而更精细的资源粒度可以更好地满足缓存的要求。因此，应从客户端和网络的角度确定资源的粒度。下列因素可能会进一步影响资源粒度：</p>\n<ul>\n<li>可缓存性</li>\n<li>修改频率</li>\n<li>可变性<br>仔细设计资源粒度，以确保使用更多缓存，减小修改频率；或将不可变数据从使用缓存较少、修改频率更高或可变数据分离出来，这样可以改善客户端和服务端的效率。</li>\n</ul>\n<p>###如何将资源组织为集合<br>将资源组织为集合，可以让客户端及服务器将一组资源视为一个资源来引用，在集合上执行查询，甚至将集合作为工厂来创建新资源。</p>\n<p>基于应用程序特有条件来识别相似的资源，常见的例子有，共享同一数据库<code>Schema</code> 的资源、有相同特性<code>attribute</code>或属性<code>property</code>的资源或客户端看起来是相似的资源。</p>\n<p>###如何支持计算或处理函数<br>将处理函数视为一个资源，使用HTTP GET来获取表述，其中包含处理函数输出。使用查询参数来为处理函数提供输入。REST只适用于应用程序领域中的“事物”或“实体”资源，这是对REST架构约束最常见的理解之一。</p>\n<p>###何时及如何使用控制器来操作资源<br>就RESTful Web服务而言，控制器能帮助提升服务器与客户端的独立程度，改善网络效率，并让服务器以原子操作的形式来实现复杂操作。控制器是一种能以原子方式修改资源的资源，它能帮助服务器抽象复杂的业务操作，并为客户端提供触发这些操作的途径。</p>\n<p>例子：</p>\n<blockquote>\n<p>客户端向要提供某书的30天免费在线版本，并带有15%折扣。服务器上维护了一个集合，其中包含所有正在提供30天免费访问的图书，客户端可以提交POST请求将该书添加到集合中：<br><code>`</code>shell</p>\n</blockquote>\n<p>#向三十天免费访问图书列表添加图书的请求<br>POST /30daybookoffers HTTP/1.1<br>Host: <a href=\"http://www.example.org\" target=\"_blank\" rel=\"noopener\">www.example.org</a><br>Content-Type:application/x-www-urlencoded<br>id=1234&amp;from=2009-10-10&amp;to=2000-11-10</p>\n<p>#响应<br>HTTP/1.1 201 Created<br>Location: <a href=\"http://www.example.org/30dayebookoffer/1234\" target=\"_blank\" rel=\"noopener\">http://www.example.org/30dayebookoffer/1234</a><br>Content-length:0<br><code>`</code><br>如果业务上要求以原子凡是完成这两个修改，那么可以使用控制器资源：即添加折扣及30天免费访问的请求。</p>\n<p>在请求中，参数<code>op=updateDiscount</code>和 <code>op=30dayOffer</code>用来标识操作，这样就会导致穿隧，穿隧会降低协议层面上的可见性，因为请求的可见部分（例如请求URI、使用HTTP方法、请求头和媒体类型）并不会明确地描述操作。要不惜一切代价避免穿隧，针对每个操作使用不同的资源。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>##Restful web Services —-第 2章 笔记</p>\n<p>###识别资源<br>开发RESTful Web 服务的首要步骤之一就是设计资源模型，资源模型对所有客户端用来与服务器交互的资源加以识别和分类。</p>\n<p>###如何选择资源粒度<br>通过网络效率、表达的多少以及客户端的易用程度来帮助确定资源的粒度。<br>粗粒度设计便于富客户端应用程序。而更精细的资源粒度可以更好地满足缓存的要求。因此，应从客户端和网络的角度确定资源的粒度。下列因素可能会进一步影响资源粒度：</p>\n<ul>\n<li>可缓存性</li>\n<li>修改频率</li>\n<li>可变性<br>仔细设计资源粒度，以确保使用更多缓存，减小修改频率；或将不可变数据从使用缓存较少、修改频率更高或可变数据分离出来，这样可以改善客户端和服务端的效率。</li>\n</ul>\n<p>###如何将资源组织为集合<br>将资源组织为集合，可以让客户端及服务器将一组资源视为一个资源来引用，在集合上执行查询，甚至将集合作为工厂来创建新资源。</p>\n<p>基于应用程序特有条件来识别相似的资源，常见的例子有，共享同一数据库<code>Schema</code> 的资源、有相同特性<code>attribute</code>或属性<code>property</code>的资源或客户端看起来是相似的资源。</p>\n<p>###如何支持计算或处理函数<br>将处理函数视为一个资源，使用HTTP GET来获取表述，其中包含处理函数输出。使用查询参数来为处理函数提供输入。REST只适用于应用程序领域中的“事物”或“实体”资源，这是对REST架构约束最常见的理解之一。</p>\n<p>###何时及如何使用控制器来操作资源<br>就RESTful Web服务而言，控制器能帮助提升服务器与客户端的独立程度，改善网络效率，并让服务器以原子操作的形式来实现复杂操作。控制器是一种能以原子方式修改资源的资源，它能帮助服务器抽象复杂的业务操作，并为客户端提供触发这些操作的途径。</p>\n<p>例子：</p>\n<blockquote>\n<p>客户端向要提供某书的30天免费在线版本，并带有15%折扣。服务器上维护了一个集合，其中包含所有正在提供30天免费访问的图书，客户端可以提交POST请求将该书添加到集合中：<br><code>`</code>shell</p>\n</blockquote>\n<p>#向三十天免费访问图书列表添加图书的请求<br>POST /30daybookoffers HTTP/1.1<br>Host: <a href=\"http://www.example.org\" target=\"_blank\" rel=\"noopener\">www.example.org</a><br>Content-Type:application/x-www-urlencoded<br>id=1234&amp;from=2009-10-10&amp;to=2000-11-10</p>\n<p>#响应<br>HTTP/1.1 201 Created<br>Location: <a href=\"http://www.example.org/30dayebookoffer/1234\" target=\"_blank\" rel=\"noopener\">http://www.example.org/30dayebookoffer/1234</a><br>Content-length:0<br><code>`</code><br>如果业务上要求以原子凡是完成这两个修改，那么可以使用控制器资源：即添加折扣及30天免费访问的请求。</p>\n<p>在请求中，参数<code>op=updateDiscount</code>和 <code>op=30dayOffer</code>用来标识操作，这样就会导致穿隧，穿隧会降低协议层面上的可见性，因为请求的可见部分（例如请求URI、使用HTTP方法、请求头和媒体类型）并不会明确地描述操作。要不惜一切代价避免穿隧，针对每个操作使用不同的资源。</p>\n"},{"title":"restfulWebService1","date":"2016-01-05T02:39:43.000Z","_content":"\n###REST(表述性状态转移）\n\nHTTP 的设计 目标是在客户端和服务器之间对库、服务器、代理、缓存和其他工具的可见性。可见性是：一个组件能够对其他两个组件之间的交互进行监视或仲裁的能力。当协议是可见的时，缓存、代理、防火墙等组件既可以监视甚至参与其中。\n\nHTTP 通过以下途径来实现可见性：\n>- HTTP的交互是无状态的，任何HTTP中介都可以推断出给定请求和响应的意义，而无须关联过去或将来的请求和响应。\n- HTTP使用一个统一接口，包括有OPTIONS，GET，HEAD,POST,DELETE和TRACE方法。接口中的每一个方   法操作一个且仅有一个资源。每个方法的语法和含义不会因应用程序或资源的不同而发生改变。\n- HTTP使用一种与MIME类似的信封格式进行表述编码。这个格式明确区分标头和内容。\n\n一个HTTP请求的格式：\n请求行：HTTP方法  资源路径  HTTP版本\n请求的表述形式表头：`Content-Type：...`\n请求的表述内容\n```\nPOST /api/bookclubserver/note/comment_text/put HTTP/1.1\\r\\n\nUser-Agent: curl/7.35.0\\r\\n\nHost: localhost:8080\\r\\n\nAccept: */*\\r\\n\ncontent-type: application/json\\r\\n\nContent-Length: 157\\r\\n\\r\\n\n{ \\\"note_id\\\":\\\"201505080931476889\\\",\\\"user_id\\\":\\\"201504171121428216\\\",\\\"note_comment_content\\\":\\\"Is luck to meet you!\\\",\\\"p_note_comment_id\\\":\\\"-1\\\",\\\"p_note_user_id\\\":\\\"-1\\\"}\n```\n一个HTTP响应的格式：\n响应行：HTTP版本  状态码  状态消息\n响应的表述形式标头：\n响应的表述内容\n```\nHTTP/1.1 200 OK\nconnection: keep-alive\nserver: Cowboy\ndate: Fri, 08 May 2015 01:43:11 GMT\ncontent-length: 61\ncontent-type: text/html\n{\"return_code\":0,\"status\":[],\"comment_id\":201505080943113579}\n```\n\n对于RESTful 服务，主要目标必定是尽最大可能保持可见性：使用HTTP方法时，其语义要与HTTP所规定的语义保持一致，并添加适当的标头来描述请求和响应；另一方面是使用适当的状态码和状态消息，以便代理、缓存和客户端可以决定请求的结果，状态码是一个整数，状态消息是文本。\n\n降低可见性原因：\n-数据的重叠\n\n为了其他好处放弃可见性：\n-方便客户端：为了方便客户端使用，服务器可能需要设计特定目标的粗粒度组件资源\n-抽象\n-网络效率：当客户端需要在短时间内连续执行几个操作时，可能需要将这些操作组合到一个批处理中，以降低网络延迟。\n\n####如何在服务器端实现安全和幂等的方法\n实现GET/OPTION/HEAD方法时，不要引起任何副作用。当客户端重新提交一个GET/HEAD/OPTIONS/PUT或DELETE请求时，确保服务器提供同样的表述形式：\n![http_method.png](http://upload-images.jianshu.io/upload_images/439839-388a3debc2df3549.png)\n\n#####实现安全方法\n为了保证安全方法不会引起副作用，可以将安全方法实现为只读操作：即客户端发起请求时，不会改变资源的状态。\n\n#####幂等方法\n幂等性保证客户端重复发起某个请求的效果与一次请求的效果一致。除POST以外的所有方法都必须是幂等的。在编程语言的术语中，幂等方法类似于`setter`。\n\n######DELETE方法的幂等性\nDELETE方法是幂等的。这意味着就算服务器在前一个请求中已经删除了资源，它也必须返回200 （OK）响应码\n\n####如何在客户端吹安全和幂等方法\n#####安全方法\n把GET/OPTIONS/HEAD看做只读操作，需要时，可以随时发起这些请求。\n#####幂等方法\n幂等性保证了客户端可以在不能肯定服务器是否成功处理了请求时，重复发起这一请求。在HTTP中，除了POST以外的所有方法都是幂等的。\n\n####何时使用GET方法\n使用 GET方法进行安全与幂等的信息获取。不要把GET方法用于不安全或非幂等操作，因为这样做可能会造成永久性的、意想不到的、不符合需要的资源改变。\n\n####何时使用POST方法\n- 创建新的资源。\n- 通过一个控制器资源来修改一个或多个资源\n- 执行需要大数据输入的查询\n- 在其他HTTP方法看上去不合适时，执行不安全或非幂等的操作。\n\n####何时使用PUT方法创建新资源\n只有在客户端可以决定资源的URi时才使用PUT方法创建新资源，否则使用POST.举个例子，一台存储服务器可能为每个客户端分配一个根URL，并让客户端把根URI作为文件系统的根目录，以便创建新资源，如果不能控制URI，请使用POST方法\n\n####如何使用POST方法实现异步任务\nHTTP是一种同步、无状态的协议。当客户端向服务器提交一个请求时，无论成功与否，客户端都期望得到一个回答。\n在接收到POST请求时，创建一个新的资源，并返回状态码202，其包含新资源的表述，这个新资源目的是让客户端可以跟踪异步任务的状态。\n","source":"_posts/restfulWebService1.md","raw":"title: restfulWebService1\ndate: 2016-01-05 10:39:43\ntags: [Web,Restful]\n---\n\n###REST(表述性状态转移）\n\nHTTP 的设计 目标是在客户端和服务器之间对库、服务器、代理、缓存和其他工具的可见性。可见性是：一个组件能够对其他两个组件之间的交互进行监视或仲裁的能力。当协议是可见的时，缓存、代理、防火墙等组件既可以监视甚至参与其中。\n\nHTTP 通过以下途径来实现可见性：\n>- HTTP的交互是无状态的，任何HTTP中介都可以推断出给定请求和响应的意义，而无须关联过去或将来的请求和响应。\n- HTTP使用一个统一接口，包括有OPTIONS，GET，HEAD,POST,DELETE和TRACE方法。接口中的每一个方   法操作一个且仅有一个资源。每个方法的语法和含义不会因应用程序或资源的不同而发生改变。\n- HTTP使用一种与MIME类似的信封格式进行表述编码。这个格式明确区分标头和内容。\n\n一个HTTP请求的格式：\n请求行：HTTP方法  资源路径  HTTP版本\n请求的表述形式表头：`Content-Type：...`\n请求的表述内容\n```\nPOST /api/bookclubserver/note/comment_text/put HTTP/1.1\\r\\n\nUser-Agent: curl/7.35.0\\r\\n\nHost: localhost:8080\\r\\n\nAccept: */*\\r\\n\ncontent-type: application/json\\r\\n\nContent-Length: 157\\r\\n\\r\\n\n{ \\\"note_id\\\":\\\"201505080931476889\\\",\\\"user_id\\\":\\\"201504171121428216\\\",\\\"note_comment_content\\\":\\\"Is luck to meet you!\\\",\\\"p_note_comment_id\\\":\\\"-1\\\",\\\"p_note_user_id\\\":\\\"-1\\\"}\n```\n一个HTTP响应的格式：\n响应行：HTTP版本  状态码  状态消息\n响应的表述形式标头：\n响应的表述内容\n```\nHTTP/1.1 200 OK\nconnection: keep-alive\nserver: Cowboy\ndate: Fri, 08 May 2015 01:43:11 GMT\ncontent-length: 61\ncontent-type: text/html\n{\"return_code\":0,\"status\":[],\"comment_id\":201505080943113579}\n```\n\n对于RESTful 服务，主要目标必定是尽最大可能保持可见性：使用HTTP方法时，其语义要与HTTP所规定的语义保持一致，并添加适当的标头来描述请求和响应；另一方面是使用适当的状态码和状态消息，以便代理、缓存和客户端可以决定请求的结果，状态码是一个整数，状态消息是文本。\n\n降低可见性原因：\n-数据的重叠\n\n为了其他好处放弃可见性：\n-方便客户端：为了方便客户端使用，服务器可能需要设计特定目标的粗粒度组件资源\n-抽象\n-网络效率：当客户端需要在短时间内连续执行几个操作时，可能需要将这些操作组合到一个批处理中，以降低网络延迟。\n\n####如何在服务器端实现安全和幂等的方法\n实现GET/OPTION/HEAD方法时，不要引起任何副作用。当客户端重新提交一个GET/HEAD/OPTIONS/PUT或DELETE请求时，确保服务器提供同样的表述形式：\n![http_method.png](http://upload-images.jianshu.io/upload_images/439839-388a3debc2df3549.png)\n\n#####实现安全方法\n为了保证安全方法不会引起副作用，可以将安全方法实现为只读操作：即客户端发起请求时，不会改变资源的状态。\n\n#####幂等方法\n幂等性保证客户端重复发起某个请求的效果与一次请求的效果一致。除POST以外的所有方法都必须是幂等的。在编程语言的术语中，幂等方法类似于`setter`。\n\n######DELETE方法的幂等性\nDELETE方法是幂等的。这意味着就算服务器在前一个请求中已经删除了资源，它也必须返回200 （OK）响应码\n\n####如何在客户端吹安全和幂等方法\n#####安全方法\n把GET/OPTIONS/HEAD看做只读操作，需要时，可以随时发起这些请求。\n#####幂等方法\n幂等性保证了客户端可以在不能肯定服务器是否成功处理了请求时，重复发起这一请求。在HTTP中，除了POST以外的所有方法都是幂等的。\n\n####何时使用GET方法\n使用 GET方法进行安全与幂等的信息获取。不要把GET方法用于不安全或非幂等操作，因为这样做可能会造成永久性的、意想不到的、不符合需要的资源改变。\n\n####何时使用POST方法\n- 创建新的资源。\n- 通过一个控制器资源来修改一个或多个资源\n- 执行需要大数据输入的查询\n- 在其他HTTP方法看上去不合适时，执行不安全或非幂等的操作。\n\n####何时使用PUT方法创建新资源\n只有在客户端可以决定资源的URi时才使用PUT方法创建新资源，否则使用POST.举个例子，一台存储服务器可能为每个客户端分配一个根URL，并让客户端把根URI作为文件系统的根目录，以便创建新资源，如果不能控制URI，请使用POST方法\n\n####如何使用POST方法实现异步任务\nHTTP是一种同步、无状态的协议。当客户端向服务器提交一个请求时，无论成功与否，客户端都期望得到一个回答。\n在接收到POST请求时，创建一个新的资源，并返回状态码202，其包含新资源的表述，这个新资源目的是让客户端可以跟踪异步任务的状态。\n","slug":"restfulWebService1","published":1,"updated":"2019-08-21T01:49:04.130Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzkm7pqm000rjl9uswsm6aqw","content":"<p>###REST(表述性状态转移）</p>\n<p>HTTP 的设计 目标是在客户端和服务器之间对库、服务器、代理、缓存和其他工具的可见性。可见性是：一个组件能够对其他两个组件之间的交互进行监视或仲裁的能力。当协议是可见的时，缓存、代理、防火墙等组件既可以监视甚至参与其中。</p>\n<p>HTTP 通过以下途径来实现可见性：</p>\n<blockquote>\n<ul>\n<li>HTTP的交互是无状态的，任何HTTP中介都可以推断出给定请求和响应的意义，而无须关联过去或将来的请求和响应。</li>\n<li>HTTP使用一个统一接口，包括有OPTIONS，GET，HEAD,POST,DELETE和TRACE方法。接口中的每一个方   法操作一个且仅有一个资源。每个方法的语法和含义不会因应用程序或资源的不同而发生改变。</li>\n<li>HTTP使用一种与MIME类似的信封格式进行表述编码。这个格式明确区分标头和内容。</li>\n</ul>\n</blockquote>\n<p>一个HTTP请求的格式：<br>请求行：HTTP方法  资源路径  HTTP版本<br>请求的表述形式表头：<code>Content-Type：...</code><br>请求的表述内容</p>\n<pre><code>POST /api/bookclubserver/note/comment_text/put HTTP/1.1\\r\\n\nUser-Agent: curl/7.35.0\\r\\n\nHost: localhost:8080\\r\\n\nAccept: */*\\r\\n\ncontent-type: application/json\\r\\n\nContent-Length: 157\\r\\n\\r\\n\n{ \\&quot;note_id\\&quot;:\\&quot;201505080931476889\\&quot;,\\&quot;user_id\\&quot;:\\&quot;201504171121428216\\&quot;,\\&quot;note_comment_content\\&quot;:\\&quot;Is luck to meet you!\\&quot;,\\&quot;p_note_comment_id\\&quot;:\\&quot;-1\\&quot;,\\&quot;p_note_user_id\\&quot;:\\&quot;-1\\&quot;}\n</code></pre><p>一个HTTP响应的格式：<br>响应行：HTTP版本  状态码  状态消息<br>响应的表述形式标头：<br>响应的表述内容</p>\n<pre><code>HTTP/1.1 200 OK\nconnection: keep-alive\nserver: Cowboy\ndate: Fri, 08 May 2015 01:43:11 GMT\ncontent-length: 61\ncontent-type: text/html\n{&quot;return_code&quot;:0,&quot;status&quot;:[],&quot;comment_id&quot;:201505080943113579}\n</code></pre><p>对于RESTful 服务，主要目标必定是尽最大可能保持可见性：使用HTTP方法时，其语义要与HTTP所规定的语义保持一致，并添加适当的标头来描述请求和响应；另一方面是使用适当的状态码和状态消息，以便代理、缓存和客户端可以决定请求的结果，状态码是一个整数，状态消息是文本。</p>\n<p>降低可见性原因：<br>-数据的重叠</p>\n<p>为了其他好处放弃可见性：<br>-方便客户端：为了方便客户端使用，服务器可能需要设计特定目标的粗粒度组件资源<br>-抽象<br>-网络效率：当客户端需要在短时间内连续执行几个操作时，可能需要将这些操作组合到一个批处理中，以降低网络延迟。</p>\n<p>####如何在服务器端实现安全和幂等的方法<br>实现GET/OPTION/HEAD方法时，不要引起任何副作用。当客户端重新提交一个GET/HEAD/OPTIONS/PUT或DELETE请求时，确保服务器提供同样的表述形式：<br><img src=\"http://upload-images.jianshu.io/upload_images/439839-388a3debc2df3549.png\" alt=\"http_method.png\"></p>\n<p>#####实现安全方法<br>为了保证安全方法不会引起副作用，可以将安全方法实现为只读操作：即客户端发起请求时，不会改变资源的状态。</p>\n<p>#####幂等方法<br>幂等性保证客户端重复发起某个请求的效果与一次请求的效果一致。除POST以外的所有方法都必须是幂等的。在编程语言的术语中，幂等方法类似于<code>setter</code>。</p>\n<p>######DELETE方法的幂等性<br>DELETE方法是幂等的。这意味着就算服务器在前一个请求中已经删除了资源，它也必须返回200 （OK）响应码</p>\n<p>####如何在客户端吹安全和幂等方法</p>\n<p>#####安全方法<br>把GET/OPTIONS/HEAD看做只读操作，需要时，可以随时发起这些请求。</p>\n<p>#####幂等方法<br>幂等性保证了客户端可以在不能肯定服务器是否成功处理了请求时，重复发起这一请求。在HTTP中，除了POST以外的所有方法都是幂等的。</p>\n<p>####何时使用GET方法<br>使用 GET方法进行安全与幂等的信息获取。不要把GET方法用于不安全或非幂等操作，因为这样做可能会造成永久性的、意想不到的、不符合需要的资源改变。</p>\n<p>####何时使用POST方法</p>\n<ul>\n<li>创建新的资源。</li>\n<li>通过一个控制器资源来修改一个或多个资源</li>\n<li>执行需要大数据输入的查询</li>\n<li>在其他HTTP方法看上去不合适时，执行不安全或非幂等的操作。</li>\n</ul>\n<p>####何时使用PUT方法创建新资源<br>只有在客户端可以决定资源的URi时才使用PUT方法创建新资源，否则使用POST.举个例子，一台存储服务器可能为每个客户端分配一个根URL，并让客户端把根URI作为文件系统的根目录，以便创建新资源，如果不能控制URI，请使用POST方法</p>\n<p>####如何使用POST方法实现异步任务<br>HTTP是一种同步、无状态的协议。当客户端向服务器提交一个请求时，无论成功与否，客户端都期望得到一个回答。<br>在接收到POST请求时，创建一个新的资源，并返回状态码202，其包含新资源的表述，这个新资源目的是让客户端可以跟踪异步任务的状态。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>###REST(表述性状态转移）</p>\n<p>HTTP 的设计 目标是在客户端和服务器之间对库、服务器、代理、缓存和其他工具的可见性。可见性是：一个组件能够对其他两个组件之间的交互进行监视或仲裁的能力。当协议是可见的时，缓存、代理、防火墙等组件既可以监视甚至参与其中。</p>\n<p>HTTP 通过以下途径来实现可见性：</p>\n<blockquote>\n<ul>\n<li>HTTP的交互是无状态的，任何HTTP中介都可以推断出给定请求和响应的意义，而无须关联过去或将来的请求和响应。</li>\n<li>HTTP使用一个统一接口，包括有OPTIONS，GET，HEAD,POST,DELETE和TRACE方法。接口中的每一个方   法操作一个且仅有一个资源。每个方法的语法和含义不会因应用程序或资源的不同而发生改变。</li>\n<li>HTTP使用一种与MIME类似的信封格式进行表述编码。这个格式明确区分标头和内容。</li>\n</ul>\n</blockquote>\n<p>一个HTTP请求的格式：<br>请求行：HTTP方法  资源路径  HTTP版本<br>请求的表述形式表头：<code>Content-Type：...</code><br>请求的表述内容</p>\n<pre><code>POST /api/bookclubserver/note/comment_text/put HTTP/1.1\\r\\n\nUser-Agent: curl/7.35.0\\r\\n\nHost: localhost:8080\\r\\n\nAccept: */*\\r\\n\ncontent-type: application/json\\r\\n\nContent-Length: 157\\r\\n\\r\\n\n{ \\&quot;note_id\\&quot;:\\&quot;201505080931476889\\&quot;,\\&quot;user_id\\&quot;:\\&quot;201504171121428216\\&quot;,\\&quot;note_comment_content\\&quot;:\\&quot;Is luck to meet you!\\&quot;,\\&quot;p_note_comment_id\\&quot;:\\&quot;-1\\&quot;,\\&quot;p_note_user_id\\&quot;:\\&quot;-1\\&quot;}\n</code></pre><p>一个HTTP响应的格式：<br>响应行：HTTP版本  状态码  状态消息<br>响应的表述形式标头：<br>响应的表述内容</p>\n<pre><code>HTTP/1.1 200 OK\nconnection: keep-alive\nserver: Cowboy\ndate: Fri, 08 May 2015 01:43:11 GMT\ncontent-length: 61\ncontent-type: text/html\n{&quot;return_code&quot;:0,&quot;status&quot;:[],&quot;comment_id&quot;:201505080943113579}\n</code></pre><p>对于RESTful 服务，主要目标必定是尽最大可能保持可见性：使用HTTP方法时，其语义要与HTTP所规定的语义保持一致，并添加适当的标头来描述请求和响应；另一方面是使用适当的状态码和状态消息，以便代理、缓存和客户端可以决定请求的结果，状态码是一个整数，状态消息是文本。</p>\n<p>降低可见性原因：<br>-数据的重叠</p>\n<p>为了其他好处放弃可见性：<br>-方便客户端：为了方便客户端使用，服务器可能需要设计特定目标的粗粒度组件资源<br>-抽象<br>-网络效率：当客户端需要在短时间内连续执行几个操作时，可能需要将这些操作组合到一个批处理中，以降低网络延迟。</p>\n<p>####如何在服务器端实现安全和幂等的方法<br>实现GET/OPTION/HEAD方法时，不要引起任何副作用。当客户端重新提交一个GET/HEAD/OPTIONS/PUT或DELETE请求时，确保服务器提供同样的表述形式：<br><img src=\"http://upload-images.jianshu.io/upload_images/439839-388a3debc2df3549.png\" alt=\"http_method.png\"></p>\n<p>#####实现安全方法<br>为了保证安全方法不会引起副作用，可以将安全方法实现为只读操作：即客户端发起请求时，不会改变资源的状态。</p>\n<p>#####幂等方法<br>幂等性保证客户端重复发起某个请求的效果与一次请求的效果一致。除POST以外的所有方法都必须是幂等的。在编程语言的术语中，幂等方法类似于<code>setter</code>。</p>\n<p>######DELETE方法的幂等性<br>DELETE方法是幂等的。这意味着就算服务器在前一个请求中已经删除了资源，它也必须返回200 （OK）响应码</p>\n<p>####如何在客户端吹安全和幂等方法</p>\n<p>#####安全方法<br>把GET/OPTIONS/HEAD看做只读操作，需要时，可以随时发起这些请求。</p>\n<p>#####幂等方法<br>幂等性保证了客户端可以在不能肯定服务器是否成功处理了请求时，重复发起这一请求。在HTTP中，除了POST以外的所有方法都是幂等的。</p>\n<p>####何时使用GET方法<br>使用 GET方法进行安全与幂等的信息获取。不要把GET方法用于不安全或非幂等操作，因为这样做可能会造成永久性的、意想不到的、不符合需要的资源改变。</p>\n<p>####何时使用POST方法</p>\n<ul>\n<li>创建新的资源。</li>\n<li>通过一个控制器资源来修改一个或多个资源</li>\n<li>执行需要大数据输入的查询</li>\n<li>在其他HTTP方法看上去不合适时，执行不安全或非幂等的操作。</li>\n</ul>\n<p>####何时使用PUT方法创建新资源<br>只有在客户端可以决定资源的URi时才使用PUT方法创建新资源，否则使用POST.举个例子，一台存储服务器可能为每个客户端分配一个根URL，并让客户端把根URI作为文件系统的根目录，以便创建新资源，如果不能控制URI，请使用POST方法</p>\n<p>####如何使用POST方法实现异步任务<br>HTTP是一种同步、无状态的协议。当客户端向服务器提交一个请求时，无论成功与否，客户端都期望得到一个回答。<br>在接收到POST请求时，创建一个新的资源，并返回状态码202，其包含新资源的表述，这个新资源目的是让客户端可以跟踪异步任务的状态。</p>\n"},{"title":"restfulWebServices3","date":"2016-01-05T02:41:11.000Z","_content":"###设计表述\n客户端所关心的资源是一个抽象的实体，它是用URI来标识的。另一方面，表述是具体而真实的，你在客户端和服务器上针对它编写代码，进行操作。\nHTTP在请求和响应中为表述提供了一种包装格式。设计表述设计：\n1.使用HTTP提供的格式包含正确的标头，\n2.当表述有正文时，为正文选择合适的媒体类型并设计一种格式。\n\n###如何使用实体头来注解表述\n表述不仅仅是以某种格式序列化后的数据，它是一连串字节加上用于描述那些字节的元数据。在HTTP中，表述元数据是由使用实体头的名值对来实现的。\n使用以下标头来注解包含消息正文的表述：\n- `Conent-Type`，用于描述表述类型，包含charset 参数或其他针对该媒体类型而定义的参数。\n- `Content-Length`,用于指定表述正文的字节大小。HTTP1.1支持一种更有效的机制，名为分块转移编码（chuncked transfer encoding)\n- `Content-Language`,如果您以某种语言对表述进行本地化，用该标头来指定语言。\n- `Content-MD5`，工具/软件 在处理或存储表述时，可能存在错误，需要提供一致性校验，用该标头来包含一个表述正文的MD5摘要,在进行内容编码(gzip,compress等）之后，转移编码（即chunked）之前计算摘要值。请注意，TCP使用checksum在传输层提供一致性校验。\n- `Content-Encoding`，当你使用gzip，compress或deflate对表述正文进行编码时，使用该标头。\n- `Last-Modified` ，用来说明服务器修改表述或资源的最后时间。\n\nHTTP的设计是这样的，发送方可以用一系列名为实体头的标头来描述表述\n正文（也称为实体正文或消息正文）。有了这些标头，接收方可以在无须查看正文的情况下决定如何处理正文。它们还可以将解析正文所需要提前了解及猜测的内容减到最小程度。\n\n###如何解释实体头\n当服务器或客户端接受到表述时，在处理请求前正确地解释实体头是很重要的。本节讨论了如何从所包含的标头中解释表述。\n\n- `Content-Type` :接收到不带Content-Type的表述时，客户端将其视为不正确的响应，服务器返回错误码400\n- `Content-Length`在没有确定接受到的表述不带Transfer-Encoding：chunked前，不要检查Content-Length头是否存在。\n- `Content-Encoding` 让您的网络库代码来解压那些压缩过的表述。\n- `Content-Language` 如果存在该标头，读取并存储它的值，记录下所使用的语言。\n\n\n###3.6如何设计JSON表述\n 在每个表述中，包含一个指向该资源的self链接，对于那些组成资源的应用程序领域实体，在表述中包含它们的标识符。如果表述中的对象是本地化的，添加一个属性来表示本地化内容的语言。\n\n###如何设计集合表述\n客户端会在集合成员中进行迭代，由于某些集合会包含大量成员资源，客户端需要对集合进行分页或滚动显示，在每个集合表述中包含以下内容：\n- 一个指向集合资源的self链接\n- 如果集合是分页的，并且还有下一页，要有一个指向下一页的链接。\n- 如果集合是分页的，并且还有上一页，要有一个指向上一页的链接。\n- 一个集合大小的指示符\n\n\n###3.11如何在表述中编码二进制数据\n使用multipart/mixed,multipart/related 或multipart/alternative这样的分段媒体类型，避免使用Base64编码将二进制数据与文本格式编码在一起。\n分段消息让你能把不同格式的数据整合到一个HTTP消息中。一个分段消息包含多个消息部分，由边界进行分割，每个部分都可以包含不同媒体类型的消息。\n```Content-type：multipart/mixed;boundary=\"abcd\"\n--abcd\nContent-type:application/xml;charset=UTF-8\n<movie> ... <./movie>\n--abcd\nContent-type:video/mpeg\n<video></video>\n--abcd--\n```\n该分段消息有两个部分，一部分包含了一个XML文档，另一部分包含一个视频。\n分段媒体类型：\n`multipart/form-data `   把键值对数据与任意媒体类型的数据编码在一起，与您用HTML表单上传文件时的用法一致。\n`multipart/mixed  `         分段消息把application/xml表示的电影元数据和video/mpeg表示的视频整合进了一个HTTP消息中\n`multipart/alternative   `\n`multipart/related  `      当消息的各个部分是互相关联的，而且需要一起处理这些部分时，使用该媒体类型，第一部分是根，可以通过Content-ID头引用其他部分\n\n\n\n###如何返回错误\nHTTP    基于表述的交换，对于错误来说也是如此，当服务器发生错误时，都会返回一个反映错误在的表述。\n","source":"_posts/restfulWebServices3.md","raw":"title: restfulWebServices3\ndate: 2016-01-05 10:41:11\ntags: [Web,Restful]\n---\n###设计表述\n客户端所关心的资源是一个抽象的实体，它是用URI来标识的。另一方面，表述是具体而真实的，你在客户端和服务器上针对它编写代码，进行操作。\nHTTP在请求和响应中为表述提供了一种包装格式。设计表述设计：\n1.使用HTTP提供的格式包含正确的标头，\n2.当表述有正文时，为正文选择合适的媒体类型并设计一种格式。\n\n###如何使用实体头来注解表述\n表述不仅仅是以某种格式序列化后的数据，它是一连串字节加上用于描述那些字节的元数据。在HTTP中，表述元数据是由使用实体头的名值对来实现的。\n使用以下标头来注解包含消息正文的表述：\n- `Conent-Type`，用于描述表述类型，包含charset 参数或其他针对该媒体类型而定义的参数。\n- `Content-Length`,用于指定表述正文的字节大小。HTTP1.1支持一种更有效的机制，名为分块转移编码（chuncked transfer encoding)\n- `Content-Language`,如果您以某种语言对表述进行本地化，用该标头来指定语言。\n- `Content-MD5`，工具/软件 在处理或存储表述时，可能存在错误，需要提供一致性校验，用该标头来包含一个表述正文的MD5摘要,在进行内容编码(gzip,compress等）之后，转移编码（即chunked）之前计算摘要值。请注意，TCP使用checksum在传输层提供一致性校验。\n- `Content-Encoding`，当你使用gzip，compress或deflate对表述正文进行编码时，使用该标头。\n- `Last-Modified` ，用来说明服务器修改表述或资源的最后时间。\n\nHTTP的设计是这样的，发送方可以用一系列名为实体头的标头来描述表述\n正文（也称为实体正文或消息正文）。有了这些标头，接收方可以在无须查看正文的情况下决定如何处理正文。它们还可以将解析正文所需要提前了解及猜测的内容减到最小程度。\n\n###如何解释实体头\n当服务器或客户端接受到表述时，在处理请求前正确地解释实体头是很重要的。本节讨论了如何从所包含的标头中解释表述。\n\n- `Content-Type` :接收到不带Content-Type的表述时，客户端将其视为不正确的响应，服务器返回错误码400\n- `Content-Length`在没有确定接受到的表述不带Transfer-Encoding：chunked前，不要检查Content-Length头是否存在。\n- `Content-Encoding` 让您的网络库代码来解压那些压缩过的表述。\n- `Content-Language` 如果存在该标头，读取并存储它的值，记录下所使用的语言。\n\n\n###3.6如何设计JSON表述\n 在每个表述中，包含一个指向该资源的self链接，对于那些组成资源的应用程序领域实体，在表述中包含它们的标识符。如果表述中的对象是本地化的，添加一个属性来表示本地化内容的语言。\n\n###如何设计集合表述\n客户端会在集合成员中进行迭代，由于某些集合会包含大量成员资源，客户端需要对集合进行分页或滚动显示，在每个集合表述中包含以下内容：\n- 一个指向集合资源的self链接\n- 如果集合是分页的，并且还有下一页，要有一个指向下一页的链接。\n- 如果集合是分页的，并且还有上一页，要有一个指向上一页的链接。\n- 一个集合大小的指示符\n\n\n###3.11如何在表述中编码二进制数据\n使用multipart/mixed,multipart/related 或multipart/alternative这样的分段媒体类型，避免使用Base64编码将二进制数据与文本格式编码在一起。\n分段消息让你能把不同格式的数据整合到一个HTTP消息中。一个分段消息包含多个消息部分，由边界进行分割，每个部分都可以包含不同媒体类型的消息。\n```Content-type：multipart/mixed;boundary=\"abcd\"\n--abcd\nContent-type:application/xml;charset=UTF-8\n<movie> ... <./movie>\n--abcd\nContent-type:video/mpeg\n<video></video>\n--abcd--\n```\n该分段消息有两个部分，一部分包含了一个XML文档，另一部分包含一个视频。\n分段媒体类型：\n`multipart/form-data `   把键值对数据与任意媒体类型的数据编码在一起，与您用HTML表单上传文件时的用法一致。\n`multipart/mixed  `         分段消息把application/xml表示的电影元数据和video/mpeg表示的视频整合进了一个HTTP消息中\n`multipart/alternative   `\n`multipart/related  `      当消息的各个部分是互相关联的，而且需要一起处理这些部分时，使用该媒体类型，第一部分是根，可以通过Content-ID头引用其他部分\n\n\n\n###如何返回错误\nHTTP    基于表述的交换，对于错误来说也是如此，当服务器发生错误时，都会返回一个反映错误在的表述。\n","slug":"restfulWebServices3","published":1,"updated":"2019-08-21T01:49:04.130Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzkm7pqn000tjl9u90l4usmr","content":"<p>###设计表述<br>客户端所关心的资源是一个抽象的实体，它是用URI来标识的。另一方面，表述是具体而真实的，你在客户端和服务器上针对它编写代码，进行操作。<br>HTTP在请求和响应中为表述提供了一种包装格式。设计表述设计：<br>1.使用HTTP提供的格式包含正确的标头，<br>2.当表述有正文时，为正文选择合适的媒体类型并设计一种格式。</p>\n<p>###如何使用实体头来注解表述<br>表述不仅仅是以某种格式序列化后的数据，它是一连串字节加上用于描述那些字节的元数据。在HTTP中，表述元数据是由使用实体头的名值对来实现的。<br>使用以下标头来注解包含消息正文的表述：</p>\n<ul>\n<li><code>Conent-Type</code>，用于描述表述类型，包含charset 参数或其他针对该媒体类型而定义的参数。</li>\n<li><code>Content-Length</code>,用于指定表述正文的字节大小。HTTP1.1支持一种更有效的机制，名为分块转移编码（chuncked transfer encoding)</li>\n<li><code>Content-Language</code>,如果您以某种语言对表述进行本地化，用该标头来指定语言。</li>\n<li><code>Content-MD5</code>，工具/软件 在处理或存储表述时，可能存在错误，需要提供一致性校验，用该标头来包含一个表述正文的MD5摘要,在进行内容编码(gzip,compress等）之后，转移编码（即chunked）之前计算摘要值。请注意，TCP使用checksum在传输层提供一致性校验。</li>\n<li><code>Content-Encoding</code>，当你使用gzip，compress或deflate对表述正文进行编码时，使用该标头。</li>\n<li><code>Last-Modified</code> ，用来说明服务器修改表述或资源的最后时间。</li>\n</ul>\n<p>HTTP的设计是这样的，发送方可以用一系列名为实体头的标头来描述表述<br>正文（也称为实体正文或消息正文）。有了这些标头，接收方可以在无须查看正文的情况下决定如何处理正文。它们还可以将解析正文所需要提前了解及猜测的内容减到最小程度。</p>\n<p>###如何解释实体头<br>当服务器或客户端接受到表述时，在处理请求前正确地解释实体头是很重要的。本节讨论了如何从所包含的标头中解释表述。</p>\n<ul>\n<li><code>Content-Type</code> :接收到不带Content-Type的表述时，客户端将其视为不正确的响应，服务器返回错误码400</li>\n<li><code>Content-Length</code>在没有确定接受到的表述不带Transfer-Encoding：chunked前，不要检查Content-Length头是否存在。</li>\n<li><code>Content-Encoding</code> 让您的网络库代码来解压那些压缩过的表述。</li>\n<li><code>Content-Language</code> 如果存在该标头，读取并存储它的值，记录下所使用的语言。</li>\n</ul>\n<p>###3.6如何设计JSON表述<br> 在每个表述中，包含一个指向该资源的self链接，对于那些组成资源的应用程序领域实体，在表述中包含它们的标识符。如果表述中的对象是本地化的，添加一个属性来表示本地化内容的语言。</p>\n<p>###如何设计集合表述<br>客户端会在集合成员中进行迭代，由于某些集合会包含大量成员资源，客户端需要对集合进行分页或滚动显示，在每个集合表述中包含以下内容：</p>\n<ul>\n<li>一个指向集合资源的self链接</li>\n<li>如果集合是分页的，并且还有下一页，要有一个指向下一页的链接。</li>\n<li>如果集合是分页的，并且还有上一页，要有一个指向上一页的链接。</li>\n<li>一个集合大小的指示符</li>\n</ul>\n<p>###3.11如何在表述中编码二进制数据<br>使用multipart/mixed,multipart/related 或multipart/alternative这样的分段媒体类型，避免使用Base64编码将二进制数据与文本格式编码在一起。<br>分段消息让你能把不同格式的数据整合到一个HTTP消息中。一个分段消息包含多个消息部分，由边界进行分割，每个部分都可以包含不同媒体类型的消息。</p>\n<pre><code class=\"Content-type：multipart/mixed;boundary=&quot;abcd&quot;\">--abcd\nContent-type:application/xml;charset=UTF-8\n&lt;movie&gt; ... &lt;./movie&gt;\n--abcd\nContent-type:video/mpeg\n&lt;video&gt;&lt;/video&gt;\n--abcd--\n</code></pre>\n<p>该分段消息有两个部分，一部分包含了一个XML文档，另一部分包含一个视频。<br>分段媒体类型：<br><code>multipart/form-data</code>   把键值对数据与任意媒体类型的数据编码在一起，与您用HTML表单上传文件时的用法一致。<br><code>multipart/mixed</code>         分段消息把application/xml表示的电影元数据和video/mpeg表示的视频整合进了一个HTTP消息中<br><code>multipart/alternative</code><br><code>multipart/related</code>      当消息的各个部分是互相关联的，而且需要一起处理这些部分时，使用该媒体类型，第一部分是根，可以通过Content-ID头引用其他部分</p>\n<p>###如何返回错误<br>HTTP    基于表述的交换，对于错误来说也是如此，当服务器发生错误时，都会返回一个反映错误在的表述。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>###设计表述<br>客户端所关心的资源是一个抽象的实体，它是用URI来标识的。另一方面，表述是具体而真实的，你在客户端和服务器上针对它编写代码，进行操作。<br>HTTP在请求和响应中为表述提供了一种包装格式。设计表述设计：<br>1.使用HTTP提供的格式包含正确的标头，<br>2.当表述有正文时，为正文选择合适的媒体类型并设计一种格式。</p>\n<p>###如何使用实体头来注解表述<br>表述不仅仅是以某种格式序列化后的数据，它是一连串字节加上用于描述那些字节的元数据。在HTTP中，表述元数据是由使用实体头的名值对来实现的。<br>使用以下标头来注解包含消息正文的表述：</p>\n<ul>\n<li><code>Conent-Type</code>，用于描述表述类型，包含charset 参数或其他针对该媒体类型而定义的参数。</li>\n<li><code>Content-Length</code>,用于指定表述正文的字节大小。HTTP1.1支持一种更有效的机制，名为分块转移编码（chuncked transfer encoding)</li>\n<li><code>Content-Language</code>,如果您以某种语言对表述进行本地化，用该标头来指定语言。</li>\n<li><code>Content-MD5</code>，工具/软件 在处理或存储表述时，可能存在错误，需要提供一致性校验，用该标头来包含一个表述正文的MD5摘要,在进行内容编码(gzip,compress等）之后，转移编码（即chunked）之前计算摘要值。请注意，TCP使用checksum在传输层提供一致性校验。</li>\n<li><code>Content-Encoding</code>，当你使用gzip，compress或deflate对表述正文进行编码时，使用该标头。</li>\n<li><code>Last-Modified</code> ，用来说明服务器修改表述或资源的最后时间。</li>\n</ul>\n<p>HTTP的设计是这样的，发送方可以用一系列名为实体头的标头来描述表述<br>正文（也称为实体正文或消息正文）。有了这些标头，接收方可以在无须查看正文的情况下决定如何处理正文。它们还可以将解析正文所需要提前了解及猜测的内容减到最小程度。</p>\n<p>###如何解释实体头<br>当服务器或客户端接受到表述时，在处理请求前正确地解释实体头是很重要的。本节讨论了如何从所包含的标头中解释表述。</p>\n<ul>\n<li><code>Content-Type</code> :接收到不带Content-Type的表述时，客户端将其视为不正确的响应，服务器返回错误码400</li>\n<li><code>Content-Length</code>在没有确定接受到的表述不带Transfer-Encoding：chunked前，不要检查Content-Length头是否存在。</li>\n<li><code>Content-Encoding</code> 让您的网络库代码来解压那些压缩过的表述。</li>\n<li><code>Content-Language</code> 如果存在该标头，读取并存储它的值，记录下所使用的语言。</li>\n</ul>\n<p>###3.6如何设计JSON表述<br> 在每个表述中，包含一个指向该资源的self链接，对于那些组成资源的应用程序领域实体，在表述中包含它们的标识符。如果表述中的对象是本地化的，添加一个属性来表示本地化内容的语言。</p>\n<p>###如何设计集合表述<br>客户端会在集合成员中进行迭代，由于某些集合会包含大量成员资源，客户端需要对集合进行分页或滚动显示，在每个集合表述中包含以下内容：</p>\n<ul>\n<li>一个指向集合资源的self链接</li>\n<li>如果集合是分页的，并且还有下一页，要有一个指向下一页的链接。</li>\n<li>如果集合是分页的，并且还有上一页，要有一个指向上一页的链接。</li>\n<li>一个集合大小的指示符</li>\n</ul>\n<p>###3.11如何在表述中编码二进制数据<br>使用multipart/mixed,multipart/related 或multipart/alternative这样的分段媒体类型，避免使用Base64编码将二进制数据与文本格式编码在一起。<br>分段消息让你能把不同格式的数据整合到一个HTTP消息中。一个分段消息包含多个消息部分，由边界进行分割，每个部分都可以包含不同媒体类型的消息。</p>\n<pre><code class=\"Content-type：multipart/mixed;boundary=&quot;abcd&quot;\">--abcd\nContent-type:application/xml;charset=UTF-8\n&lt;movie&gt; ... &lt;./movie&gt;\n--abcd\nContent-type:video/mpeg\n&lt;video&gt;&lt;/video&gt;\n--abcd--\n</code></pre>\n<p>该分段消息有两个部分，一部分包含了一个XML文档，另一部分包含一个视频。<br>分段媒体类型：<br><code>multipart/form-data</code>   把键值对数据与任意媒体类型的数据编码在一起，与您用HTML表单上传文件时的用法一致。<br><code>multipart/mixed</code>         分段消息把application/xml表示的电影元数据和video/mpeg表示的视频整合进了一个HTTP消息中<br><code>multipart/alternative</code><br><code>multipart/related</code>      当消息的各个部分是互相关联的，而且需要一起处理这些部分时，使用该媒体类型，第一部分是根，可以通过Content-ID头引用其他部分</p>\n<p>###如何返回错误<br>HTTP    基于表述的交换，对于错误来说也是如此，当服务器发生错误时，都会返回一个反映错误在的表述。</p>\n"},{"title":"tsung压测restful服务器","date":"2015-11-06T08:18:20.000Z","_content":"\n1. android 手机一部\n2. tsung 环境\n\n思路：使用tsung的recorder功能 先记录下app的请求内容(这个可以通过 让手机代理到tsung机器的指定端口），然后让tsung使用recorder记录下来的xml文件无脑进行回放，以达到测试服务性压力。\n\n\n\n\n1.tsung启动监听代理\n======\n执行`tsung-recorder -p http -L 8080 start`,这样就会直接进行代理，并记录通过8080端口的协议内容，然后就可以在app上面点击功能让app向服务器请求内容。\n\n\n2.编辑tsung.xml配置\n======\n第一步生成的recorder 的xml文件默认在`~/.tsung/tsung_recorder_date.xml`,内容格式大概如下：\n\n     \n```xml\n<session name='rec20151106-1447' probability='100'  type='ts_http' bidi=\"true\">\n<request><http url='http://172.16.2.106:80/api/v1/bookclubserver/mp/get' version='1.1'  contents='{\"user_id\":\"144447713885360800\",\"page_size\":\"10\",\"filter_goods_id_set\":[],\"filter_user_type_set\":[],\"p_version\":\"1\",\"page_index\":\"0\"}' content_type='application/json' method='POST'><add_cookie key=\"ifm_sid\" value=\"0521be8ac72fcf353dc38db77049ce2f\"/></http></request>\n\n<thinktime random='true' value='1'/>\n\n<request><http url='http://172.16.2.103/data/app_user/upload/144447713885360800/logo_144447713885360800_logo.png' version='1.1' method='GET'><add_cookie key=\"ifm_sid\" value=\"0521be8ac72fcf353dc38db77049ce2f\"/></http></request>\n<request><http url='/data/app_user/upload/144447713885360800/logo_144447713885360800_logo.png' version='1.1' method='GET'><add_cookie key=\"ifm_sid\" value=\"0521be8ac72fcf353dc38db77049ce2f\"/></http></request>\n\n<thinktime random='true' value='3'/>\n\n<request><http url='http://172.16.2.106:80/api/personalserver/personalinfo/get' version='1.1'  contents='{\"user_id\":\"144447713885360800\",\"p_version\":\"1\"}' content_type='application/json' method='POST'><add_cookie key=\"ifm_sid\" value=\"0521be8ac72fcf353dc38db77049ce2f\"/></http></request>\n<request><http url='http://172.16.2.103/data/app_user/upload/144447713885360800/logo_144447713885360800_logo.png' version='1.1' method='GET'><add_cookie key=\"ifm_sid\" value=\"0521be8ac72fcf353dc38db77049ce2f\"/></http></request>\n<request><http url='http://172.16.2.106:80/api/bookclubserver/bookreader/fprint/get' version='1.1'  contents='{\"user_id\":\"144447713885360800\",\"p_version\":\"1\",\"page_size\":\"120\",\"page_index\":\"0\"}' content_type='application/json' method='POST'><add_cookie key=\"ifm_sid\" value=\"0521be8ac72fcf353dc38db77049ce2f\"/></http></request>\n\n<thinktime random='true' value='2'/>\n....\n</session>\n```\n   编辑好的tsung.xml如下，可以按照[tsung文档](http://tsung.erlang-projects.org/user_manual/configuration.html)的来配置，其实觉得挺复杂的。。：\n```xml\n <?xml version=\"1.0\"?>\n<!DOCTYPE tsung SYSTEM \"/usr/local/share/tsung/tsung-1.0.dtd\"[ <!ENTITY mysession1 SYSTEM \"/root/.tsung/tsung_recorder20151106-1447.xml\">\n]>\n<tsung loglevel=\"notice\" version=\"1.0\">\n  <!-- Client side setup -->\n  <clients>\n    <client host=\"localhost\" use_controller_vm=\"true\" maxusers=\"30000\"/>\n  </clients>\n \n  <!-- Server side setup -->\n<servers>\n <server host=\"localhost\" port=\"8080\"  type=\"tcp\"></server>\n</servers>\n  <!-- to start os monitoring (cpu, network, memory). Use an erlang\n  agent on the remote machine or SNMP. erlang is the default -->\n  <monitoring>\n    <monitor host=\"myserver\" type=\"snmp\"></monitor>\n  </monitoring>\n \n  <load>\n  <!-- several arrival phases can be set: for each phase, you can set\n  the mean inter-arrival time between new clients and the phase\n  duration -->\n   <arrivalphase phase=\"1\" duration=\"10\" unit=\"minute\">\n     <users interarrival=\"2\" unit=\"second\"></users>\n   </arrivalphase>\n  </load>\n  <options>\n   <option type=\"ts_http\" name=\"user_agent\">\n    <user_agent probability=\"80\">Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.7.8) Gecko/20050513 Galeon/1.3.21</user_agent>\n    <user_agent probability=\"20\">Mozilla/5.0 (Windows; U; Windows NT 5.2; fr-FR; rv:1.7.8) Gecko/20050511 Firefox/1.0.4</user_agent>\n   </option>\n  </options>\n  <!-- start a session for a http user. the probability is the\n  frequency of this type os session. The sum of all session's\n  probabilities must be 100 -->\n <sessions>\n &mysession1;\n </sessions>\n</tsung>\n\n```\n\n\n3.进行压测\n======\n执行`tsung start`就可以开始进行压测了\n\n4.生成report\n======\n最后cd到`~/.tsung/log/data/`里面执行执行 `tsung_stats.pl`   生成` report.html`\n","source":"_posts/tsung压测restful服务器.md","raw":"title: tsung压测restful服务器\ndate: 2015-11-06 16:18:20\ntags: [Erlang,Tsung,压测]\n---\n\n1. android 手机一部\n2. tsung 环境\n\n思路：使用tsung的recorder功能 先记录下app的请求内容(这个可以通过 让手机代理到tsung机器的指定端口），然后让tsung使用recorder记录下来的xml文件无脑进行回放，以达到测试服务性压力。\n\n\n\n\n1.tsung启动监听代理\n======\n执行`tsung-recorder -p http -L 8080 start`,这样就会直接进行代理，并记录通过8080端口的协议内容，然后就可以在app上面点击功能让app向服务器请求内容。\n\n\n2.编辑tsung.xml配置\n======\n第一步生成的recorder 的xml文件默认在`~/.tsung/tsung_recorder_date.xml`,内容格式大概如下：\n\n     \n```xml\n<session name='rec20151106-1447' probability='100'  type='ts_http' bidi=\"true\">\n<request><http url='http://172.16.2.106:80/api/v1/bookclubserver/mp/get' version='1.1'  contents='{\"user_id\":\"144447713885360800\",\"page_size\":\"10\",\"filter_goods_id_set\":[],\"filter_user_type_set\":[],\"p_version\":\"1\",\"page_index\":\"0\"}' content_type='application/json' method='POST'><add_cookie key=\"ifm_sid\" value=\"0521be8ac72fcf353dc38db77049ce2f\"/></http></request>\n\n<thinktime random='true' value='1'/>\n\n<request><http url='http://172.16.2.103/data/app_user/upload/144447713885360800/logo_144447713885360800_logo.png' version='1.1' method='GET'><add_cookie key=\"ifm_sid\" value=\"0521be8ac72fcf353dc38db77049ce2f\"/></http></request>\n<request><http url='/data/app_user/upload/144447713885360800/logo_144447713885360800_logo.png' version='1.1' method='GET'><add_cookie key=\"ifm_sid\" value=\"0521be8ac72fcf353dc38db77049ce2f\"/></http></request>\n\n<thinktime random='true' value='3'/>\n\n<request><http url='http://172.16.2.106:80/api/personalserver/personalinfo/get' version='1.1'  contents='{\"user_id\":\"144447713885360800\",\"p_version\":\"1\"}' content_type='application/json' method='POST'><add_cookie key=\"ifm_sid\" value=\"0521be8ac72fcf353dc38db77049ce2f\"/></http></request>\n<request><http url='http://172.16.2.103/data/app_user/upload/144447713885360800/logo_144447713885360800_logo.png' version='1.1' method='GET'><add_cookie key=\"ifm_sid\" value=\"0521be8ac72fcf353dc38db77049ce2f\"/></http></request>\n<request><http url='http://172.16.2.106:80/api/bookclubserver/bookreader/fprint/get' version='1.1'  contents='{\"user_id\":\"144447713885360800\",\"p_version\":\"1\",\"page_size\":\"120\",\"page_index\":\"0\"}' content_type='application/json' method='POST'><add_cookie key=\"ifm_sid\" value=\"0521be8ac72fcf353dc38db77049ce2f\"/></http></request>\n\n<thinktime random='true' value='2'/>\n....\n</session>\n```\n   编辑好的tsung.xml如下，可以按照[tsung文档](http://tsung.erlang-projects.org/user_manual/configuration.html)的来配置，其实觉得挺复杂的。。：\n```xml\n <?xml version=\"1.0\"?>\n<!DOCTYPE tsung SYSTEM \"/usr/local/share/tsung/tsung-1.0.dtd\"[ <!ENTITY mysession1 SYSTEM \"/root/.tsung/tsung_recorder20151106-1447.xml\">\n]>\n<tsung loglevel=\"notice\" version=\"1.0\">\n  <!-- Client side setup -->\n  <clients>\n    <client host=\"localhost\" use_controller_vm=\"true\" maxusers=\"30000\"/>\n  </clients>\n \n  <!-- Server side setup -->\n<servers>\n <server host=\"localhost\" port=\"8080\"  type=\"tcp\"></server>\n</servers>\n  <!-- to start os monitoring (cpu, network, memory). Use an erlang\n  agent on the remote machine or SNMP. erlang is the default -->\n  <monitoring>\n    <monitor host=\"myserver\" type=\"snmp\"></monitor>\n  </monitoring>\n \n  <load>\n  <!-- several arrival phases can be set: for each phase, you can set\n  the mean inter-arrival time between new clients and the phase\n  duration -->\n   <arrivalphase phase=\"1\" duration=\"10\" unit=\"minute\">\n     <users interarrival=\"2\" unit=\"second\"></users>\n   </arrivalphase>\n  </load>\n  <options>\n   <option type=\"ts_http\" name=\"user_agent\">\n    <user_agent probability=\"80\">Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.7.8) Gecko/20050513 Galeon/1.3.21</user_agent>\n    <user_agent probability=\"20\">Mozilla/5.0 (Windows; U; Windows NT 5.2; fr-FR; rv:1.7.8) Gecko/20050511 Firefox/1.0.4</user_agent>\n   </option>\n  </options>\n  <!-- start a session for a http user. the probability is the\n  frequency of this type os session. The sum of all session's\n  probabilities must be 100 -->\n <sessions>\n &mysession1;\n </sessions>\n</tsung>\n\n```\n\n\n3.进行压测\n======\n执行`tsung start`就可以开始进行压测了\n\n4.生成report\n======\n最后cd到`~/.tsung/log/data/`里面执行执行 `tsung_stats.pl`   生成` report.html`\n","slug":"tsung压测restful服务器","published":1,"updated":"2019-08-21T01:49:04.131Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzkm7pqo000vjl9uvghcqa1r","content":"<ol>\n<li>android 手机一部</li>\n<li>tsung 环境</li>\n</ol>\n<p>思路：使用tsung的recorder功能 先记录下app的请求内容(这个可以通过 让手机代理到tsung机器的指定端口），然后让tsung使用recorder记录下来的xml文件无脑进行回放，以达到测试服务性压力。</p>\n<h1 id=\"1-tsung启动监听代理\"><a href=\"#1-tsung启动监听代理\" class=\"headerlink\" title=\"1.tsung启动监听代理\"></a>1.tsung启动监听代理</h1><p>执行<code>tsung-recorder -p http -L 8080 start</code>,这样就会直接进行代理，并记录通过8080端口的协议内容，然后就可以在app上面点击功能让app向服务器请求内容。</p>\n<h1 id=\"2-编辑tsung-xml配置\"><a href=\"#2-编辑tsung-xml配置\" class=\"headerlink\" title=\"2.编辑tsung.xml配置\"></a>2.编辑tsung.xml配置</h1><p>第一步生成的recorder 的xml文件默认在<code>~/.tsung/tsung_recorder_date.xml</code>,内容格式大概如下：</p>\n<pre><code class=\"xml\">&lt;session name=&#39;rec20151106-1447&#39; probability=&#39;100&#39;  type=&#39;ts_http&#39; bidi=&quot;true&quot;&gt;\n&lt;request&gt;&lt;http url=&#39;http://172.16.2.106:80/api/v1/bookclubserver/mp/get&#39; version=&#39;1.1&#39;  contents=&#39;{&quot;user_id&quot;:&quot;144447713885360800&quot;,&quot;page_size&quot;:&quot;10&quot;,&quot;filter_goods_id_set&quot;:[],&quot;filter_user_type_set&quot;:[],&quot;p_version&quot;:&quot;1&quot;,&quot;page_index&quot;:&quot;0&quot;}&#39; content_type=&#39;application/json&#39; method=&#39;POST&#39;&gt;&lt;add_cookie key=&quot;ifm_sid&quot; value=&quot;0521be8ac72fcf353dc38db77049ce2f&quot;/&gt;&lt;/http&gt;&lt;/request&gt;\n\n&lt;thinktime random=&#39;true&#39; value=&#39;1&#39;/&gt;\n\n&lt;request&gt;&lt;http url=&#39;http://172.16.2.103/data/app_user/upload/144447713885360800/logo_144447713885360800_logo.png&#39; version=&#39;1.1&#39; method=&#39;GET&#39;&gt;&lt;add_cookie key=&quot;ifm_sid&quot; value=&quot;0521be8ac72fcf353dc38db77049ce2f&quot;/&gt;&lt;/http&gt;&lt;/request&gt;\n&lt;request&gt;&lt;http url=&#39;/data/app_user/upload/144447713885360800/logo_144447713885360800_logo.png&#39; version=&#39;1.1&#39; method=&#39;GET&#39;&gt;&lt;add_cookie key=&quot;ifm_sid&quot; value=&quot;0521be8ac72fcf353dc38db77049ce2f&quot;/&gt;&lt;/http&gt;&lt;/request&gt;\n\n&lt;thinktime random=&#39;true&#39; value=&#39;3&#39;/&gt;\n\n&lt;request&gt;&lt;http url=&#39;http://172.16.2.106:80/api/personalserver/personalinfo/get&#39; version=&#39;1.1&#39;  contents=&#39;{&quot;user_id&quot;:&quot;144447713885360800&quot;,&quot;p_version&quot;:&quot;1&quot;}&#39; content_type=&#39;application/json&#39; method=&#39;POST&#39;&gt;&lt;add_cookie key=&quot;ifm_sid&quot; value=&quot;0521be8ac72fcf353dc38db77049ce2f&quot;/&gt;&lt;/http&gt;&lt;/request&gt;\n&lt;request&gt;&lt;http url=&#39;http://172.16.2.103/data/app_user/upload/144447713885360800/logo_144447713885360800_logo.png&#39; version=&#39;1.1&#39; method=&#39;GET&#39;&gt;&lt;add_cookie key=&quot;ifm_sid&quot; value=&quot;0521be8ac72fcf353dc38db77049ce2f&quot;/&gt;&lt;/http&gt;&lt;/request&gt;\n&lt;request&gt;&lt;http url=&#39;http://172.16.2.106:80/api/bookclubserver/bookreader/fprint/get&#39; version=&#39;1.1&#39;  contents=&#39;{&quot;user_id&quot;:&quot;144447713885360800&quot;,&quot;p_version&quot;:&quot;1&quot;,&quot;page_size&quot;:&quot;120&quot;,&quot;page_index&quot;:&quot;0&quot;}&#39; content_type=&#39;application/json&#39; method=&#39;POST&#39;&gt;&lt;add_cookie key=&quot;ifm_sid&quot; value=&quot;0521be8ac72fcf353dc38db77049ce2f&quot;/&gt;&lt;/http&gt;&lt;/request&gt;\n\n&lt;thinktime random=&#39;true&#39; value=&#39;2&#39;/&gt;\n....\n&lt;/session&gt;\n</code></pre>\n<p>   编辑好的tsung.xml如下，可以按照<a href=\"http://tsung.erlang-projects.org/user_manual/configuration.html\" target=\"_blank\" rel=\"noopener\">tsung文档</a>的来配置，其实觉得挺复杂的。。：</p>\n<pre><code class=\"xml\"> &lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;!DOCTYPE tsung SYSTEM &quot;/usr/local/share/tsung/tsung-1.0.dtd&quot;[ &lt;!ENTITY mysession1 SYSTEM &quot;/root/.tsung/tsung_recorder20151106-1447.xml&quot;&gt;\n]&gt;\n&lt;tsung loglevel=&quot;notice&quot; version=&quot;1.0&quot;&gt;\n  &lt;!-- Client side setup --&gt;\n  &lt;clients&gt;\n    &lt;client host=&quot;localhost&quot; use_controller_vm=&quot;true&quot; maxusers=&quot;30000&quot;/&gt;\n  &lt;/clients&gt;\n\n  &lt;!-- Server side setup --&gt;\n&lt;servers&gt;\n &lt;server host=&quot;localhost&quot; port=&quot;8080&quot;  type=&quot;tcp&quot;&gt;&lt;/server&gt;\n&lt;/servers&gt;\n  &lt;!-- to start os monitoring (cpu, network, memory). Use an erlang\n  agent on the remote machine or SNMP. erlang is the default --&gt;\n  &lt;monitoring&gt;\n    &lt;monitor host=&quot;myserver&quot; type=&quot;snmp&quot;&gt;&lt;/monitor&gt;\n  &lt;/monitoring&gt;\n\n  &lt;load&gt;\n  &lt;!-- several arrival phases can be set: for each phase, you can set\n  the mean inter-arrival time between new clients and the phase\n  duration --&gt;\n   &lt;arrivalphase phase=&quot;1&quot; duration=&quot;10&quot; unit=&quot;minute&quot;&gt;\n     &lt;users interarrival=&quot;2&quot; unit=&quot;second&quot;&gt;&lt;/users&gt;\n   &lt;/arrivalphase&gt;\n  &lt;/load&gt;\n  &lt;options&gt;\n   &lt;option type=&quot;ts_http&quot; name=&quot;user_agent&quot;&gt;\n    &lt;user_agent probability=&quot;80&quot;&gt;Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.7.8) Gecko/20050513 Galeon/1.3.21&lt;/user_agent&gt;\n    &lt;user_agent probability=&quot;20&quot;&gt;Mozilla/5.0 (Windows; U; Windows NT 5.2; fr-FR; rv:1.7.8) Gecko/20050511 Firefox/1.0.4&lt;/user_agent&gt;\n   &lt;/option&gt;\n  &lt;/options&gt;\n  &lt;!-- start a session for a http user. the probability is the\n  frequency of this type os session. The sum of all session&#39;s\n  probabilities must be 100 --&gt;\n &lt;sessions&gt;\n &amp;mysession1;\n &lt;/sessions&gt;\n&lt;/tsung&gt;\n\n</code></pre>\n<h1 id=\"3-进行压测\"><a href=\"#3-进行压测\" class=\"headerlink\" title=\"3.进行压测\"></a>3.进行压测</h1><p>执行<code>tsung start</code>就可以开始进行压测了</p>\n<h1 id=\"4-生成report\"><a href=\"#4-生成report\" class=\"headerlink\" title=\"4.生成report\"></a>4.生成report</h1><p>最后cd到<code>~/.tsung/log/data/</code>里面执行执行 <code>tsung_stats.pl</code>   生成<code>report.html</code></p>\n","site":{"data":{}},"excerpt":"","more":"<ol>\n<li>android 手机一部</li>\n<li>tsung 环境</li>\n</ol>\n<p>思路：使用tsung的recorder功能 先记录下app的请求内容(这个可以通过 让手机代理到tsung机器的指定端口），然后让tsung使用recorder记录下来的xml文件无脑进行回放，以达到测试服务性压力。</p>\n<h1 id=\"1-tsung启动监听代理\"><a href=\"#1-tsung启动监听代理\" class=\"headerlink\" title=\"1.tsung启动监听代理\"></a>1.tsung启动监听代理</h1><p>执行<code>tsung-recorder -p http -L 8080 start</code>,这样就会直接进行代理，并记录通过8080端口的协议内容，然后就可以在app上面点击功能让app向服务器请求内容。</p>\n<h1 id=\"2-编辑tsung-xml配置\"><a href=\"#2-编辑tsung-xml配置\" class=\"headerlink\" title=\"2.编辑tsung.xml配置\"></a>2.编辑tsung.xml配置</h1><p>第一步生成的recorder 的xml文件默认在<code>~/.tsung/tsung_recorder_date.xml</code>,内容格式大概如下：</p>\n<pre><code class=\"xml\">&lt;session name=&#39;rec20151106-1447&#39; probability=&#39;100&#39;  type=&#39;ts_http&#39; bidi=&quot;true&quot;&gt;\n&lt;request&gt;&lt;http url=&#39;http://172.16.2.106:80/api/v1/bookclubserver/mp/get&#39; version=&#39;1.1&#39;  contents=&#39;{&quot;user_id&quot;:&quot;144447713885360800&quot;,&quot;page_size&quot;:&quot;10&quot;,&quot;filter_goods_id_set&quot;:[],&quot;filter_user_type_set&quot;:[],&quot;p_version&quot;:&quot;1&quot;,&quot;page_index&quot;:&quot;0&quot;}&#39; content_type=&#39;application/json&#39; method=&#39;POST&#39;&gt;&lt;add_cookie key=&quot;ifm_sid&quot; value=&quot;0521be8ac72fcf353dc38db77049ce2f&quot;/&gt;&lt;/http&gt;&lt;/request&gt;\n\n&lt;thinktime random=&#39;true&#39; value=&#39;1&#39;/&gt;\n\n&lt;request&gt;&lt;http url=&#39;http://172.16.2.103/data/app_user/upload/144447713885360800/logo_144447713885360800_logo.png&#39; version=&#39;1.1&#39; method=&#39;GET&#39;&gt;&lt;add_cookie key=&quot;ifm_sid&quot; value=&quot;0521be8ac72fcf353dc38db77049ce2f&quot;/&gt;&lt;/http&gt;&lt;/request&gt;\n&lt;request&gt;&lt;http url=&#39;/data/app_user/upload/144447713885360800/logo_144447713885360800_logo.png&#39; version=&#39;1.1&#39; method=&#39;GET&#39;&gt;&lt;add_cookie key=&quot;ifm_sid&quot; value=&quot;0521be8ac72fcf353dc38db77049ce2f&quot;/&gt;&lt;/http&gt;&lt;/request&gt;\n\n&lt;thinktime random=&#39;true&#39; value=&#39;3&#39;/&gt;\n\n&lt;request&gt;&lt;http url=&#39;http://172.16.2.106:80/api/personalserver/personalinfo/get&#39; version=&#39;1.1&#39;  contents=&#39;{&quot;user_id&quot;:&quot;144447713885360800&quot;,&quot;p_version&quot;:&quot;1&quot;}&#39; content_type=&#39;application/json&#39; method=&#39;POST&#39;&gt;&lt;add_cookie key=&quot;ifm_sid&quot; value=&quot;0521be8ac72fcf353dc38db77049ce2f&quot;/&gt;&lt;/http&gt;&lt;/request&gt;\n&lt;request&gt;&lt;http url=&#39;http://172.16.2.103/data/app_user/upload/144447713885360800/logo_144447713885360800_logo.png&#39; version=&#39;1.1&#39; method=&#39;GET&#39;&gt;&lt;add_cookie key=&quot;ifm_sid&quot; value=&quot;0521be8ac72fcf353dc38db77049ce2f&quot;/&gt;&lt;/http&gt;&lt;/request&gt;\n&lt;request&gt;&lt;http url=&#39;http://172.16.2.106:80/api/bookclubserver/bookreader/fprint/get&#39; version=&#39;1.1&#39;  contents=&#39;{&quot;user_id&quot;:&quot;144447713885360800&quot;,&quot;p_version&quot;:&quot;1&quot;,&quot;page_size&quot;:&quot;120&quot;,&quot;page_index&quot;:&quot;0&quot;}&#39; content_type=&#39;application/json&#39; method=&#39;POST&#39;&gt;&lt;add_cookie key=&quot;ifm_sid&quot; value=&quot;0521be8ac72fcf353dc38db77049ce2f&quot;/&gt;&lt;/http&gt;&lt;/request&gt;\n\n&lt;thinktime random=&#39;true&#39; value=&#39;2&#39;/&gt;\n....\n&lt;/session&gt;\n</code></pre>\n<p>   编辑好的tsung.xml如下，可以按照<a href=\"http://tsung.erlang-projects.org/user_manual/configuration.html\" target=\"_blank\" rel=\"noopener\">tsung文档</a>的来配置，其实觉得挺复杂的。。：</p>\n<pre><code class=\"xml\"> &lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;!DOCTYPE tsung SYSTEM &quot;/usr/local/share/tsung/tsung-1.0.dtd&quot;[ &lt;!ENTITY mysession1 SYSTEM &quot;/root/.tsung/tsung_recorder20151106-1447.xml&quot;&gt;\n]&gt;\n&lt;tsung loglevel=&quot;notice&quot; version=&quot;1.0&quot;&gt;\n  &lt;!-- Client side setup --&gt;\n  &lt;clients&gt;\n    &lt;client host=&quot;localhost&quot; use_controller_vm=&quot;true&quot; maxusers=&quot;30000&quot;/&gt;\n  &lt;/clients&gt;\n\n  &lt;!-- Server side setup --&gt;\n&lt;servers&gt;\n &lt;server host=&quot;localhost&quot; port=&quot;8080&quot;  type=&quot;tcp&quot;&gt;&lt;/server&gt;\n&lt;/servers&gt;\n  &lt;!-- to start os monitoring (cpu, network, memory). Use an erlang\n  agent on the remote machine or SNMP. erlang is the default --&gt;\n  &lt;monitoring&gt;\n    &lt;monitor host=&quot;myserver&quot; type=&quot;snmp&quot;&gt;&lt;/monitor&gt;\n  &lt;/monitoring&gt;\n\n  &lt;load&gt;\n  &lt;!-- several arrival phases can be set: for each phase, you can set\n  the mean inter-arrival time between new clients and the phase\n  duration --&gt;\n   &lt;arrivalphase phase=&quot;1&quot; duration=&quot;10&quot; unit=&quot;minute&quot;&gt;\n     &lt;users interarrival=&quot;2&quot; unit=&quot;second&quot;&gt;&lt;/users&gt;\n   &lt;/arrivalphase&gt;\n  &lt;/load&gt;\n  &lt;options&gt;\n   &lt;option type=&quot;ts_http&quot; name=&quot;user_agent&quot;&gt;\n    &lt;user_agent probability=&quot;80&quot;&gt;Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.7.8) Gecko/20050513 Galeon/1.3.21&lt;/user_agent&gt;\n    &lt;user_agent probability=&quot;20&quot;&gt;Mozilla/5.0 (Windows; U; Windows NT 5.2; fr-FR; rv:1.7.8) Gecko/20050511 Firefox/1.0.4&lt;/user_agent&gt;\n   &lt;/option&gt;\n  &lt;/options&gt;\n  &lt;!-- start a session for a http user. the probability is the\n  frequency of this type os session. The sum of all session&#39;s\n  probabilities must be 100 --&gt;\n &lt;sessions&gt;\n &amp;mysession1;\n &lt;/sessions&gt;\n&lt;/tsung&gt;\n\n</code></pre>\n<h1 id=\"3-进行压测\"><a href=\"#3-进行压测\" class=\"headerlink\" title=\"3.进行压测\"></a>3.进行压测</h1><p>执行<code>tsung start</code>就可以开始进行压测了</p>\n<h1 id=\"4-生成report\"><a href=\"#4-生成report\" class=\"headerlink\" title=\"4.生成report\"></a>4.生成report</h1><p>最后cd到<code>~/.tsung/log/data/</code>里面执行执行 <code>tsung_stats.pl</code>   生成<code>report.html</code></p>\n"},{"title":"webrtc一些笔记","date":"2016-09-13T02:02:05.000Z","_content":"#### webrtc一些笔记\n\n##### 基础框架\n ![](http://7xj8b1.com1.z0.glb.clouddn.com/turn.png)\n\n组成部分：\n1. Signalling,客户端session控制，网络和多媒体信息同步的机制。不是RTCPerrConnection API的一部分，用户可以根据需求自己定义和实现signalling，signalling主要用于三种类型的信息：\n   - session控制消息：初始化或关闭 会话，还可以上报错误\n   - 网络配置：通过signalling告诉 第三方(想和自己连接的Peer)自己的IP和Port\n   - 多媒体文件处理能力:决定双方的多媒体文件的编码、解码格式。\n\n2. ICE framework 用于连接Peer(端点)间的互相连接.\n3. STUN 和 STUN协议的扩展 [TURN](https://en.wikipedia.org/wiki/Traversal_Using_Relays_around_NAT)协议，这个主要是[ICE](https://en.wikipedia.org/wiki/Interactive_Connectivity_Establishment) framework 用来支持 NAT穿透，使得 RTCPeerConnection 能够应对变幻莫测的网络环境。\n\n\n\n`stun`的`long-term credential mechanism` 的key 可以通过`coturn`的 `turnadmin -a -u username -p password -k`获得,也就是说如果通过`udp`连接到`coturn server`则需要通过 `long-term credential mechanism` 来认证,下面的例子：\n \nserver:  \n```\nturnserver  --user=ninefingers:0xbc807ee29df3c9ffa736523fb2c4e8ee --user=gorst:hero -r north.gov --cert=turn_server_cert.pem  --pkey=turn_server_pkey.pem --log-file=stdout -v --mobility --cipher-list=ALL $@\n```\nclient 使用udp:\n```\nturnutils_uclient  -z 5 -n 10 -s -m 1 -l 170 -e 127.0.0.1 -X -g -u ninefingers -w youhavetoberealistic   $server_ip -v\n```\nclient 使用tcp:\n```\nturnutils_uclient  -z 5 -n 10 -s -m 1 -l 170 -e 127.0.0.1 -X -g -u gorst -W hero  $server_ip -v\n```\n注意在server命令中 `--user=ninefingers:0xbc807ee29df3c9ffa736523fb2c4e8ee`和`--user=gorst:hero`的不同。\n\n简单的来说，`stun` 用来告诉client自身穿透nat之后的公网ip和端口是多少，而`turn`则是扩展了中继转发功能,`turn`具体流程如下：\n```\n                                                            Peer A\n                                       Server-Reflexive    +---------+\n                                       Transport Address   |         |\n                                       192.0.2.150:32102   |         |\n                                           |              /|         |\n                         TURN              |            / ^|  Peer A |\n   Client’s              Server            |           /  ||         |\n   Host Transport        Transport         |         //   ||         |\n   Address               Address           |       //     |+---------+\n  10.1.1.2:49721       192.0.2.15:3478     |+-+  //     Peer A\n           |               |               ||N| /       Host Transport\n           |   +-+         |               ||A|/        Address\n           |   | |         |               v|T|     192.168.100.2:49582\n           |   | |         |               /+-+\n+---------+|   | |         |+---------+   /              +---------+\n|         ||   |N|         ||         | //               |         |\n| TURN    |v   | |         v| TURN    |/                 |         |\n| Client  |----|A|----------| Server  |------------------|  Peer B |\n|         |    | |^         |         |^                ^|         |\n|         |    |T||         |         ||                ||         |\n+---------+    | ||         +---------+|                |+---------+\n               | ||                    |                |\n               | ||                    |                |\n               +-+|                    |                |\n                  |                    |                |\n                  |                    |                |\n            Client’s                   |            Peer B\n            Server-Reflexive    Relayed             Transport\n            Transport Address   Transport Address   Address\n            192.0.2.1:7000      192.0.2.15:50000     192.0.2.210:49191\n```\n在上图中，左边的TURN Client是位于NAT后面的一个客户端（内网地址是10.1.1.2:49721），连接公网的TURN服务器（默认端口3478）后， 服务器会得到一个Client的反射地址（Reflexive Transport Address, 即NAT分配的公网IP和端口)192.0.2.1:7000， 此时Client会通过TURN命令创建或管理ALLOCATION，allocation是服务器上的一个数据结构，包含了中继地址的信息。 服务器随后会给Client分配一个中继地址，即图中的192.0.2.15:50000，另外两个对等端若要通过TURN协议和Client进行通信， 可以直接往中继地址收发数据即可，TURN服务器会把发往指定中继地址的数据转发到对应的Client，这里是其反射地址。\n\nServer上的每一个allocation都唯一对应一个client，并且只有一个中继地址，因此当数据包到达某个中继地址时，服务器总是知道应该将其转发到什么地方。 但值得一提的是，一个Client可能在同一时间在一个Server上会有多个allocation，这和上述规则是并不矛盾的。\n\n\n通信过程：\n![](http://7xj8b1.com1.z0.glb.clouddn.com/p2p_process.png)\n\n\n\n参考：  \n[P2P通信标准协议(二)之TURN](https://pannzh.github.io/tech/p2p/2015/12/16/p2p-standard-protocol-turn.html)  \n[the-basic-p2p-communication-process](https://github.com/YK-Unit/AppRTCDemo/blob/master/README.md#the-basic-p2p-communication-process)\n","source":"_posts/webrtc一些笔记.md","raw":"title: webrtc一些笔记\ndate: 2016-09-13 10:02:05\ntags: [webrtc,peer to peer]\n---\n#### webrtc一些笔记\n\n##### 基础框架\n ![](http://7xj8b1.com1.z0.glb.clouddn.com/turn.png)\n\n组成部分：\n1. Signalling,客户端session控制，网络和多媒体信息同步的机制。不是RTCPerrConnection API的一部分，用户可以根据需求自己定义和实现signalling，signalling主要用于三种类型的信息：\n   - session控制消息：初始化或关闭 会话，还可以上报错误\n   - 网络配置：通过signalling告诉 第三方(想和自己连接的Peer)自己的IP和Port\n   - 多媒体文件处理能力:决定双方的多媒体文件的编码、解码格式。\n\n2. ICE framework 用于连接Peer(端点)间的互相连接.\n3. STUN 和 STUN协议的扩展 [TURN](https://en.wikipedia.org/wiki/Traversal_Using_Relays_around_NAT)协议，这个主要是[ICE](https://en.wikipedia.org/wiki/Interactive_Connectivity_Establishment) framework 用来支持 NAT穿透，使得 RTCPeerConnection 能够应对变幻莫测的网络环境。\n\n\n\n`stun`的`long-term credential mechanism` 的key 可以通过`coturn`的 `turnadmin -a -u username -p password -k`获得,也就是说如果通过`udp`连接到`coturn server`则需要通过 `long-term credential mechanism` 来认证,下面的例子：\n \nserver:  \n```\nturnserver  --user=ninefingers:0xbc807ee29df3c9ffa736523fb2c4e8ee --user=gorst:hero -r north.gov --cert=turn_server_cert.pem  --pkey=turn_server_pkey.pem --log-file=stdout -v --mobility --cipher-list=ALL $@\n```\nclient 使用udp:\n```\nturnutils_uclient  -z 5 -n 10 -s -m 1 -l 170 -e 127.0.0.1 -X -g -u ninefingers -w youhavetoberealistic   $server_ip -v\n```\nclient 使用tcp:\n```\nturnutils_uclient  -z 5 -n 10 -s -m 1 -l 170 -e 127.0.0.1 -X -g -u gorst -W hero  $server_ip -v\n```\n注意在server命令中 `--user=ninefingers:0xbc807ee29df3c9ffa736523fb2c4e8ee`和`--user=gorst:hero`的不同。\n\n简单的来说，`stun` 用来告诉client自身穿透nat之后的公网ip和端口是多少，而`turn`则是扩展了中继转发功能,`turn`具体流程如下：\n```\n                                                            Peer A\n                                       Server-Reflexive    +---------+\n                                       Transport Address   |         |\n                                       192.0.2.150:32102   |         |\n                                           |              /|         |\n                         TURN              |            / ^|  Peer A |\n   Client’s              Server            |           /  ||         |\n   Host Transport        Transport         |         //   ||         |\n   Address               Address           |       //     |+---------+\n  10.1.1.2:49721       192.0.2.15:3478     |+-+  //     Peer A\n           |               |               ||N| /       Host Transport\n           |   +-+         |               ||A|/        Address\n           |   | |         |               v|T|     192.168.100.2:49582\n           |   | |         |               /+-+\n+---------+|   | |         |+---------+   /              +---------+\n|         ||   |N|         ||         | //               |         |\n| TURN    |v   | |         v| TURN    |/                 |         |\n| Client  |----|A|----------| Server  |------------------|  Peer B |\n|         |    | |^         |         |^                ^|         |\n|         |    |T||         |         ||                ||         |\n+---------+    | ||         +---------+|                |+---------+\n               | ||                    |                |\n               | ||                    |                |\n               +-+|                    |                |\n                  |                    |                |\n                  |                    |                |\n            Client’s                   |            Peer B\n            Server-Reflexive    Relayed             Transport\n            Transport Address   Transport Address   Address\n            192.0.2.1:7000      192.0.2.15:50000     192.0.2.210:49191\n```\n在上图中，左边的TURN Client是位于NAT后面的一个客户端（内网地址是10.1.1.2:49721），连接公网的TURN服务器（默认端口3478）后， 服务器会得到一个Client的反射地址（Reflexive Transport Address, 即NAT分配的公网IP和端口)192.0.2.1:7000， 此时Client会通过TURN命令创建或管理ALLOCATION，allocation是服务器上的一个数据结构，包含了中继地址的信息。 服务器随后会给Client分配一个中继地址，即图中的192.0.2.15:50000，另外两个对等端若要通过TURN协议和Client进行通信， 可以直接往中继地址收发数据即可，TURN服务器会把发往指定中继地址的数据转发到对应的Client，这里是其反射地址。\n\nServer上的每一个allocation都唯一对应一个client，并且只有一个中继地址，因此当数据包到达某个中继地址时，服务器总是知道应该将其转发到什么地方。 但值得一提的是，一个Client可能在同一时间在一个Server上会有多个allocation，这和上述规则是并不矛盾的。\n\n\n通信过程：\n![](http://7xj8b1.com1.z0.glb.clouddn.com/p2p_process.png)\n\n\n\n参考：  \n[P2P通信标准协议(二)之TURN](https://pannzh.github.io/tech/p2p/2015/12/16/p2p-standard-protocol-turn.html)  \n[the-basic-p2p-communication-process](https://github.com/YK-Unit/AppRTCDemo/blob/master/README.md#the-basic-p2p-communication-process)\n","slug":"webrtc一些笔记","published":1,"updated":"2019-08-21T01:49:04.131Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzkm7pqp000wjl9u0pgoizur","content":"<h4 id=\"webrtc一些笔记\"><a href=\"#webrtc一些笔记\" class=\"headerlink\" title=\"webrtc一些笔记\"></a>webrtc一些笔记</h4><h5 id=\"基础框架\"><a href=\"#基础框架\" class=\"headerlink\" title=\"基础框架\"></a>基础框架</h5><p> <img src=\"http://7xj8b1.com1.z0.glb.clouddn.com/turn.png\" alt=\"\"></p>\n<p>组成部分：</p>\n<ol>\n<li><p>Signalling,客户端session控制，网络和多媒体信息同步的机制。不是RTCPerrConnection API的一部分，用户可以根据需求自己定义和实现signalling，signalling主要用于三种类型的信息：</p>\n<ul>\n<li>session控制消息：初始化或关闭 会话，还可以上报错误</li>\n<li>网络配置：通过signalling告诉 第三方(想和自己连接的Peer)自己的IP和Port</li>\n<li>多媒体文件处理能力:决定双方的多媒体文件的编码、解码格式。</li>\n</ul>\n</li>\n<li><p>ICE framework 用于连接Peer(端点)间的互相连接.</p>\n</li>\n<li>STUN 和 STUN协议的扩展 <a href=\"https://en.wikipedia.org/wiki/Traversal_Using_Relays_around_NAT\" target=\"_blank\" rel=\"noopener\">TURN</a>协议，这个主要是<a href=\"https://en.wikipedia.org/wiki/Interactive_Connectivity_Establishment\" target=\"_blank\" rel=\"noopener\">ICE</a> framework 用来支持 NAT穿透，使得 RTCPeerConnection 能够应对变幻莫测的网络环境。</li>\n</ol>\n<p><code>stun</code>的<code>long-term credential mechanism</code> 的key 可以通过<code>coturn</code>的 <code>turnadmin -a -u username -p password -k</code>获得,也就是说如果通过<code>udp</code>连接到<code>coturn server</code>则需要通过 <code>long-term credential mechanism</code> 来认证,下面的例子：</p>\n<p>server:  </p>\n<pre><code>turnserver  --user=ninefingers:0xbc807ee29df3c9ffa736523fb2c4e8ee --user=gorst:hero -r north.gov --cert=turn_server_cert.pem  --pkey=turn_server_pkey.pem --log-file=stdout -v --mobility --cipher-list=ALL $@\n</code></pre><p>client 使用udp:</p>\n<pre><code>turnutils_uclient  -z 5 -n 10 -s -m 1 -l 170 -e 127.0.0.1 -X -g -u ninefingers -w youhavetoberealistic   $server_ip -v\n</code></pre><p>client 使用tcp:</p>\n<pre><code>turnutils_uclient  -z 5 -n 10 -s -m 1 -l 170 -e 127.0.0.1 -X -g -u gorst -W hero  $server_ip -v\n</code></pre><p>注意在server命令中 <code>--user=ninefingers:0xbc807ee29df3c9ffa736523fb2c4e8ee</code>和<code>--user=gorst:hero</code>的不同。</p>\n<p>简单的来说，<code>stun</code> 用来告诉client自身穿透nat之后的公网ip和端口是多少，而<code>turn</code>则是扩展了中继转发功能,<code>turn</code>具体流程如下：</p>\n<pre><code>                                                            Peer A\n                                       Server-Reflexive    +---------+\n                                       Transport Address   |         |\n                                       192.0.2.150:32102   |         |\n                                           |              /|         |\n                         TURN              |            / ^|  Peer A |\n   Client’s              Server            |           /  ||         |\n   Host Transport        Transport         |         //   ||         |\n   Address               Address           |       //     |+---------+\n  10.1.1.2:49721       192.0.2.15:3478     |+-+  //     Peer A\n           |               |               ||N| /       Host Transport\n           |   +-+         |               ||A|/        Address\n           |   | |         |               v|T|     192.168.100.2:49582\n           |   | |         |               /+-+\n+---------+|   | |         |+---------+   /              +---------+\n|         ||   |N|         ||         | //               |         |\n| TURN    |v   | |         v| TURN    |/                 |         |\n| Client  |----|A|----------| Server  |------------------|  Peer B |\n|         |    | |^         |         |^                ^|         |\n|         |    |T||         |         ||                ||         |\n+---------+    | ||         +---------+|                |+---------+\n               | ||                    |                |\n               | ||                    |                |\n               +-+|                    |                |\n                  |                    |                |\n                  |                    |                |\n            Client’s                   |            Peer B\n            Server-Reflexive    Relayed             Transport\n            Transport Address   Transport Address   Address\n            192.0.2.1:7000      192.0.2.15:50000     192.0.2.210:49191\n</code></pre><p>在上图中，左边的TURN Client是位于NAT后面的一个客户端（内网地址是10.1.1.2:49721），连接公网的TURN服务器（默认端口3478）后， 服务器会得到一个Client的反射地址（Reflexive Transport Address, 即NAT分配的公网IP和端口)192.0.2.1:7000， 此时Client会通过TURN命令创建或管理ALLOCATION，allocation是服务器上的一个数据结构，包含了中继地址的信息。 服务器随后会给Client分配一个中继地址，即图中的192.0.2.15:50000，另外两个对等端若要通过TURN协议和Client进行通信， 可以直接往中继地址收发数据即可，TURN服务器会把发往指定中继地址的数据转发到对应的Client，这里是其反射地址。</p>\n<p>Server上的每一个allocation都唯一对应一个client，并且只有一个中继地址，因此当数据包到达某个中继地址时，服务器总是知道应该将其转发到什么地方。 但值得一提的是，一个Client可能在同一时间在一个Server上会有多个allocation，这和上述规则是并不矛盾的。</p>\n<p>通信过程：<br><img src=\"http://7xj8b1.com1.z0.glb.clouddn.com/p2p_process.png\" alt=\"\"></p>\n<p>参考：<br><a href=\"https://pannzh.github.io/tech/p2p/2015/12/16/p2p-standard-protocol-turn.html\" target=\"_blank\" rel=\"noopener\">P2P通信标准协议(二)之TURN</a><br><a href=\"https://github.com/YK-Unit/AppRTCDemo/blob/master/README.md#the-basic-p2p-communication-process\" target=\"_blank\" rel=\"noopener\">the-basic-p2p-communication-process</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h4 id=\"webrtc一些笔记\"><a href=\"#webrtc一些笔记\" class=\"headerlink\" title=\"webrtc一些笔记\"></a>webrtc一些笔记</h4><h5 id=\"基础框架\"><a href=\"#基础框架\" class=\"headerlink\" title=\"基础框架\"></a>基础框架</h5><p> <img src=\"http://7xj8b1.com1.z0.glb.clouddn.com/turn.png\" alt=\"\"></p>\n<p>组成部分：</p>\n<ol>\n<li><p>Signalling,客户端session控制，网络和多媒体信息同步的机制。不是RTCPerrConnection API的一部分，用户可以根据需求自己定义和实现signalling，signalling主要用于三种类型的信息：</p>\n<ul>\n<li>session控制消息：初始化或关闭 会话，还可以上报错误</li>\n<li>网络配置：通过signalling告诉 第三方(想和自己连接的Peer)自己的IP和Port</li>\n<li>多媒体文件处理能力:决定双方的多媒体文件的编码、解码格式。</li>\n</ul>\n</li>\n<li><p>ICE framework 用于连接Peer(端点)间的互相连接.</p>\n</li>\n<li>STUN 和 STUN协议的扩展 <a href=\"https://en.wikipedia.org/wiki/Traversal_Using_Relays_around_NAT\" target=\"_blank\" rel=\"noopener\">TURN</a>协议，这个主要是<a href=\"https://en.wikipedia.org/wiki/Interactive_Connectivity_Establishment\" target=\"_blank\" rel=\"noopener\">ICE</a> framework 用来支持 NAT穿透，使得 RTCPeerConnection 能够应对变幻莫测的网络环境。</li>\n</ol>\n<p><code>stun</code>的<code>long-term credential mechanism</code> 的key 可以通过<code>coturn</code>的 <code>turnadmin -a -u username -p password -k</code>获得,也就是说如果通过<code>udp</code>连接到<code>coturn server</code>则需要通过 <code>long-term credential mechanism</code> 来认证,下面的例子：</p>\n<p>server:  </p>\n<pre><code>turnserver  --user=ninefingers:0xbc807ee29df3c9ffa736523fb2c4e8ee --user=gorst:hero -r north.gov --cert=turn_server_cert.pem  --pkey=turn_server_pkey.pem --log-file=stdout -v --mobility --cipher-list=ALL $@\n</code></pre><p>client 使用udp:</p>\n<pre><code>turnutils_uclient  -z 5 -n 10 -s -m 1 -l 170 -e 127.0.0.1 -X -g -u ninefingers -w youhavetoberealistic   $server_ip -v\n</code></pre><p>client 使用tcp:</p>\n<pre><code>turnutils_uclient  -z 5 -n 10 -s -m 1 -l 170 -e 127.0.0.1 -X -g -u gorst -W hero  $server_ip -v\n</code></pre><p>注意在server命令中 <code>--user=ninefingers:0xbc807ee29df3c9ffa736523fb2c4e8ee</code>和<code>--user=gorst:hero</code>的不同。</p>\n<p>简单的来说，<code>stun</code> 用来告诉client自身穿透nat之后的公网ip和端口是多少，而<code>turn</code>则是扩展了中继转发功能,<code>turn</code>具体流程如下：</p>\n<pre><code>                                                            Peer A\n                                       Server-Reflexive    +---------+\n                                       Transport Address   |         |\n                                       192.0.2.150:32102   |         |\n                                           |              /|         |\n                         TURN              |            / ^|  Peer A |\n   Client’s              Server            |           /  ||         |\n   Host Transport        Transport         |         //   ||         |\n   Address               Address           |       //     |+---------+\n  10.1.1.2:49721       192.0.2.15:3478     |+-+  //     Peer A\n           |               |               ||N| /       Host Transport\n           |   +-+         |               ||A|/        Address\n           |   | |         |               v|T|     192.168.100.2:49582\n           |   | |         |               /+-+\n+---------+|   | |         |+---------+   /              +---------+\n|         ||   |N|         ||         | //               |         |\n| TURN    |v   | |         v| TURN    |/                 |         |\n| Client  |----|A|----------| Server  |------------------|  Peer B |\n|         |    | |^         |         |^                ^|         |\n|         |    |T||         |         ||                ||         |\n+---------+    | ||         +---------+|                |+---------+\n               | ||                    |                |\n               | ||                    |                |\n               +-+|                    |                |\n                  |                    |                |\n                  |                    |                |\n            Client’s                   |            Peer B\n            Server-Reflexive    Relayed             Transport\n            Transport Address   Transport Address   Address\n            192.0.2.1:7000      192.0.2.15:50000     192.0.2.210:49191\n</code></pre><p>在上图中，左边的TURN Client是位于NAT后面的一个客户端（内网地址是10.1.1.2:49721），连接公网的TURN服务器（默认端口3478）后， 服务器会得到一个Client的反射地址（Reflexive Transport Address, 即NAT分配的公网IP和端口)192.0.2.1:7000， 此时Client会通过TURN命令创建或管理ALLOCATION，allocation是服务器上的一个数据结构，包含了中继地址的信息。 服务器随后会给Client分配一个中继地址，即图中的192.0.2.15:50000，另外两个对等端若要通过TURN协议和Client进行通信， 可以直接往中继地址收发数据即可，TURN服务器会把发往指定中继地址的数据转发到对应的Client，这里是其反射地址。</p>\n<p>Server上的每一个allocation都唯一对应一个client，并且只有一个中继地址，因此当数据包到达某个中继地址时，服务器总是知道应该将其转发到什么地方。 但值得一提的是，一个Client可能在同一时间在一个Server上会有多个allocation，这和上述规则是并不矛盾的。</p>\n<p>通信过程：<br><img src=\"http://7xj8b1.com1.z0.glb.clouddn.com/p2p_process.png\" alt=\"\"></p>\n<p>参考：<br><a href=\"https://pannzh.github.io/tech/p2p/2015/12/16/p2p-standard-protocol-turn.html\" target=\"_blank\" rel=\"noopener\">P2P通信标准协议(二)之TURN</a><br><a href=\"https://github.com/YK-Unit/AppRTCDemo/blob/master/README.md#the-basic-p2p-communication-process\" target=\"_blank\" rel=\"noopener\">the-basic-p2p-communication-process</a></p>\n"},{"title":"阿里短信发送api","date":"2016-03-08T09:27:03.000Z","_content":"阿里大鱼 短信发送接口 alibaba.aliqin.fc.sms.num.send 防坑指南\n===\n\n0x00 吐槽\n====\n[文档](http://open.taobao.com/doc2/apiDetail.htm?spm=a219a.7629065.0.0.teG5ys&apiId=25450)写的已经无力吐槽了，请问您哪里有指出 参数需要 secret了呢？？？\n\n0x01 注意项\n====\n1.md5 sign的生成是字符串 ： \n```\n${SECRET}app_key${APP_KEY}formatjsonmethodalibaba.aliqin.fc.sms.num.sendrec_num${PHONE_NUMBER}secretcb13046b7f305eb305e6e45d6b93405fsign_methodmd5sms_free_sign_name${SIGN_NAME}sms_param${PARAMS}sms_template_code${TEMPLATE_CODE}sms_typenormaltimestamp2016-03-08 16:01:53v2.0cb13046${SECRET}\n```\n 通过MD5加密生成。其中 `${}`是对应的参数变量，一定不要忘了`secret`字段，这是文档里面没有的。。。。\n\n>如果使用hmac方式加密`（sign_method: ‘hmac’）`，则不需要首尾加上secret，md5则需要\n\n2.参数的value 要进行 url编码\n\n0x02 Erlang 代码接口\n====\n[github地址](https://github.com/chenshaobo/ali_sms)\n\n```erlang\n\n\t%%%-------------------------------------------------------------------\n\t%%% @author chenshaobo0428\n\t%%% @copyright (C) 2016, <COMPANY>\n\t%%% @doc\n\t%%%\n\t%%% @end\n\t%%% Created : 08. 03 2016 16:47\n\t%%%-------------------------------------------------------------------\n\t-module(ali_sms).\n\t-author(\"chenshaobo0428\").\n\n\t%% API\n\t-export([gen_ali_sms_url/4]).\n\t-define(DEFAULT_PARAMS,[\n\t    {\"method\",<<\"alibaba.aliqin.fc.sms.num.send\">>},\n\t    {\"app_key\",<<\"YOUR KEY\">>},\n\t    {\"secret\",\"YOUR SECRET\"},\n\t    {\"v\",<<\"2.0\">>},\n\t    {\"sign_method\",<<\"md5\">>},\n\t    {\"format\",<<\"json\">>},\n\t    {\"sms_type\",<<\"normal\">>}\n\t]).\n\n\t-define(BASE_URL,\"http://gw.api.taobao.com/router/rest?\").\n\t%% 传入参数 返回 通过阿里大鱼（get方式)发送短信的完整url\n\n\tgen_ali_sms_url(PhoneNumber,SMSParam,SignName,TemplateCode)->\n\n\t    {\"secret\", SecretKey} = lists:keyfind(\"secret\", 1, ?DEFAULT_PARAMS),\n\n\t    Params=\n\t    [{\"rec_num\", to_bin(PhoneNumber)}, {\"sms_param\", to_bin(SMSParam)},\n\t\t{\"sms_free_sign_name\", to_bin(SignName)}, {\"sms_template_code\", TemplateCode},\n\t\t{\"timestamp\", to_bin(format_date())}] ++ ?DEFAULT_PARAMS,\n\t%%     按照字母排序\n\t    SortList = lists:sort(fun({Key1, _}, {Key2, _}) ->\n\t\tKey1 < Key2\n\t    end, Params),\n\t    MD5Source = SecretKey ++ lists:flatten([io_lib:format(\"~s~s\", [Key, Val]) || {Key, Val} <- SortList]) ++ SecretKey,\n\t    SignMd5 = to_bin(string:to_upper(to_list(to_md5(MD5Source)))),\n\t%%\n\t    RequestQuery = lists:flatten([io_lib:format(\"~s=~s&\", [Key, http_uri:encode(to_list(Val))]) || {Key, Val} <- [{\"sign\", SignMd5} | SortList]]),\n\t    ?BASE_URL ++ RequestQuery.\n\n\n\t-define(FILL_ZERO(X) ,case X > 9 of\n\t\t\t\t true ->\n\t\t\t\t     to_list(X);\n\t\t\t\t false ->\n\t\t\t\t     \"0\"++ \tto_list(X)\n\t\t\t     end).\n\n\tformat_date()->\n\t    {Y,M,D} = erlang:date(),\n\t    {H,Min,S}= time(),\n\t    lists:flatten(io_lib:format(\"~s-~s-~s ~s:~s:~s\", [?FILL_ZERO(Y),?FILL_ZERO(M),?FILL_ZERO(D),?FILL_ZERO(H),?FILL_ZERO(Min),?FILL_ZERO(S)])).\n\n\tto_bin(Int) when is_integer(Int) ->\n\t    erlang:integer_to_binary(Int);\n\tto_bin(Float) when is_float(Float)->\n\t    erlang:float_to_binary(Float,[{decimals, 2}, compact]);\n\tto_bin(Atom) when is_atom(Atom) ->\n\t    erlang:atom_to_binary(Atom, utf8);\n\tto_bin(List) when is_list(List) ->\n\t    erlang:list_to_binary(List);\n\tto_bin(Binary) when is_binary(Binary) ->\n\t    Binary;\n\tto_bin(_) ->\n\t    erlang:throw(error_type).\n\n\n\t    % return value is binary\n\tto_md5(Value) ->\n\t    to_hex(to_list(erlang:md5(Value))).\n\n\tto_hex(L) when is_list(L) ->\n\t    lists:flatten([hex(I) || I <- L]).\n\t    \n\thex(I) when I > 16#f ->\n\t    [hex0((I band 16#f0) bsr 4), hex0((I band 16#0f))];\n\thex(I) -> [$0, hex0(I)].\n\n\thex0(10) -> $a;\n\thex0(11) -> $b;\n\thex0(12) -> $c;\n\thex0(13) -> $d;\n\thex0(14) -> $e;\n\thex0(15) -> $f;\n\thex0(I) -> $0 + I.\n\n\n\tto_list(Atom) when is_atom(Atom) -> erlang:atom_to_list(Atom);\n\tto_list(Int) when is_integer(Int) -> erlang:integer_to_list(Int);\n\tto_list(List) when is_list(List) -> List;\n\tto_list(Bin) when is_binary(Bin) -> erlang:binary_to_list(Bin);\n\tto_list(_) ->\n\t    erlang:throw(error_type).\n```\n\n\n","source":"_posts/阿里短信发送api.md","raw":"title: 阿里短信发送api\ndate: 2016-03-08 17:27:03\ntags: [Erlang]\n---\n阿里大鱼 短信发送接口 alibaba.aliqin.fc.sms.num.send 防坑指南\n===\n\n0x00 吐槽\n====\n[文档](http://open.taobao.com/doc2/apiDetail.htm?spm=a219a.7629065.0.0.teG5ys&apiId=25450)写的已经无力吐槽了，请问您哪里有指出 参数需要 secret了呢？？？\n\n0x01 注意项\n====\n1.md5 sign的生成是字符串 ： \n```\n${SECRET}app_key${APP_KEY}formatjsonmethodalibaba.aliqin.fc.sms.num.sendrec_num${PHONE_NUMBER}secretcb13046b7f305eb305e6e45d6b93405fsign_methodmd5sms_free_sign_name${SIGN_NAME}sms_param${PARAMS}sms_template_code${TEMPLATE_CODE}sms_typenormaltimestamp2016-03-08 16:01:53v2.0cb13046${SECRET}\n```\n 通过MD5加密生成。其中 `${}`是对应的参数变量，一定不要忘了`secret`字段，这是文档里面没有的。。。。\n\n>如果使用hmac方式加密`（sign_method: ‘hmac’）`，则不需要首尾加上secret，md5则需要\n\n2.参数的value 要进行 url编码\n\n0x02 Erlang 代码接口\n====\n[github地址](https://github.com/chenshaobo/ali_sms)\n\n```erlang\n\n\t%%%-------------------------------------------------------------------\n\t%%% @author chenshaobo0428\n\t%%% @copyright (C) 2016, <COMPANY>\n\t%%% @doc\n\t%%%\n\t%%% @end\n\t%%% Created : 08. 03 2016 16:47\n\t%%%-------------------------------------------------------------------\n\t-module(ali_sms).\n\t-author(\"chenshaobo0428\").\n\n\t%% API\n\t-export([gen_ali_sms_url/4]).\n\t-define(DEFAULT_PARAMS,[\n\t    {\"method\",<<\"alibaba.aliqin.fc.sms.num.send\">>},\n\t    {\"app_key\",<<\"YOUR KEY\">>},\n\t    {\"secret\",\"YOUR SECRET\"},\n\t    {\"v\",<<\"2.0\">>},\n\t    {\"sign_method\",<<\"md5\">>},\n\t    {\"format\",<<\"json\">>},\n\t    {\"sms_type\",<<\"normal\">>}\n\t]).\n\n\t-define(BASE_URL,\"http://gw.api.taobao.com/router/rest?\").\n\t%% 传入参数 返回 通过阿里大鱼（get方式)发送短信的完整url\n\n\tgen_ali_sms_url(PhoneNumber,SMSParam,SignName,TemplateCode)->\n\n\t    {\"secret\", SecretKey} = lists:keyfind(\"secret\", 1, ?DEFAULT_PARAMS),\n\n\t    Params=\n\t    [{\"rec_num\", to_bin(PhoneNumber)}, {\"sms_param\", to_bin(SMSParam)},\n\t\t{\"sms_free_sign_name\", to_bin(SignName)}, {\"sms_template_code\", TemplateCode},\n\t\t{\"timestamp\", to_bin(format_date())}] ++ ?DEFAULT_PARAMS,\n\t%%     按照字母排序\n\t    SortList = lists:sort(fun({Key1, _}, {Key2, _}) ->\n\t\tKey1 < Key2\n\t    end, Params),\n\t    MD5Source = SecretKey ++ lists:flatten([io_lib:format(\"~s~s\", [Key, Val]) || {Key, Val} <- SortList]) ++ SecretKey,\n\t    SignMd5 = to_bin(string:to_upper(to_list(to_md5(MD5Source)))),\n\t%%\n\t    RequestQuery = lists:flatten([io_lib:format(\"~s=~s&\", [Key, http_uri:encode(to_list(Val))]) || {Key, Val} <- [{\"sign\", SignMd5} | SortList]]),\n\t    ?BASE_URL ++ RequestQuery.\n\n\n\t-define(FILL_ZERO(X) ,case X > 9 of\n\t\t\t\t true ->\n\t\t\t\t     to_list(X);\n\t\t\t\t false ->\n\t\t\t\t     \"0\"++ \tto_list(X)\n\t\t\t     end).\n\n\tformat_date()->\n\t    {Y,M,D} = erlang:date(),\n\t    {H,Min,S}= time(),\n\t    lists:flatten(io_lib:format(\"~s-~s-~s ~s:~s:~s\", [?FILL_ZERO(Y),?FILL_ZERO(M),?FILL_ZERO(D),?FILL_ZERO(H),?FILL_ZERO(Min),?FILL_ZERO(S)])).\n\n\tto_bin(Int) when is_integer(Int) ->\n\t    erlang:integer_to_binary(Int);\n\tto_bin(Float) when is_float(Float)->\n\t    erlang:float_to_binary(Float,[{decimals, 2}, compact]);\n\tto_bin(Atom) when is_atom(Atom) ->\n\t    erlang:atom_to_binary(Atom, utf8);\n\tto_bin(List) when is_list(List) ->\n\t    erlang:list_to_binary(List);\n\tto_bin(Binary) when is_binary(Binary) ->\n\t    Binary;\n\tto_bin(_) ->\n\t    erlang:throw(error_type).\n\n\n\t    % return value is binary\n\tto_md5(Value) ->\n\t    to_hex(to_list(erlang:md5(Value))).\n\n\tto_hex(L) when is_list(L) ->\n\t    lists:flatten([hex(I) || I <- L]).\n\t    \n\thex(I) when I > 16#f ->\n\t    [hex0((I band 16#f0) bsr 4), hex0((I band 16#0f))];\n\thex(I) -> [$0, hex0(I)].\n\n\thex0(10) -> $a;\n\thex0(11) -> $b;\n\thex0(12) -> $c;\n\thex0(13) -> $d;\n\thex0(14) -> $e;\n\thex0(15) -> $f;\n\thex0(I) -> $0 + I.\n\n\n\tto_list(Atom) when is_atom(Atom) -> erlang:atom_to_list(Atom);\n\tto_list(Int) when is_integer(Int) -> erlang:integer_to_list(Int);\n\tto_list(List) when is_list(List) -> List;\n\tto_list(Bin) when is_binary(Bin) -> erlang:binary_to_list(Bin);\n\tto_list(_) ->\n\t    erlang:throw(error_type).\n```\n\n\n","slug":"阿里短信发送api","published":1,"updated":"2019-08-21T01:49:04.132Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzkm7pqr000zjl9umyo5cyw7","content":"<h1 id=\"阿里大鱼-短信发送接口-alibaba-aliqin-fc-sms-num-send-防坑指南\"><a href=\"#阿里大鱼-短信发送接口-alibaba-aliqin-fc-sms-num-send-防坑指南\" class=\"headerlink\" title=\"阿里大鱼 短信发送接口 alibaba.aliqin.fc.sms.num.send 防坑指南\"></a>阿里大鱼 短信发送接口 alibaba.aliqin.fc.sms.num.send 防坑指南</h1><h1 id=\"0x00-吐槽\"><a href=\"#0x00-吐槽\" class=\"headerlink\" title=\"0x00 吐槽\"></a>0x00 吐槽</h1><p><a href=\"http://open.taobao.com/doc2/apiDetail.htm?spm=a219a.7629065.0.0.teG5ys&amp;apiId=25450\" target=\"_blank\" rel=\"noopener\">文档</a>写的已经无力吐槽了，请问您哪里有指出 参数需要 secret了呢？？？</p>\n<h1 id=\"0x01-注意项\"><a href=\"#0x01-注意项\" class=\"headerlink\" title=\"0x01 注意项\"></a>0x01 注意项</h1><p>1.md5 sign的生成是字符串 ： </p>\n<pre><code>${SECRET}app_key${APP_KEY}formatjsonmethodalibaba.aliqin.fc.sms.num.sendrec_num${PHONE_NUMBER}secretcb13046b7f305eb305e6e45d6b93405fsign_methodmd5sms_free_sign_name${SIGN_NAME}sms_param${PARAMS}sms_template_code${TEMPLATE_CODE}sms_typenormaltimestamp2016-03-08 16:01:53v2.0cb13046${SECRET}\n</code></pre><p> 通过MD5加密生成。其中 <code>${}</code>是对应的参数变量，一定不要忘了<code>secret</code>字段，这是文档里面没有的。。。。</p>\n<blockquote>\n<p>如果使用hmac方式加密<code>（sign_method: ‘hmac’）</code>，则不需要首尾加上secret，md5则需要</p>\n</blockquote>\n<p>2.参数的value 要进行 url编码</p>\n<h1 id=\"0x02-Erlang-代码接口\"><a href=\"#0x02-Erlang-代码接口\" class=\"headerlink\" title=\"0x02 Erlang 代码接口\"></a>0x02 Erlang 代码接口</h1><p><a href=\"https://github.com/chenshaobo/ali_sms\" target=\"_blank\" rel=\"noopener\">github地址</a></p>\n<pre><code class=\"erlang\">\n    %%%-------------------------------------------------------------------\n    %%% @author chenshaobo0428\n    %%% @copyright (C) 2016, &lt;COMPANY&gt;\n    %%% @doc\n    %%%\n    %%% @end\n    %%% Created : 08. 03 2016 16:47\n    %%%-------------------------------------------------------------------\n    -module(ali_sms).\n    -author(&quot;chenshaobo0428&quot;).\n\n    %% API\n    -export([gen_ali_sms_url/4]).\n    -define(DEFAULT_PARAMS,[\n        {&quot;method&quot;,&lt;&lt;&quot;alibaba.aliqin.fc.sms.num.send&quot;&gt;&gt;},\n        {&quot;app_key&quot;,&lt;&lt;&quot;YOUR KEY&quot;&gt;&gt;},\n        {&quot;secret&quot;,&quot;YOUR SECRET&quot;},\n        {&quot;v&quot;,&lt;&lt;&quot;2.0&quot;&gt;&gt;},\n        {&quot;sign_method&quot;,&lt;&lt;&quot;md5&quot;&gt;&gt;},\n        {&quot;format&quot;,&lt;&lt;&quot;json&quot;&gt;&gt;},\n        {&quot;sms_type&quot;,&lt;&lt;&quot;normal&quot;&gt;&gt;}\n    ]).\n\n    -define(BASE_URL,&quot;http://gw.api.taobao.com/router/rest?&quot;).\n    %% 传入参数 返回 通过阿里大鱼（get方式)发送短信的完整url\n\n    gen_ali_sms_url(PhoneNumber,SMSParam,SignName,TemplateCode)-&gt;\n\n        {&quot;secret&quot;, SecretKey} = lists:keyfind(&quot;secret&quot;, 1, ?DEFAULT_PARAMS),\n\n        Params=\n        [{&quot;rec_num&quot;, to_bin(PhoneNumber)}, {&quot;sms_param&quot;, to_bin(SMSParam)},\n        {&quot;sms_free_sign_name&quot;, to_bin(SignName)}, {&quot;sms_template_code&quot;, TemplateCode},\n        {&quot;timestamp&quot;, to_bin(format_date())}] ++ ?DEFAULT_PARAMS,\n    %%     按照字母排序\n        SortList = lists:sort(fun({Key1, _}, {Key2, _}) -&gt;\n        Key1 &lt; Key2\n        end, Params),\n        MD5Source = SecretKey ++ lists:flatten([io_lib:format(&quot;~s~s&quot;, [Key, Val]) || {Key, Val} &lt;- SortList]) ++ SecretKey,\n        SignMd5 = to_bin(string:to_upper(to_list(to_md5(MD5Source)))),\n    %%\n        RequestQuery = lists:flatten([io_lib:format(&quot;~s=~s&amp;&quot;, [Key, http_uri:encode(to_list(Val))]) || {Key, Val} &lt;- [{&quot;sign&quot;, SignMd5} | SortList]]),\n        ?BASE_URL ++ RequestQuery.\n\n\n    -define(FILL_ZERO(X) ,case X &gt; 9 of\n                 true -&gt;\n                     to_list(X);\n                 false -&gt;\n                     &quot;0&quot;++     to_list(X)\n                 end).\n\n    format_date()-&gt;\n        {Y,M,D} = erlang:date(),\n        {H,Min,S}= time(),\n        lists:flatten(io_lib:format(&quot;~s-~s-~s ~s:~s:~s&quot;, [?FILL_ZERO(Y),?FILL_ZERO(M),?FILL_ZERO(D),?FILL_ZERO(H),?FILL_ZERO(Min),?FILL_ZERO(S)])).\n\n    to_bin(Int) when is_integer(Int) -&gt;\n        erlang:integer_to_binary(Int);\n    to_bin(Float) when is_float(Float)-&gt;\n        erlang:float_to_binary(Float,[{decimals, 2}, compact]);\n    to_bin(Atom) when is_atom(Atom) -&gt;\n        erlang:atom_to_binary(Atom, utf8);\n    to_bin(List) when is_list(List) -&gt;\n        erlang:list_to_binary(List);\n    to_bin(Binary) when is_binary(Binary) -&gt;\n        Binary;\n    to_bin(_) -&gt;\n        erlang:throw(error_type).\n\n\n        % return value is binary\n    to_md5(Value) -&gt;\n        to_hex(to_list(erlang:md5(Value))).\n\n    to_hex(L) when is_list(L) -&gt;\n        lists:flatten([hex(I) || I &lt;- L]).\n\n    hex(I) when I &gt; 16#f -&gt;\n        [hex0((I band 16#f0) bsr 4), hex0((I band 16#0f))];\n    hex(I) -&gt; [$0, hex0(I)].\n\n    hex0(10) -&gt; $a;\n    hex0(11) -&gt; $b;\n    hex0(12) -&gt; $c;\n    hex0(13) -&gt; $d;\n    hex0(14) -&gt; $e;\n    hex0(15) -&gt; $f;\n    hex0(I) -&gt; $0 + I.\n\n\n    to_list(Atom) when is_atom(Atom) -&gt; erlang:atom_to_list(Atom);\n    to_list(Int) when is_integer(Int) -&gt; erlang:integer_to_list(Int);\n    to_list(List) when is_list(List) -&gt; List;\n    to_list(Bin) when is_binary(Bin) -&gt; erlang:binary_to_list(Bin);\n    to_list(_) -&gt;\n        erlang:throw(error_type).\n</code></pre>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"阿里大鱼-短信发送接口-alibaba-aliqin-fc-sms-num-send-防坑指南\"><a href=\"#阿里大鱼-短信发送接口-alibaba-aliqin-fc-sms-num-send-防坑指南\" class=\"headerlink\" title=\"阿里大鱼 短信发送接口 alibaba.aliqin.fc.sms.num.send 防坑指南\"></a>阿里大鱼 短信发送接口 alibaba.aliqin.fc.sms.num.send 防坑指南</h1><h1 id=\"0x00-吐槽\"><a href=\"#0x00-吐槽\" class=\"headerlink\" title=\"0x00 吐槽\"></a>0x00 吐槽</h1><p><a href=\"http://open.taobao.com/doc2/apiDetail.htm?spm=a219a.7629065.0.0.teG5ys&amp;apiId=25450\" target=\"_blank\" rel=\"noopener\">文档</a>写的已经无力吐槽了，请问您哪里有指出 参数需要 secret了呢？？？</p>\n<h1 id=\"0x01-注意项\"><a href=\"#0x01-注意项\" class=\"headerlink\" title=\"0x01 注意项\"></a>0x01 注意项</h1><p>1.md5 sign的生成是字符串 ： </p>\n<pre><code>${SECRET}app_key${APP_KEY}formatjsonmethodalibaba.aliqin.fc.sms.num.sendrec_num${PHONE_NUMBER}secretcb13046b7f305eb305e6e45d6b93405fsign_methodmd5sms_free_sign_name${SIGN_NAME}sms_param${PARAMS}sms_template_code${TEMPLATE_CODE}sms_typenormaltimestamp2016-03-08 16:01:53v2.0cb13046${SECRET}\n</code></pre><p> 通过MD5加密生成。其中 <code>${}</code>是对应的参数变量，一定不要忘了<code>secret</code>字段，这是文档里面没有的。。。。</p>\n<blockquote>\n<p>如果使用hmac方式加密<code>（sign_method: ‘hmac’）</code>，则不需要首尾加上secret，md5则需要</p>\n</blockquote>\n<p>2.参数的value 要进行 url编码</p>\n<h1 id=\"0x02-Erlang-代码接口\"><a href=\"#0x02-Erlang-代码接口\" class=\"headerlink\" title=\"0x02 Erlang 代码接口\"></a>0x02 Erlang 代码接口</h1><p><a href=\"https://github.com/chenshaobo/ali_sms\" target=\"_blank\" rel=\"noopener\">github地址</a></p>\n<pre><code class=\"erlang\">\n    %%%-------------------------------------------------------------------\n    %%% @author chenshaobo0428\n    %%% @copyright (C) 2016, &lt;COMPANY&gt;\n    %%% @doc\n    %%%\n    %%% @end\n    %%% Created : 08. 03 2016 16:47\n    %%%-------------------------------------------------------------------\n    -module(ali_sms).\n    -author(&quot;chenshaobo0428&quot;).\n\n    %% API\n    -export([gen_ali_sms_url/4]).\n    -define(DEFAULT_PARAMS,[\n        {&quot;method&quot;,&lt;&lt;&quot;alibaba.aliqin.fc.sms.num.send&quot;&gt;&gt;},\n        {&quot;app_key&quot;,&lt;&lt;&quot;YOUR KEY&quot;&gt;&gt;},\n        {&quot;secret&quot;,&quot;YOUR SECRET&quot;},\n        {&quot;v&quot;,&lt;&lt;&quot;2.0&quot;&gt;&gt;},\n        {&quot;sign_method&quot;,&lt;&lt;&quot;md5&quot;&gt;&gt;},\n        {&quot;format&quot;,&lt;&lt;&quot;json&quot;&gt;&gt;},\n        {&quot;sms_type&quot;,&lt;&lt;&quot;normal&quot;&gt;&gt;}\n    ]).\n\n    -define(BASE_URL,&quot;http://gw.api.taobao.com/router/rest?&quot;).\n    %% 传入参数 返回 通过阿里大鱼（get方式)发送短信的完整url\n\n    gen_ali_sms_url(PhoneNumber,SMSParam,SignName,TemplateCode)-&gt;\n\n        {&quot;secret&quot;, SecretKey} = lists:keyfind(&quot;secret&quot;, 1, ?DEFAULT_PARAMS),\n\n        Params=\n        [{&quot;rec_num&quot;, to_bin(PhoneNumber)}, {&quot;sms_param&quot;, to_bin(SMSParam)},\n        {&quot;sms_free_sign_name&quot;, to_bin(SignName)}, {&quot;sms_template_code&quot;, TemplateCode},\n        {&quot;timestamp&quot;, to_bin(format_date())}] ++ ?DEFAULT_PARAMS,\n    %%     按照字母排序\n        SortList = lists:sort(fun({Key1, _}, {Key2, _}) -&gt;\n        Key1 &lt; Key2\n        end, Params),\n        MD5Source = SecretKey ++ lists:flatten([io_lib:format(&quot;~s~s&quot;, [Key, Val]) || {Key, Val} &lt;- SortList]) ++ SecretKey,\n        SignMd5 = to_bin(string:to_upper(to_list(to_md5(MD5Source)))),\n    %%\n        RequestQuery = lists:flatten([io_lib:format(&quot;~s=~s&amp;&quot;, [Key, http_uri:encode(to_list(Val))]) || {Key, Val} &lt;- [{&quot;sign&quot;, SignMd5} | SortList]]),\n        ?BASE_URL ++ RequestQuery.\n\n\n    -define(FILL_ZERO(X) ,case X &gt; 9 of\n                 true -&gt;\n                     to_list(X);\n                 false -&gt;\n                     &quot;0&quot;++     to_list(X)\n                 end).\n\n    format_date()-&gt;\n        {Y,M,D} = erlang:date(),\n        {H,Min,S}= time(),\n        lists:flatten(io_lib:format(&quot;~s-~s-~s ~s:~s:~s&quot;, [?FILL_ZERO(Y),?FILL_ZERO(M),?FILL_ZERO(D),?FILL_ZERO(H),?FILL_ZERO(Min),?FILL_ZERO(S)])).\n\n    to_bin(Int) when is_integer(Int) -&gt;\n        erlang:integer_to_binary(Int);\n    to_bin(Float) when is_float(Float)-&gt;\n        erlang:float_to_binary(Float,[{decimals, 2}, compact]);\n    to_bin(Atom) when is_atom(Atom) -&gt;\n        erlang:atom_to_binary(Atom, utf8);\n    to_bin(List) when is_list(List) -&gt;\n        erlang:list_to_binary(List);\n    to_bin(Binary) when is_binary(Binary) -&gt;\n        Binary;\n    to_bin(_) -&gt;\n        erlang:throw(error_type).\n\n\n        % return value is binary\n    to_md5(Value) -&gt;\n        to_hex(to_list(erlang:md5(Value))).\n\n    to_hex(L) when is_list(L) -&gt;\n        lists:flatten([hex(I) || I &lt;- L]).\n\n    hex(I) when I &gt; 16#f -&gt;\n        [hex0((I band 16#f0) bsr 4), hex0((I band 16#0f))];\n    hex(I) -&gt; [$0, hex0(I)].\n\n    hex0(10) -&gt; $a;\n    hex0(11) -&gt; $b;\n    hex0(12) -&gt; $c;\n    hex0(13) -&gt; $d;\n    hex0(14) -&gt; $e;\n    hex0(15) -&gt; $f;\n    hex0(I) -&gt; $0 + I.\n\n\n    to_list(Atom) when is_atom(Atom) -&gt; erlang:atom_to_list(Atom);\n    to_list(Int) when is_integer(Int) -&gt; erlang:integer_to_list(Int);\n    to_list(List) when is_list(List) -&gt; List;\n    to_list(Bin) when is_binary(Bin) -&gt; erlang:binary_to_list(Bin);\n    to_list(_) -&gt;\n        erlang:throw(error_type).\n</code></pre>\n"},{"title":"erlang程序优化点","date":"2015-11-10T17:54:26.000Z","_content":" 进程标志设置\n======\n消息和binary内存：`erlang:process_flag(min_bin_vheap_size, 1024*1024)`，减少大量消息到达或处理过程中产生大量binary时的gc次数\n堆内存：`erlang:process_flag(min_heap_size, 1024*1024)`，减少处理过程中产生大量term，尤其是list时的gc次数\n进程优先级：`erlang:process_flag(priority, high)`，防止特殊进程被其它常见进程强制执行reductions\n进程调度器绑定：`erlang:process_flag(scheduler, 1)`，当进程使用了port时，还需要port绑定支持，防止进程在不同调度器间迁移引起性能损失，如cache、跨numa node拷贝等，当进程使用了port时，主要是套接字，若进程与port不在一个scheduler上，可能会引发严重的epoll fd锁竞争及跨numa node拷贝，导致性能严重下降\n\n 虚拟机参数\n======\n`+S X:X` ：启用调度器数量，多个调度器使用多线程，有大量锁争用\n`-smp disable` ：取消smp，仅使用单线程，16个-smp_disabled虚拟机性能高于+S 16:16\n`+sbt db` ：将scheduler绑定到具体的cpu核心上，再配合erlang进程和port绑定，可以显著提升性能，但是如果绑定错误，反而会有反效果\n\n\n消息队列\n======\n消息队列长度对性能的影响主要体现在以下两个方面：进程binary堆的gc和进程内消息匹配，前者可以通过放大堆内存来减少gc影响，后者需要谨慎处理。\n若进程在处理消息时是通过消息匹配方式取得消息，同时又允许其它进程无限制投递消息到本进程，此时会引发灾难，匹配方式取得消息会引发遍历进程消息队列，如果此时仍然有其它进程投递消息，会导致进程消息队列暴涨，遍历过程也将增大代价，引发恶性循环。已知模式有：在gen_server中使用file:write（raw模式）或gen_tcp:send等，这些操作都是erlang虚拟机内部通过port driver实现的，均有内部receive匹配接收，对于这些操作，最好的办法是将其改写为nif，直接走进程堆进行操作，次之为将`file:write`或`gen_tcp:send`改写为两阶段，第一阶段为port_command，第二阶段由gen_server接收返回结果，这种异步化可能有些正确性问题，对于`gen_tcp:send`影响不大，因为网络请求本身要么同步化要么异步化，都需要内部的确认机制；对于`file:write`影响较大，`file:write`的错误通常为目录不存在或磁盘空间不足，确保这两个错误不造成影响即可，同时如果进程的其它部分需要使用file的其它操作，必须首先清空之前file:write产生的所有file的port消息，否则有可能产生消息序列紊乱的问题。\n对于套接字的接口调用，可以参考rabbitmq的两阶段套接字发送方法，而对于文件接口调用，可以参考riak的bitcask引擎将文件读写封装为nif的方法\n\n内存及ets表\n======\nets表可以用于进程间交换大数据，或充当缓存，以及复杂匹配代理等，其性能颇高，并发读写可达千万级qps，并有两个并发选项，在建立表时设置，分别是{write_concurrency, true} | {read_concurrency, true}，以允许ets的并发读写\n使用ets表可以绕过进程消息机制，从而在一定程度上提高性能，并将编程模式从面向消息模式变为面向共享内存模式\n\n CPU密集型操作\n======\nerlang执行流程的问题：\n1. 其指令都是由其虚拟机执行的，一条指令可能需要cpu执行3-4条指令，一些大规模的匹配或遍历操作会严重影响性能;\n2. 其bif调用执行过程类似于操作系统的系统调用，需要对传入参数进行转换，在大量小操作时损失性能较为严重\n3. 其port driver流程较为繁冗复杂，需要经历大量的回调等，一般的小功能操作，不要通过port driver实现\n建议：\n字符串匹配不要通过list进行，最好通过binary；单字节匹配，尤其是语法解析，如xmerl、mochijson2、lexx等，尽管使用binary，但是它们是一个字节一个字节匹配的，性能会退化到list的水平，应该尽量将其nif化；\n对于一些小操作，反而应该去bif化、去nif化、去port driver化，因为进入erlang内部函数的执行代价也不小；\n已知的性能瓶颈：re、xmerl、mochijson2、lexx、erlang:now、calendar:local_time_to_universal_time_dst等\n\n数据结构\n======\n减少遍历，尽量使用API提供的操作\n由于各种类型的变量实际可以当做c的指针，因此erlang语言级的操作并不会有太大代价\nlists：reverse为c代码实现，性能较高，依赖于该接口实现的lists API性能都不差，避免list遍历，[||]和foreach性能是foldl的2倍，不在非必要的时候遍历list\ndict：find为微秒级操作，内部通过动态hash实现，数据结构先有若干槽位，后根据数据规模变大而逐步增加槽位，fold遍历性能低下\ngb_trees：lookup为微秒级操作，内部通过一个大的元组实现，iterator+next遍历性能低下，比list的foldl还要低2个数量级\n其它常用结构：queue，set，graph等\n\n 计时器\n======\nerlang的计时器timer是通过一个唯一的timer进程实现的，该进程是一个gen_server，用户通过timer:send_after和timer:apply_after在指定时间间隔后收到指定消息或执行某个函数，每个用户的计时器都是一条记录，保存在timer的ets表timer_tab中，timer的时序驱动通过gen_server的超时机制实现。若同时使用timer的用户过多，则tiemr将响应不过来，成为瓶颈。\n更好的方法是使用erlang的原生计时器erlang:send_after和erlang:start_timer，它们把计时器附着在进程自己身上。\n\n 尾调用和尾递归\n======\n尾调用和尾递归是erlang函数式语言最强大的优化，尽量保持函数尾部有尾调用或尾递归\n\n文件预读，批量写，缓存\n======\n这些方式都是局部性的体现：\n预读：读空间局部性，文件提供了read_ahead选项\n批量写：写空间局部性\n对于文件写或套接字发送，存在若干级别的批量写：\n1. erlang进程级：进程内部通过list缓存数据\n2. erlang虚拟机：不管是efile还是inet的driver，都提供了批量写的选项delayed_write|delay_send，它们对大量的异步写性能提升很有效\n3. 操作系统级：操作系统内部有文件写缓冲及套接字写缓冲\n4. 硬件级：cache等\n 缓存：读写时间局部性，读写空间局部性，主要通过操作系统系统，erlang虚拟机没有内部的缓存\n\n套接字标志设置\n======\n延迟发送：`{delay_send, true}`，聚合若干小消息为一个大消息，性能提升显著\n发送高低水位：`{high_watermark, 128 * 1024} | {low_watermark, 64 * 1024}`，辅助delay_send使用，delay_send的聚合缓冲区大小为high_watermark，数据缓存到high_watermark后，将阻塞port_command，使用send发送数据，直到缓冲区大小降低到low_watermark后，解除阻塞，通常这些值越大越好，但erlang虚拟机允许设置的最大值不超过128K\n发送缓冲大小：`{sndbuf, 16 * 1024}`，操作系统对套接字的发送缓冲大小，在延迟发送时有效，越大越好，但有极值\n接收缓冲大小：`{recbuf, 16 * 1024}`，操作系统对套接字的接收缓冲大小\n\n序列化/反序列化\n======\n通常情况下，为了简化实现，一般将erlang的term序列化为binary，传递到目的地后，在将binary反序列化为term，这通常涉及到两个操作：\nterm_to_binary及binary_to_term，这两个操作性能消耗极为严重，应至多只做一次，减少甚至消除它们是最正确的，例如直接构造binary进行跨虚拟机数据交换；\n但对比与其它的序列化和反序列化方式，如利用protobuf等，term_to_binary和binary_to_term的性能是高于这些方式的，毕竟是erlang原生格式，对于力求简单的应用，其序列化和反序列化方式推荐term_to_binary和binary_to_term\n\n并发化\n======\n在一些场景下，如web请求、数据库请求、分布式文件系统等，单个接入接口已经不能满足性能需求，需要有多个接入接口，多个数据通道，等等，这要求所有请求处理过程必须是无状态的，或者状态更改同步进入一个公共存储，而公共存储也必须是支持并发处理的，如并发数据库、类hdfs、类dynamo存储等，若一致性要求较高，最好选用并发数据库，如mysql等，若在此基础上还要求高可用，最好选择同步多结点存储，\nmnesia、zk都是这方面的典型；若不需要较高的一致性，类hdfs、类dynamo这类no sql存储即可满足\n\nhipe\n======\n将erlang汇编翻译成机器码，减少一条erlang指令对应的cpu指令数\n","source":"_posts/erlang—program-optimization.md","raw":"title: erlang程序优化点\ndate: 2015-11-11 01:54:26\ntags: [Erlang]\n---\n 进程标志设置\n======\n消息和binary内存：`erlang:process_flag(min_bin_vheap_size, 1024*1024)`，减少大量消息到达或处理过程中产生大量binary时的gc次数\n堆内存：`erlang:process_flag(min_heap_size, 1024*1024)`，减少处理过程中产生大量term，尤其是list时的gc次数\n进程优先级：`erlang:process_flag(priority, high)`，防止特殊进程被其它常见进程强制执行reductions\n进程调度器绑定：`erlang:process_flag(scheduler, 1)`，当进程使用了port时，还需要port绑定支持，防止进程在不同调度器间迁移引起性能损失，如cache、跨numa node拷贝等，当进程使用了port时，主要是套接字，若进程与port不在一个scheduler上，可能会引发严重的epoll fd锁竞争及跨numa node拷贝，导致性能严重下降\n\n 虚拟机参数\n======\n`+S X:X` ：启用调度器数量，多个调度器使用多线程，有大量锁争用\n`-smp disable` ：取消smp，仅使用单线程，16个-smp_disabled虚拟机性能高于+S 16:16\n`+sbt db` ：将scheduler绑定到具体的cpu核心上，再配合erlang进程和port绑定，可以显著提升性能，但是如果绑定错误，反而会有反效果\n\n\n消息队列\n======\n消息队列长度对性能的影响主要体现在以下两个方面：进程binary堆的gc和进程内消息匹配，前者可以通过放大堆内存来减少gc影响，后者需要谨慎处理。\n若进程在处理消息时是通过消息匹配方式取得消息，同时又允许其它进程无限制投递消息到本进程，此时会引发灾难，匹配方式取得消息会引发遍历进程消息队列，如果此时仍然有其它进程投递消息，会导致进程消息队列暴涨，遍历过程也将增大代价，引发恶性循环。已知模式有：在gen_server中使用file:write（raw模式）或gen_tcp:send等，这些操作都是erlang虚拟机内部通过port driver实现的，均有内部receive匹配接收，对于这些操作，最好的办法是将其改写为nif，直接走进程堆进行操作，次之为将`file:write`或`gen_tcp:send`改写为两阶段，第一阶段为port_command，第二阶段由gen_server接收返回结果，这种异步化可能有些正确性问题，对于`gen_tcp:send`影响不大，因为网络请求本身要么同步化要么异步化，都需要内部的确认机制；对于`file:write`影响较大，`file:write`的错误通常为目录不存在或磁盘空间不足，确保这两个错误不造成影响即可，同时如果进程的其它部分需要使用file的其它操作，必须首先清空之前file:write产生的所有file的port消息，否则有可能产生消息序列紊乱的问题。\n对于套接字的接口调用，可以参考rabbitmq的两阶段套接字发送方法，而对于文件接口调用，可以参考riak的bitcask引擎将文件读写封装为nif的方法\n\n内存及ets表\n======\nets表可以用于进程间交换大数据，或充当缓存，以及复杂匹配代理等，其性能颇高，并发读写可达千万级qps，并有两个并发选项，在建立表时设置，分别是{write_concurrency, true} | {read_concurrency, true}，以允许ets的并发读写\n使用ets表可以绕过进程消息机制，从而在一定程度上提高性能，并将编程模式从面向消息模式变为面向共享内存模式\n\n CPU密集型操作\n======\nerlang执行流程的问题：\n1. 其指令都是由其虚拟机执行的，一条指令可能需要cpu执行3-4条指令，一些大规模的匹配或遍历操作会严重影响性能;\n2. 其bif调用执行过程类似于操作系统的系统调用，需要对传入参数进行转换，在大量小操作时损失性能较为严重\n3. 其port driver流程较为繁冗复杂，需要经历大量的回调等，一般的小功能操作，不要通过port driver实现\n建议：\n字符串匹配不要通过list进行，最好通过binary；单字节匹配，尤其是语法解析，如xmerl、mochijson2、lexx等，尽管使用binary，但是它们是一个字节一个字节匹配的，性能会退化到list的水平，应该尽量将其nif化；\n对于一些小操作，反而应该去bif化、去nif化、去port driver化，因为进入erlang内部函数的执行代价也不小；\n已知的性能瓶颈：re、xmerl、mochijson2、lexx、erlang:now、calendar:local_time_to_universal_time_dst等\n\n数据结构\n======\n减少遍历，尽量使用API提供的操作\n由于各种类型的变量实际可以当做c的指针，因此erlang语言级的操作并不会有太大代价\nlists：reverse为c代码实现，性能较高，依赖于该接口实现的lists API性能都不差，避免list遍历，[||]和foreach性能是foldl的2倍，不在非必要的时候遍历list\ndict：find为微秒级操作，内部通过动态hash实现，数据结构先有若干槽位，后根据数据规模变大而逐步增加槽位，fold遍历性能低下\ngb_trees：lookup为微秒级操作，内部通过一个大的元组实现，iterator+next遍历性能低下，比list的foldl还要低2个数量级\n其它常用结构：queue，set，graph等\n\n 计时器\n======\nerlang的计时器timer是通过一个唯一的timer进程实现的，该进程是一个gen_server，用户通过timer:send_after和timer:apply_after在指定时间间隔后收到指定消息或执行某个函数，每个用户的计时器都是一条记录，保存在timer的ets表timer_tab中，timer的时序驱动通过gen_server的超时机制实现。若同时使用timer的用户过多，则tiemr将响应不过来，成为瓶颈。\n更好的方法是使用erlang的原生计时器erlang:send_after和erlang:start_timer，它们把计时器附着在进程自己身上。\n\n 尾调用和尾递归\n======\n尾调用和尾递归是erlang函数式语言最强大的优化，尽量保持函数尾部有尾调用或尾递归\n\n文件预读，批量写，缓存\n======\n这些方式都是局部性的体现：\n预读：读空间局部性，文件提供了read_ahead选项\n批量写：写空间局部性\n对于文件写或套接字发送，存在若干级别的批量写：\n1. erlang进程级：进程内部通过list缓存数据\n2. erlang虚拟机：不管是efile还是inet的driver，都提供了批量写的选项delayed_write|delay_send，它们对大量的异步写性能提升很有效\n3. 操作系统级：操作系统内部有文件写缓冲及套接字写缓冲\n4. 硬件级：cache等\n 缓存：读写时间局部性，读写空间局部性，主要通过操作系统系统，erlang虚拟机没有内部的缓存\n\n套接字标志设置\n======\n延迟发送：`{delay_send, true}`，聚合若干小消息为一个大消息，性能提升显著\n发送高低水位：`{high_watermark, 128 * 1024} | {low_watermark, 64 * 1024}`，辅助delay_send使用，delay_send的聚合缓冲区大小为high_watermark，数据缓存到high_watermark后，将阻塞port_command，使用send发送数据，直到缓冲区大小降低到low_watermark后，解除阻塞，通常这些值越大越好，但erlang虚拟机允许设置的最大值不超过128K\n发送缓冲大小：`{sndbuf, 16 * 1024}`，操作系统对套接字的发送缓冲大小，在延迟发送时有效，越大越好，但有极值\n接收缓冲大小：`{recbuf, 16 * 1024}`，操作系统对套接字的接收缓冲大小\n\n序列化/反序列化\n======\n通常情况下，为了简化实现，一般将erlang的term序列化为binary，传递到目的地后，在将binary反序列化为term，这通常涉及到两个操作：\nterm_to_binary及binary_to_term，这两个操作性能消耗极为严重，应至多只做一次，减少甚至消除它们是最正确的，例如直接构造binary进行跨虚拟机数据交换；\n但对比与其它的序列化和反序列化方式，如利用protobuf等，term_to_binary和binary_to_term的性能是高于这些方式的，毕竟是erlang原生格式，对于力求简单的应用，其序列化和反序列化方式推荐term_to_binary和binary_to_term\n\n并发化\n======\n在一些场景下，如web请求、数据库请求、分布式文件系统等，单个接入接口已经不能满足性能需求，需要有多个接入接口，多个数据通道，等等，这要求所有请求处理过程必须是无状态的，或者状态更改同步进入一个公共存储，而公共存储也必须是支持并发处理的，如并发数据库、类hdfs、类dynamo存储等，若一致性要求较高，最好选用并发数据库，如mysql等，若在此基础上还要求高可用，最好选择同步多结点存储，\nmnesia、zk都是这方面的典型；若不需要较高的一致性，类hdfs、类dynamo这类no sql存储即可满足\n\nhipe\n======\n将erlang汇编翻译成机器码，减少一条erlang指令对应的cpu指令数\n","slug":"erlang—program-optimization","published":1,"updated":"2019-08-21T01:49:04.129Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzkm7pra001zjl9uor750bx1","content":"<h1 id=\"进程标志设置\"><a href=\"#进程标志设置\" class=\"headerlink\" title=\" 进程标志设置\"></a> 进程标志设置</h1><p>消息和binary内存：<code>erlang:process_flag(min_bin_vheap_size, 1024*1024)</code>，减少大量消息到达或处理过程中产生大量binary时的gc次数<br>堆内存：<code>erlang:process_flag(min_heap_size, 1024*1024)</code>，减少处理过程中产生大量term，尤其是list时的gc次数<br>进程优先级：<code>erlang:process_flag(priority, high)</code>，防止特殊进程被其它常见进程强制执行reductions<br>进程调度器绑定：<code>erlang:process_flag(scheduler, 1)</code>，当进程使用了port时，还需要port绑定支持，防止进程在不同调度器间迁移引起性能损失，如cache、跨numa node拷贝等，当进程使用了port时，主要是套接字，若进程与port不在一个scheduler上，可能会引发严重的epoll fd锁竞争及跨numa node拷贝，导致性能严重下降</p>\n<h1 id=\"虚拟机参数\"><a href=\"#虚拟机参数\" class=\"headerlink\" title=\" 虚拟机参数\"></a> 虚拟机参数</h1><p><code>+S X:X</code> ：启用调度器数量，多个调度器使用多线程，有大量锁争用<br><code>-smp disable</code> ：取消smp，仅使用单线程，16个-smp_disabled虚拟机性能高于+S 16:16<br><code>+sbt db</code> ：将scheduler绑定到具体的cpu核心上，再配合erlang进程和port绑定，可以显著提升性能，但是如果绑定错误，反而会有反效果</p>\n<h1 id=\"消息队列\"><a href=\"#消息队列\" class=\"headerlink\" title=\"消息队列\"></a>消息队列</h1><p>消息队列长度对性能的影响主要体现在以下两个方面：进程binary堆的gc和进程内消息匹配，前者可以通过放大堆内存来减少gc影响，后者需要谨慎处理。<br>若进程在处理消息时是通过消息匹配方式取得消息，同时又允许其它进程无限制投递消息到本进程，此时会引发灾难，匹配方式取得消息会引发遍历进程消息队列，如果此时仍然有其它进程投递消息，会导致进程消息队列暴涨，遍历过程也将增大代价，引发恶性循环。已知模式有：在gen_server中使用file:write（raw模式）或gen_tcp:send等，这些操作都是erlang虚拟机内部通过port driver实现的，均有内部receive匹配接收，对于这些操作，最好的办法是将其改写为nif，直接走进程堆进行操作，次之为将<code>file:write</code>或<code>gen_tcp:send</code>改写为两阶段，第一阶段为port_command，第二阶段由gen_server接收返回结果，这种异步化可能有些正确性问题，对于<code>gen_tcp:send</code>影响不大，因为网络请求本身要么同步化要么异步化，都需要内部的确认机制；对于<code>file:write</code>影响较大，<code>file:write</code>的错误通常为目录不存在或磁盘空间不足，确保这两个错误不造成影响即可，同时如果进程的其它部分需要使用file的其它操作，必须首先清空之前file:write产生的所有file的port消息，否则有可能产生消息序列紊乱的问题。<br>对于套接字的接口调用，可以参考rabbitmq的两阶段套接字发送方法，而对于文件接口调用，可以参考riak的bitcask引擎将文件读写封装为nif的方法</p>\n<h1 id=\"内存及ets表\"><a href=\"#内存及ets表\" class=\"headerlink\" title=\"内存及ets表\"></a>内存及ets表</h1><p>ets表可以用于进程间交换大数据，或充当缓存，以及复杂匹配代理等，其性能颇高，并发读写可达千万级qps，并有两个并发选项，在建立表时设置，分别是{write_concurrency, true} | {read_concurrency, true}，以允许ets的并发读写<br>使用ets表可以绕过进程消息机制，从而在一定程度上提高性能，并将编程模式从面向消息模式变为面向共享内存模式</p>\n<h1 id=\"CPU密集型操作\"><a href=\"#CPU密集型操作\" class=\"headerlink\" title=\" CPU密集型操作\"></a> CPU密集型操作</h1><p>erlang执行流程的问题：</p>\n<ol>\n<li>其指令都是由其虚拟机执行的，一条指令可能需要cpu执行3-4条指令，一些大规模的匹配或遍历操作会严重影响性能;</li>\n<li>其bif调用执行过程类似于操作系统的系统调用，需要对传入参数进行转换，在大量小操作时损失性能较为严重</li>\n<li>其port driver流程较为繁冗复杂，需要经历大量的回调等，一般的小功能操作，不要通过port driver实现<br>建议：<br>字符串匹配不要通过list进行，最好通过binary；单字节匹配，尤其是语法解析，如xmerl、mochijson2、lexx等，尽管使用binary，但是它们是一个字节一个字节匹配的，性能会退化到list的水平，应该尽量将其nif化；<br>对于一些小操作，反而应该去bif化、去nif化、去port driver化，因为进入erlang内部函数的执行代价也不小；<br>已知的性能瓶颈：re、xmerl、mochijson2、lexx、erlang:now、calendar:local_time_to_universal_time_dst等</li>\n</ol>\n<h1 id=\"数据结构\"><a href=\"#数据结构\" class=\"headerlink\" title=\"数据结构\"></a>数据结构</h1><p>减少遍历，尽量使用API提供的操作<br>由于各种类型的变量实际可以当做c的指针，因此erlang语言级的操作并不会有太大代价<br>lists：reverse为c代码实现，性能较高，依赖于该接口实现的lists API性能都不差，避免list遍历，[||]和foreach性能是foldl的2倍，不在非必要的时候遍历list<br>dict：find为微秒级操作，内部通过动态hash实现，数据结构先有若干槽位，后根据数据规模变大而逐步增加槽位，fold遍历性能低下<br>gb_trees：lookup为微秒级操作，内部通过一个大的元组实现，iterator+next遍历性能低下，比list的foldl还要低2个数量级<br>其它常用结构：queue，set，graph等</p>\n<h1 id=\"计时器\"><a href=\"#计时器\" class=\"headerlink\" title=\" 计时器\"></a> 计时器</h1><p>erlang的计时器timer是通过一个唯一的timer进程实现的，该进程是一个gen_server，用户通过timer:send_after和timer:apply_after在指定时间间隔后收到指定消息或执行某个函数，每个用户的计时器都是一条记录，保存在timer的ets表timer_tab中，timer的时序驱动通过gen_server的超时机制实现。若同时使用timer的用户过多，则tiemr将响应不过来，成为瓶颈。<br>更好的方法是使用erlang的原生计时器erlang:send_after和erlang:start_timer，它们把计时器附着在进程自己身上。</p>\n<h1 id=\"尾调用和尾递归\"><a href=\"#尾调用和尾递归\" class=\"headerlink\" title=\" 尾调用和尾递归\"></a> 尾调用和尾递归</h1><p>尾调用和尾递归是erlang函数式语言最强大的优化，尽量保持函数尾部有尾调用或尾递归</p>\n<h1 id=\"文件预读，批量写，缓存\"><a href=\"#文件预读，批量写，缓存\" class=\"headerlink\" title=\"文件预读，批量写，缓存\"></a>文件预读，批量写，缓存</h1><p>这些方式都是局部性的体现：<br>预读：读空间局部性，文件提供了read_ahead选项<br>批量写：写空间局部性<br>对于文件写或套接字发送，存在若干级别的批量写：</p>\n<ol>\n<li>erlang进程级：进程内部通过list缓存数据</li>\n<li>erlang虚拟机：不管是efile还是inet的driver，都提供了批量写的选项delayed_write|delay_send，它们对大量的异步写性能提升很有效</li>\n<li>操作系统级：操作系统内部有文件写缓冲及套接字写缓冲</li>\n<li>硬件级：cache等<br>缓存：读写时间局部性，读写空间局部性，主要通过操作系统系统，erlang虚拟机没有内部的缓存</li>\n</ol>\n<h1 id=\"套接字标志设置\"><a href=\"#套接字标志设置\" class=\"headerlink\" title=\"套接字标志设置\"></a>套接字标志设置</h1><p>延迟发送：<code>{delay_send, true}</code>，聚合若干小消息为一个大消息，性能提升显著<br>发送高低水位：<code>{high_watermark, 128 * 1024} | {low_watermark, 64 * 1024}</code>，辅助delay_send使用，delay_send的聚合缓冲区大小为high_watermark，数据缓存到high_watermark后，将阻塞port_command，使用send发送数据，直到缓冲区大小降低到low_watermark后，解除阻塞，通常这些值越大越好，但erlang虚拟机允许设置的最大值不超过128K<br>发送缓冲大小：<code>{sndbuf, 16 * 1024}</code>，操作系统对套接字的发送缓冲大小，在延迟发送时有效，越大越好，但有极值<br>接收缓冲大小：<code>{recbuf, 16 * 1024}</code>，操作系统对套接字的接收缓冲大小</p>\n<h1 id=\"序列化-反序列化\"><a href=\"#序列化-反序列化\" class=\"headerlink\" title=\"序列化/反序列化\"></a>序列化/反序列化</h1><p>通常情况下，为了简化实现，一般将erlang的term序列化为binary，传递到目的地后，在将binary反序列化为term，这通常涉及到两个操作：<br>term_to_binary及binary_to_term，这两个操作性能消耗极为严重，应至多只做一次，减少甚至消除它们是最正确的，例如直接构造binary进行跨虚拟机数据交换；<br>但对比与其它的序列化和反序列化方式，如利用protobuf等，term_to_binary和binary_to_term的性能是高于这些方式的，毕竟是erlang原生格式，对于力求简单的应用，其序列化和反序列化方式推荐term_to_binary和binary_to_term</p>\n<h1 id=\"并发化\"><a href=\"#并发化\" class=\"headerlink\" title=\"并发化\"></a>并发化</h1><p>在一些场景下，如web请求、数据库请求、分布式文件系统等，单个接入接口已经不能满足性能需求，需要有多个接入接口，多个数据通道，等等，这要求所有请求处理过程必须是无状态的，或者状态更改同步进入一个公共存储，而公共存储也必须是支持并发处理的，如并发数据库、类hdfs、类dynamo存储等，若一致性要求较高，最好选用并发数据库，如mysql等，若在此基础上还要求高可用，最好选择同步多结点存储，<br>mnesia、zk都是这方面的典型；若不需要较高的一致性，类hdfs、类dynamo这类no sql存储即可满足</p>\n<h1 id=\"hipe\"><a href=\"#hipe\" class=\"headerlink\" title=\"hipe\"></a>hipe</h1><p>将erlang汇编翻译成机器码，减少一条erlang指令对应的cpu指令数</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"进程标志设置\"><a href=\"#进程标志设置\" class=\"headerlink\" title=\" 进程标志设置\"></a> 进程标志设置</h1><p>消息和binary内存：<code>erlang:process_flag(min_bin_vheap_size, 1024*1024)</code>，减少大量消息到达或处理过程中产生大量binary时的gc次数<br>堆内存：<code>erlang:process_flag(min_heap_size, 1024*1024)</code>，减少处理过程中产生大量term，尤其是list时的gc次数<br>进程优先级：<code>erlang:process_flag(priority, high)</code>，防止特殊进程被其它常见进程强制执行reductions<br>进程调度器绑定：<code>erlang:process_flag(scheduler, 1)</code>，当进程使用了port时，还需要port绑定支持，防止进程在不同调度器间迁移引起性能损失，如cache、跨numa node拷贝等，当进程使用了port时，主要是套接字，若进程与port不在一个scheduler上，可能会引发严重的epoll fd锁竞争及跨numa node拷贝，导致性能严重下降</p>\n<h1 id=\"虚拟机参数\"><a href=\"#虚拟机参数\" class=\"headerlink\" title=\" 虚拟机参数\"></a> 虚拟机参数</h1><p><code>+S X:X</code> ：启用调度器数量，多个调度器使用多线程，有大量锁争用<br><code>-smp disable</code> ：取消smp，仅使用单线程，16个-smp_disabled虚拟机性能高于+S 16:16<br><code>+sbt db</code> ：将scheduler绑定到具体的cpu核心上，再配合erlang进程和port绑定，可以显著提升性能，但是如果绑定错误，反而会有反效果</p>\n<h1 id=\"消息队列\"><a href=\"#消息队列\" class=\"headerlink\" title=\"消息队列\"></a>消息队列</h1><p>消息队列长度对性能的影响主要体现在以下两个方面：进程binary堆的gc和进程内消息匹配，前者可以通过放大堆内存来减少gc影响，后者需要谨慎处理。<br>若进程在处理消息时是通过消息匹配方式取得消息，同时又允许其它进程无限制投递消息到本进程，此时会引发灾难，匹配方式取得消息会引发遍历进程消息队列，如果此时仍然有其它进程投递消息，会导致进程消息队列暴涨，遍历过程也将增大代价，引发恶性循环。已知模式有：在gen_server中使用file:write（raw模式）或gen_tcp:send等，这些操作都是erlang虚拟机内部通过port driver实现的，均有内部receive匹配接收，对于这些操作，最好的办法是将其改写为nif，直接走进程堆进行操作，次之为将<code>file:write</code>或<code>gen_tcp:send</code>改写为两阶段，第一阶段为port_command，第二阶段由gen_server接收返回结果，这种异步化可能有些正确性问题，对于<code>gen_tcp:send</code>影响不大，因为网络请求本身要么同步化要么异步化，都需要内部的确认机制；对于<code>file:write</code>影响较大，<code>file:write</code>的错误通常为目录不存在或磁盘空间不足，确保这两个错误不造成影响即可，同时如果进程的其它部分需要使用file的其它操作，必须首先清空之前file:write产生的所有file的port消息，否则有可能产生消息序列紊乱的问题。<br>对于套接字的接口调用，可以参考rabbitmq的两阶段套接字发送方法，而对于文件接口调用，可以参考riak的bitcask引擎将文件读写封装为nif的方法</p>\n<h1 id=\"内存及ets表\"><a href=\"#内存及ets表\" class=\"headerlink\" title=\"内存及ets表\"></a>内存及ets表</h1><p>ets表可以用于进程间交换大数据，或充当缓存，以及复杂匹配代理等，其性能颇高，并发读写可达千万级qps，并有两个并发选项，在建立表时设置，分别是{write_concurrency, true} | {read_concurrency, true}，以允许ets的并发读写<br>使用ets表可以绕过进程消息机制，从而在一定程度上提高性能，并将编程模式从面向消息模式变为面向共享内存模式</p>\n<h1 id=\"CPU密集型操作\"><a href=\"#CPU密集型操作\" class=\"headerlink\" title=\" CPU密集型操作\"></a> CPU密集型操作</h1><p>erlang执行流程的问题：</p>\n<ol>\n<li>其指令都是由其虚拟机执行的，一条指令可能需要cpu执行3-4条指令，一些大规模的匹配或遍历操作会严重影响性能;</li>\n<li>其bif调用执行过程类似于操作系统的系统调用，需要对传入参数进行转换，在大量小操作时损失性能较为严重</li>\n<li>其port driver流程较为繁冗复杂，需要经历大量的回调等，一般的小功能操作，不要通过port driver实现<br>建议：<br>字符串匹配不要通过list进行，最好通过binary；单字节匹配，尤其是语法解析，如xmerl、mochijson2、lexx等，尽管使用binary，但是它们是一个字节一个字节匹配的，性能会退化到list的水平，应该尽量将其nif化；<br>对于一些小操作，反而应该去bif化、去nif化、去port driver化，因为进入erlang内部函数的执行代价也不小；<br>已知的性能瓶颈：re、xmerl、mochijson2、lexx、erlang:now、calendar:local_time_to_universal_time_dst等</li>\n</ol>\n<h1 id=\"数据结构\"><a href=\"#数据结构\" class=\"headerlink\" title=\"数据结构\"></a>数据结构</h1><p>减少遍历，尽量使用API提供的操作<br>由于各种类型的变量实际可以当做c的指针，因此erlang语言级的操作并不会有太大代价<br>lists：reverse为c代码实现，性能较高，依赖于该接口实现的lists API性能都不差，避免list遍历，[||]和foreach性能是foldl的2倍，不在非必要的时候遍历list<br>dict：find为微秒级操作，内部通过动态hash实现，数据结构先有若干槽位，后根据数据规模变大而逐步增加槽位，fold遍历性能低下<br>gb_trees：lookup为微秒级操作，内部通过一个大的元组实现，iterator+next遍历性能低下，比list的foldl还要低2个数量级<br>其它常用结构：queue，set，graph等</p>\n<h1 id=\"计时器\"><a href=\"#计时器\" class=\"headerlink\" title=\" 计时器\"></a> 计时器</h1><p>erlang的计时器timer是通过一个唯一的timer进程实现的，该进程是一个gen_server，用户通过timer:send_after和timer:apply_after在指定时间间隔后收到指定消息或执行某个函数，每个用户的计时器都是一条记录，保存在timer的ets表timer_tab中，timer的时序驱动通过gen_server的超时机制实现。若同时使用timer的用户过多，则tiemr将响应不过来，成为瓶颈。<br>更好的方法是使用erlang的原生计时器erlang:send_after和erlang:start_timer，它们把计时器附着在进程自己身上。</p>\n<h1 id=\"尾调用和尾递归\"><a href=\"#尾调用和尾递归\" class=\"headerlink\" title=\" 尾调用和尾递归\"></a> 尾调用和尾递归</h1><p>尾调用和尾递归是erlang函数式语言最强大的优化，尽量保持函数尾部有尾调用或尾递归</p>\n<h1 id=\"文件预读，批量写，缓存\"><a href=\"#文件预读，批量写，缓存\" class=\"headerlink\" title=\"文件预读，批量写，缓存\"></a>文件预读，批量写，缓存</h1><p>这些方式都是局部性的体现：<br>预读：读空间局部性，文件提供了read_ahead选项<br>批量写：写空间局部性<br>对于文件写或套接字发送，存在若干级别的批量写：</p>\n<ol>\n<li>erlang进程级：进程内部通过list缓存数据</li>\n<li>erlang虚拟机：不管是efile还是inet的driver，都提供了批量写的选项delayed_write|delay_send，它们对大量的异步写性能提升很有效</li>\n<li>操作系统级：操作系统内部有文件写缓冲及套接字写缓冲</li>\n<li>硬件级：cache等<br>缓存：读写时间局部性，读写空间局部性，主要通过操作系统系统，erlang虚拟机没有内部的缓存</li>\n</ol>\n<h1 id=\"套接字标志设置\"><a href=\"#套接字标志设置\" class=\"headerlink\" title=\"套接字标志设置\"></a>套接字标志设置</h1><p>延迟发送：<code>{delay_send, true}</code>，聚合若干小消息为一个大消息，性能提升显著<br>发送高低水位：<code>{high_watermark, 128 * 1024} | {low_watermark, 64 * 1024}</code>，辅助delay_send使用，delay_send的聚合缓冲区大小为high_watermark，数据缓存到high_watermark后，将阻塞port_command，使用send发送数据，直到缓冲区大小降低到low_watermark后，解除阻塞，通常这些值越大越好，但erlang虚拟机允许设置的最大值不超过128K<br>发送缓冲大小：<code>{sndbuf, 16 * 1024}</code>，操作系统对套接字的发送缓冲大小，在延迟发送时有效，越大越好，但有极值<br>接收缓冲大小：<code>{recbuf, 16 * 1024}</code>，操作系统对套接字的接收缓冲大小</p>\n<h1 id=\"序列化-反序列化\"><a href=\"#序列化-反序列化\" class=\"headerlink\" title=\"序列化/反序列化\"></a>序列化/反序列化</h1><p>通常情况下，为了简化实现，一般将erlang的term序列化为binary，传递到目的地后，在将binary反序列化为term，这通常涉及到两个操作：<br>term_to_binary及binary_to_term，这两个操作性能消耗极为严重，应至多只做一次，减少甚至消除它们是最正确的，例如直接构造binary进行跨虚拟机数据交换；<br>但对比与其它的序列化和反序列化方式，如利用protobuf等，term_to_binary和binary_to_term的性能是高于这些方式的，毕竟是erlang原生格式，对于力求简单的应用，其序列化和反序列化方式推荐term_to_binary和binary_to_term</p>\n<h1 id=\"并发化\"><a href=\"#并发化\" class=\"headerlink\" title=\"并发化\"></a>并发化</h1><p>在一些场景下，如web请求、数据库请求、分布式文件系统等，单个接入接口已经不能满足性能需求，需要有多个接入接口，多个数据通道，等等，这要求所有请求处理过程必须是无状态的，或者状态更改同步进入一个公共存储，而公共存储也必须是支持并发处理的，如并发数据库、类hdfs、类dynamo存储等，若一致性要求较高，最好选用并发数据库，如mysql等，若在此基础上还要求高可用，最好选择同步多结点存储，<br>mnesia、zk都是这方面的典型；若不需要较高的一致性，类hdfs、类dynamo这类no sql存储即可满足</p>\n<h1 id=\"hipe\"><a href=\"#hipe\" class=\"headerlink\" title=\"hipe\"></a>hipe</h1><p>将erlang汇编翻译成机器码，减少一条erlang指令对应的cpu指令数</p>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"cjzkm7ppv0001jl9u6ujvzyrk","tag_id":"cjzkm7pq10003jl9uodqss2ga","_id":"cjzkm7pq70008jl9ughgay9d3"},{"post_id":"cjzkm7ppz0002jl9uidm2xk2w","tag_id":"cjzkm7pq60007jl9untcqqicb","_id":"cjzkm7pqc000djl9u76nyabtb"},{"post_id":"cjzkm7pqb000cjl9ur3fw0tyy","tag_id":"cjzkm7pq60007jl9untcqqicb","_id":"cjzkm7pqg000gjl9u35k3xa89"},{"post_id":"cjzkm7pq30004jl9uccv1me6a","tag_id":"cjzkm7pq60007jl9untcqqicb","_id":"cjzkm7pqh000ijl9uvq6hef7y"},{"post_id":"cjzkm7pq40005jl9u5npnhmds","tag_id":"cjzkm7pq60007jl9untcqqicb","_id":"cjzkm7pqj000mjl9u42aoku6i"},{"post_id":"cjzkm7pq50006jl9uyo8t0two","tag_id":"cjzkm7pqi000kjl9u976znvpi","_id":"cjzkm7pqm000qjl9ubcxhi8hf"},{"post_id":"cjzkm7pq70009jl9u479qhc33","tag_id":"cjzkm7pql000ojl9uge5dqffr","_id":"cjzkm7pqo000ujl9udg1um5pa"},{"post_id":"cjzkm7pq8000ajl9uxj9mnnk4","tag_id":"cjzkm7pqn000sjl9uvugakemc","_id":"cjzkm7pqq000yjl9u38ud39tq"},{"post_id":"cjzkm7pqr000zjl9umyo5cyw7","tag_id":"cjzkm7pq60007jl9untcqqicb","_id":"cjzkm7pqs0011jl9ufsmpf7cc"},{"post_id":"cjzkm7pqc000ejl9uh9v83fjg","tag_id":"cjzkm7pqq000xjl9uhrvsin8f","_id":"cjzkm7pqs0013jl9ubir3di5p"},{"post_id":"cjzkm7pqc000ejl9uh9v83fjg","tag_id":"cjzkm7pqs0010jl9uhdxcgh9p","_id":"cjzkm7pqt0014jl9ue1b4yaq4"},{"post_id":"cjzkm7pqg000hjl9ueio7zpyd","tag_id":"cjzkm7pqs0012jl9upcuf4wcj","_id":"cjzkm7pqu0016jl9u510z7vjf"},{"post_id":"cjzkm7pqh000jjl9uz8p61ho1","tag_id":"cjzkm7pqt0015jl9u0t979a27","_id":"cjzkm7pqv0018jl9uio76zvme"},{"post_id":"cjzkm7pqj000ljl9uwp1l9bpq","tag_id":"cjzkm7pqv0017jl9ucthrss72","_id":"cjzkm7pqw001bjl9u8h2t0wx7"},{"post_id":"cjzkm7pqj000ljl9uwp1l9bpq","tag_id":"cjzkm7pqv0019jl9u8phv7ypm","_id":"cjzkm7pqw001cjl9uym7bdigk"},{"post_id":"cjzkm7pqk000njl9usndlbyw2","tag_id":"cjzkm7pqw001ajl9upp8443lo","_id":"cjzkm7pqw001ejl9ugh05gqqx"},{"post_id":"cjzkm7pql000pjl9uskqgd5am","tag_id":"cjzkm7pqw001djl9u8z6rfhsg","_id":"cjzkm7pqx001hjl9u85rupob3"},{"post_id":"cjzkm7pql000pjl9uskqgd5am","tag_id":"cjzkm7pqx001fjl9uxv81am0y","_id":"cjzkm7pqx001ijl9ugo46lo63"},{"post_id":"cjzkm7pqm000rjl9uswsm6aqw","tag_id":"cjzkm7pqw001djl9u8z6rfhsg","_id":"cjzkm7pqz001ljl9uuesmyvey"},{"post_id":"cjzkm7pqm000rjl9uswsm6aqw","tag_id":"cjzkm7pqx001fjl9uxv81am0y","_id":"cjzkm7pqz001mjl9ucd4lbm33"},{"post_id":"cjzkm7pqn000tjl9u90l4usmr","tag_id":"cjzkm7pqw001djl9u8z6rfhsg","_id":"cjzkm7pr0001pjl9ubsxxuiyu"},{"post_id":"cjzkm7pqn000tjl9u90l4usmr","tag_id":"cjzkm7pqx001fjl9uxv81am0y","_id":"cjzkm7pr0001qjl9uub3kufad"},{"post_id":"cjzkm7pqo000vjl9uvghcqa1r","tag_id":"cjzkm7pq60007jl9untcqqicb","_id":"cjzkm7pr1001tjl9uda7qoaux"},{"post_id":"cjzkm7pqo000vjl9uvghcqa1r","tag_id":"cjzkm7pr0001ojl9utfwj7cxq","_id":"cjzkm7pr1001ujl9uu3yk3cp0"},{"post_id":"cjzkm7pqo000vjl9uvghcqa1r","tag_id":"cjzkm7pr1001rjl9ufsyoyctg","_id":"cjzkm7pr1001wjl9ukg7z245m"},{"post_id":"cjzkm7pqp000wjl9u0pgoizur","tag_id":"cjzkm7pr1001sjl9u06x69iid","_id":"cjzkm7pr2001xjl9ubhgtjcjw"},{"post_id":"cjzkm7pqp000wjl9u0pgoizur","tag_id":"cjzkm7pr1001vjl9u45nzyzuu","_id":"cjzkm7pr2001yjl9uckdyxckt"},{"post_id":"cjzkm7pra001zjl9uor750bx1","tag_id":"cjzkm7pq60007jl9untcqqicb","_id":"cjzkm7prb0021jl9uk4bw4ld5"}],"Tag":[{"name":"Cowboy","_id":"cjzkm7pq10003jl9uodqss2ga"},{"name":"Erlang","_id":"cjzkm7pq60007jl9untcqqicb"},{"name":"mqtt","_id":"cjzkm7pqi000kjl9u976znvpi"},{"name":"Nginx","_id":"cjzkm7pql000ojl9uge5dqffr"},{"name":"Swift","_id":"cjzkm7pqn000sjl9uvugakemc"},{"name":"Riak","_id":"cjzkm7pqq000xjl9uhrvsin8f"},{"name":"MapReduce","_id":"cjzkm7pqs0010jl9uhdxcgh9p"},{"name":"Ejabberd","_id":"cjzkm7pqs0012jl9upcuf4wcj"},{"name":"Git","_id":"cjzkm7pqt0015jl9u0t979a27"},{"name":"micro service","_id":"cjzkm7pqv0017jl9ucthrss72"},{"name":"golang","_id":"cjzkm7pqv0019jl9u8phv7ypm"},{"name":"hexo","_id":"cjzkm7pqw001ajl9upp8443lo"},{"name":"Web","_id":"cjzkm7pqw001djl9u8z6rfhsg"},{"name":"Restful","_id":"cjzkm7pqx001fjl9uxv81am0y"},{"name":"Tsung","_id":"cjzkm7pr0001ojl9utfwj7cxq"},{"name":"压测","_id":"cjzkm7pr1001rjl9ufsyoyctg"},{"name":"webrtc","_id":"cjzkm7pr1001sjl9u06x69iid"},{"name":"peer to peer","_id":"cjzkm7pr1001vjl9u45nzyzuu"}]}}